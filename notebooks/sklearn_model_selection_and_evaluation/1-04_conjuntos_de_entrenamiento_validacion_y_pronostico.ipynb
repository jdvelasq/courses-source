{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamiento de los datos en crossvalidation --- 8:05 min\n",
    "===\n",
    "\n",
    "* 8:05 min | Ultima modificación: Septiembre 29, 2021 | [YouTube](https://youtu.be/gLQ0lKpISrI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección se describe como debe realizarse el particionamiento de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjuntos de entrenamiento, validación y pronóstico\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de la evaluación de los modelos es dependiente de los datos usados. En la práctica, los datos se suelen partir en tres conjuntos, tal como muestra la gráfica de abajo:\n",
    "\n",
    "\n",
    "* Conjunto de calibración de parámetros del modelo.\n",
    "\n",
    "\n",
    "* Conjunto de prueba, usado comunmente para determinar la complejidad del modelo o el valor óptimo de alguno de sus parámetros.\n",
    "\n",
    "\n",
    "* Conjunto de pronóstico, en el que se intenta reproducir el comportamiento del modelo en productivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](assets/data-partition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura anterior, los datos se dividen secuencialmente, pero podría construirse cada conjunto aletaoriamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se tiene en cuenta que hay muchas particiones aleatorias posibles, una mejor estimación de la matriz de confusión (o cualquier otro estadístico que se calcule para un conjunto de datos) podría ser tomando los valores esperados de cada métrica. Es decir, si se repite el experimento $N$ veces, se tendrían $N$ valores posibles para cada uno de los elementos de la matriz de confusión y por lo tanto se podría tener su valor medio. Esta sería una métrica mucho más apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso básico de las técnicas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00],\n",
       "       [ 9.39692621e-01,  3.42020143e-01],\n",
       "       [ 7.66044443e-01,  6.42787610e-01],\n",
       "       [ 5.00000000e-01,  8.66025404e-01],\n",
       "       [ 1.73648178e-01,  9.84807753e-01],\n",
       "       [-1.73648178e-01,  9.84807753e-01],\n",
       "       [-5.00000000e-01,  8.66025404e-01],\n",
       "       [-7.66044443e-01,  6.42787610e-01],\n",
       "       [-9.39692621e-01,  3.42020143e-01],\n",
       "       [-1.00000000e+00,  1.22464680e-16],\n",
       "       [ 0.00000000e+00,  5.00000000e-01],\n",
       "       [ 6.03073792e-02,  1.57979857e-01],\n",
       "       [ 2.33955557e-01, -1.42787610e-01],\n",
       "       [ 5.00000000e-01, -3.66025404e-01],\n",
       "       [ 8.26351822e-01, -4.84807753e-01],\n",
       "       [ 1.17364818e+00, -4.84807753e-01],\n",
       "       [ 1.50000000e+00, -3.66025404e-01],\n",
       "       [ 1.76604444e+00, -1.42787610e-01],\n",
       "       [ 1.93969262e+00,  1.57979857e-01],\n",
       "       [ 2.00000000e+00,  5.00000000e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(\n",
    "    n_samples=20,\n",
    "    shuffle=False,\n",
    "    noise=None,\n",
    "    random_state=12345,\n",
    ")\n",
    "\n",
    "display(\n",
    "    X,\n",
    "    y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Se train_test_split para particionar los datos\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=5,\n",
    "    random_state=12345,\n",
    ")\n",
    "\n",
    "\n",
    "#\n",
    "# Se crea un esquema de partición de los datos\n",
    "# para usar crossvalidation\n",
    "#\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kFold = KFold(n_splits=5)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#\n",
    "# Se crea el modelo y se usa el cv seleccionado\n",
    "#\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LogisticRegressionCV(\n",
    "    Cs=10,\n",
    "    cv=kFold,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#\n",
    "# Se usa el conjunto de prueba para analizar la\n",
    "# generalización del modelo\n",
    "#\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "display(\n",
    "    accuracy_score(y_train, y_train_pred),\n",
    "    accuracy_score(y_test, y_test_pred),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
