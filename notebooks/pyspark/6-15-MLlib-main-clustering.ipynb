{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentación del mercado de adolecentes en PySpark\n",
    "===\n",
    "\n",
    "* *30 min* | Última modificación: Junio 22, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este tutorial se aplica el algoritmo K-means para clasificar un grupo de adolecentes con base en sus intéreses, con el fin de diseñar estrategias publicitarias y servicios encaminados a cada grupo de interés usando PySpark. Este tutorial se enfoca en la programación de PySpark y no en el análisis del problema. Para abordar este tutorial, el lector debe tener suficiencia en los módulos correspondientes de analítica predictiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un vendedor desea enviar publicidad electrónica a una población de adolecentes y adultos jóvenes con el fin de maximizar sus ventas. Para ello, desea poder clasificar a sus clientes potenciales por grupos de interés de acuerdo con sus intereses y consecuentemente enviar publicidad específica a cada uno de ellos.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este problema se desea determina que grupos de interés existen en una población de clientes a partir de los mensajes enviados por un servicio de redes sociales. La información disponible consiste en 30000 observaciones de 40 variables que podrían caracterizar los intereses de la población analizada. Estas variables corresponden a palabras que pueden asociarse a un interés de la poblaión analizada. Cada variable mide la frecuencia con que una determinada palabra aparece en los mensajes de texto; adicionalmente, dentro de estas variables se incluye  información como el sexo, la edad y la cantidad de contactos de la persona. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Se cargan librerías auxiliares que \n",
    "## pueden ser de utilidad en el desarrollo\n",
    "## del código\n",
    "##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Carga de las librerías de Spark\n",
    "##\n",
    "import findspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "APP_NAME = \"spark-kmeans-app\"\n",
    "\n",
    "conf = SparkConf().setAppName(APP_NAME) \n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo con los datos se encuentra en la carpeta actual de trabajo en la máquina local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-15 00:56:14--  https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/snsdata.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2631136 (2.5M) [text/plain]\n",
      "Saving to: 'snsdata.csv'\n",
      "\n",
      "snsdata.csv         100%[===================>]   2.51M  1.97MB/s    in 1.3s    \n",
      "\n",
      "2019-11-15 00:56:18 (1.97 MB/s) - 'snsdata.csv' saved [2631136/2631136]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/snsdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradyear,gender,age,friends,basketball,football,soccer,softball,volleyball,swimming,cheerleading,baseball,tennis,sports,cute,sex,sexy,hot,kissed,dance,band,marching,music,rock,god,church,jesus,bible,hair,dress,blonde,mall,shopping,clothes,hollister,abercrombie,die,death,drunk,drugs\n",
      "2006,M,18.982,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "2006,F,18.801,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,2,2,1,0,0,0,6,4,0,1,0,0,0,0,0,0,0,0\n",
      "2006,M,18.335,69,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0\n",
      "2006,F,18.875,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "2006,NA,18.995,10,0,0,0,0,0,0,0,0,0,0,0,1,0,0,5,1,1,0,3,0,1,0,0,0,1,0,0,0,2,0,0,0,0,0,1,1\n",
      "2006,F,,142,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,2,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0\n",
      "2006,F,18.93,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,2,0,0,2,0,0,0,0,0\n",
      "2006,M,18.322,17,0,0,0,1,0,0,0,0,0,0,0,2,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "2006,F,19.055,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Contenido del archivo\n",
    "##\n",
    "!head snsdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Mueve el archivo de datos al hdfs\n",
    "##\n",
    "!hdfs dfs -copyFromLocal snsdata.csv /tmp/snsdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Se carga el archivo en PySpark\n",
    "##\n",
    "spark_df = spark.read.load(\"/tmp/snsdata.csv\",\n",
    "                           format=\"csv\", \n",
    "                           sep=\",\", \n",
    "                           inferSchema=\"true\", \n",
    "                           header=\"true\")\n",
    "\n",
    "##\n",
    "## Número de registros cargados\n",
    "##\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gradyear: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- friends: integer (nullable = true)\n",
      " |-- basketball: integer (nullable = true)\n",
      " |-- football: integer (nullable = true)\n",
      " |-- soccer: integer (nullable = true)\n",
      " |-- softball: integer (nullable = true)\n",
      " |-- volleyball: integer (nullable = true)\n",
      " |-- swimming: integer (nullable = true)\n",
      " |-- cheerleading: integer (nullable = true)\n",
      " |-- baseball: integer (nullable = true)\n",
      " |-- tennis: integer (nullable = true)\n",
      " |-- sports: integer (nullable = true)\n",
      " |-- cute: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- sexy: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- kissed: integer (nullable = true)\n",
      " |-- dance: integer (nullable = true)\n",
      " |-- band: integer (nullable = true)\n",
      " |-- marching: integer (nullable = true)\n",
      " |-- music: integer (nullable = true)\n",
      " |-- rock: integer (nullable = true)\n",
      " |-- god: integer (nullable = true)\n",
      " |-- church: integer (nullable = true)\n",
      " |-- jesus: integer (nullable = true)\n",
      " |-- bible: integer (nullable = true)\n",
      " |-- hair: integer (nullable = true)\n",
      " |-- dress: integer (nullable = true)\n",
      " |-- blonde: integer (nullable = true)\n",
      " |-- mall: integer (nullable = true)\n",
      " |-- shopping: integer (nullable = true)\n",
      " |-- clothes: integer (nullable = true)\n",
      " |-- hollister: integer (nullable = true)\n",
      " |-- abercrombie: integer (nullable = true)\n",
      " |-- die: integer (nullable = true)\n",
      " |-- death: integer (nullable = true)\n",
      " |-- drunk: integer (nullable = true)\n",
      " |-- drugs: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Tipos de datos de los campos del DataFrame\n",
    "##\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se ejemplifican algunos cómputos típicos para el análisis exploratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>22054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NA</td>\n",
       "      <td>2724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>5222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  count\n",
       "0      F  22054\n",
       "1     NA   2724\n",
       "2      M   5222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Conteo por género\n",
    "##\n",
    "spark_df.groupBy('gender').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>24914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>17.993949546439772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>7.858054477853863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>3.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>106.927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 age\n",
       "0   count               24914\n",
       "1    mean  17.993949546439772\n",
       "2  stddev   7.858054477853863\n",
       "3     min               3.086\n",
       "4     max             106.927"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Se analizan los rangos de las variables \n",
    "## para determinar si hay datos por fuera de sus \n",
    "## rangos válidos. La variable `edad` contiene\n",
    "## datos por fuera de la población de interés.\n",
    "##\n",
    "## La muestra contiene un rango de edades \n",
    "## por fuera de la población de interés\n",
    "##\n",
    "spark_df.select('age').describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   age|\n",
      "+------+\n",
      "|18.982|\n",
      "|18.801|\n",
      "|18.335|\n",
      "|18.875|\n",
      "|18.995|\n",
      "|  null|\n",
      "| 18.93|\n",
      "|18.322|\n",
      "|19.055|\n",
      "|18.708|\n",
      "|18.543|\n",
      "|19.463|\n",
      "|18.097|\n",
      "|  null|\n",
      "|18.398|\n",
      "|  null|\n",
      "|  null|\n",
      "|18.987|\n",
      "|17.158|\n",
      "|18.497|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Se imprimen algunos registros para ver los \n",
    "## valores del campo edad\n",
    "##\n",
    "spark_df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5086"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Cantidad de nulos en la columna age\n",
    "##\n",
    "spark_df.filter(spark_df['age'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>age1319</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>24477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>17.25242893328433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>1.1574649278955391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>13.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>19.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary             age1319\n",
       "0   count               24477\n",
       "1    mean   17.25242893328433\n",
       "2  stddev  1.1574649278955391\n",
       "3     min              13.027\n",
       "4     max              19.995"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Se seleccionan las personas entre 13 y 20 años y \n",
    "## se descartan las demás observaciones\n",
    "##\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import when \n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "##\n",
    "## Se agrega una columna con las edades entre 13 y 19,\n",
    "## reemplazando por null los valores por fuera de este\n",
    "## rango\n",
    "##\n",
    "spark_df = spark_df.withColumn(\n",
    "    'age1319', \n",
    "    when((spark_df['age'] >= 13) & (spark_df['age'] < 20), \n",
    "         spark_df['age']\n",
    "        ).otherwise(lit(None).cast(DoubleType())))\n",
    "\n",
    "##\n",
    "## Se verifican los valores en la nueva columna\n",
    "##\n",
    "spark_df.select('age1319').describe().toPandas()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|gradyear|      avg(age1319)|\n",
      "+--------+------------------+\n",
      "|    2006|18.655857950872626|\n",
      "|    2007| 17.70617237497992|\n",
      "|    2008|16.767700737100785|\n",
      "|    2009|15.819573344509596|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Se calcula la edad promedio por año \n",
    "## de graduación para la muestra en el\n",
    "## rango de edades considerado\n",
    "##\n",
    "age_df = spark_df.groupby(\"gradyear\").mean().select(['gradyear', 'avg(age1319)']).orderBy('gradyear')\n",
    "age_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombres de las columnas de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['friends',\n",
       " 'basketball',\n",
       " 'football',\n",
       " 'soccer',\n",
       " 'softball',\n",
       " 'volleyball',\n",
       " 'swimming',\n",
       " 'cheerleading',\n",
       " 'baseball',\n",
       " 'tennis',\n",
       " 'sports',\n",
       " 'cute',\n",
       " 'sex',\n",
       " 'sexy',\n",
       " 'hot',\n",
       " 'kissed',\n",
       " 'dance',\n",
       " 'band',\n",
       " 'marching',\n",
       " 'music',\n",
       " 'rock',\n",
       " 'god',\n",
       " 'church',\n",
       " 'jesus',\n",
       " 'bible',\n",
       " 'hair',\n",
       " 'dress',\n",
       " 'blonde',\n",
       " 'mall',\n",
       " 'shopping',\n",
       " 'clothes',\n",
       " 'hollister',\n",
       " 'abercrombie',\n",
       " 'die',\n",
       " 'death',\n",
       " 'drunk',\n",
       " 'drugs']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Se obtienen las columnas de las\n",
    "## características de interes\n",
    "##\n",
    "inputCols = [a for a,_ in spark_df.dtypes]\n",
    "inputCols = inputCols[3:-1]\n",
    "inputCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensamble de las columnas usadas en el clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ensamblan las columnas en una lista por cada registro del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         rawFeatures|\n",
      "+--------------------+\n",
      "|(37,[0,16],[7.0,1...|\n",
      "|(37,[2,11,19,20,2...|\n",
      "|(37,[0,2,17,19,34...|\n",
      "|(37,[11,20],[1.0,...|\n",
      "|(37,[0,12,15,16,1...|\n",
      "|(37,[0,12,18,19,2...|\n",
      "|(37,[0,17,18,28,3...|\n",
      "|(37,[0,4,12,13,19...|\n",
      "|     (37,[0],[52.0])|\n",
      "|(37,[0,11,14,19,2...|\n",
      "|      (37,[0],[8.0])|\n",
      "|(37,[0,2,22],[21....|\n",
      "|(37,[0,12,19],[87...|\n",
      "|          (37,[],[])|\n",
      "|(37,[16,19,21,26,...|\n",
      "|          (37,[],[])|\n",
      "|(37,[0,20,21],[13...|\n",
      "|(37,[0,3,10,19],[...|\n",
      "|(37,[0,1,2,10,22]...|\n",
      "|(37,[0,7,19,21,28...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols = inputCols,\n",
    "    outputCol = 'rawFeatures')\n",
    "\n",
    "spark_df = vectorAssembler.transform(spark_df)\n",
    "\n",
    "spark_df.select('rawFeatures').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede al escalamiento de los datos relevantes para el agrupamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.00843373493975...|\n",
      "|[0.0,0.0,0.066666...|\n",
      "|[0.08313253012048...|\n",
      "|[0.0,0.0,0.0,0.0,...|\n",
      "|[0.01204819277108...|\n",
      "|[0.17108433734939...|\n",
      "|[0.08674698795180...|\n",
      "|[0.02048192771084...|\n",
      "|[0.06265060240963...|\n",
      "|[0.04698795180722...|\n",
      "|[0.00963855421686...|\n",
      "|[0.02530120481927...|\n",
      "|[0.10481927710843...|\n",
      "|[0.0,0.0,0.0,0.0,...|\n",
      "|[0.0,0.0,0.0,0.0,...|\n",
      "|[0.0,0.0,0.0,0.0,...|\n",
      "|[0.16265060240963...|\n",
      "|[0.03132530120481...|\n",
      "|[0.03253012048192...|\n",
      "|[0.14819277108433...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "## \n",
    "## Se construye el modelo y se entrena\n",
    "##\n",
    "scalerModel = MinMaxScaler(inputCol=\"rawFeatures\", outputCol=\"features\").fit(spark_df)\n",
    "\n",
    "##\n",
    "## Se aplica al DataFrame original para escalar los datos\n",
    "##\n",
    "spark_df = scalerModel.transform(spark_df)\n",
    "\n",
    "## \n",
    "## Se imprimen los datos escalados\n",
    "##\n",
    "spark_df.select(['features']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determinación de los grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.4111397632582284\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "##\n",
    "## Se realiza el agrupamiento. SetK() indica la\n",
    "## cantidad de grupos para los que deben obtenerse\n",
    "## sus centros.\n",
    "##\n",
    "model = KMeans().setK(5).setSeed(1).fit(spark_df)\n",
    "\n",
    "\n",
    "spark_df = model.transform(spark_df)\n",
    "\n",
    "silhouette = ClusteringEvaluator().evaluate(spark_df)\n",
    "\n",
    "\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[0.03319446 0.00894352 0.01386418 0.00704525 0.00718048 0.00752434\n",
      " 0.00329701 0.00325638 0.00601355 0.00510883 0.00979218 0.01168149\n",
      " 0.00109098 0.00634891 0.00791208 0.00176525 0.01047724 0.00405721\n",
      " 0.00361525 0.00989082 0.00927761 0.00515989 0.00441119 0.00343609\n",
      " 0.0017008  0.00643388 0.00628235 0.00016319 0.0098997  0.01184277\n",
      " 0.         0.0031591  0.00252869 0.00657909 0.00662576 0.\n",
      " 0.00188643]\n",
      "[0.04732319 0.01824388 0.03681733 0.00983469 0.01404121 0.01513317\n",
      " 0.00610534 0.32093534 0.01156427 0.00508475 0.01400659 0.03185813\n",
      " 0.00263901 0.01129944 0.02429379 0.00727944 0.02231638 0.00395908\n",
      " 0.00218285 0.01167461 0.01715093 0.00770579 0.00834617 0.00386064\n",
      " 0.00243965 0.01786532 0.01647834 0.00088547 0.03495763 0.06471495\n",
      " 0.02683616 0.02354049 0.01977401 0.00866718 0.0090799  0.01059322\n",
      " 0.00512006]\n",
      "[0.05157551 0.01875615 0.02536873 0.01379875 0.01931286 0.02498946\n",
      " 0.00851651 0.00940675 0.00704277 0.0094002  0.01499508 0.04242871\n",
      " 0.00224603 0.01052114 0.0319469  0.00502609 0.02823009 0.00519353\n",
      " 0.00362027 0.0150212  0.01591516 0.00712072 0.01041164 0.00486726\n",
      " 0.00182355 0.01958862 0.04018355 0.00048533 0.08043265 0.15253419\n",
      " 0.01924779 0.02713864 0.02297198 0.01016358 0.01093552 0.00567847\n",
      " 0.00431416]\n",
      "[0.03767757 0.01132303 0.01799075 0.00882724 0.00908686 0.00860205\n",
      " 0.00518651 0.00525431 0.00669924 0.00592686 0.01718159 0.02360936\n",
      " 0.00719564 0.01492224 0.01664565 0.01581143 0.01784363 0.00648668\n",
      " 0.00338186 0.01583189 0.01948598 0.00930611 0.00600424 0.00405633\n",
      " 0.00298063 0.03004328 0.01800476 0.00117619 0.02690206 0.02361573\n",
      " 0.01875788 0.00735603 0.00732976 0.02117964 0.01657359 0.17946091\n",
      " 0.02088588]\n",
      "[0.03914672 0.01744742 0.02414277 0.01028256 0.01484647 0.01313849\n",
      " 0.00653796 0.00662843 0.00901052 0.00724028 0.01889739 0.03089016\n",
      " 0.00402871 0.01155726 0.0214914  0.01281071 0.02217973 0.00666898\n",
      " 0.00500608 0.01794336 0.01884731 0.00778856 0.00869981 0.00452518\n",
      " 0.00330262 0.02917679 0.02183981 0.00053444 0.03384321 0.04029202\n",
      " 0.16935946 0.016826   0.01281071 0.01303668 0.01193663 0.00707457\n",
      " 0.00803059]\n"
     ]
    }
   ],
   "source": [
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         0|\n",
      "|         2|\n",
      "|         0|\n",
      "|         0|\n",
      "|         3|\n",
      "|         3|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         4|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         2|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select('prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  count\n",
       "0           1    708\n",
       "1           3   1592\n",
       "2           4   2607\n",
       "3           2   3361\n",
       "4           0  21732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Número de patrones asignados a cada cluster\n",
    "##\n",
    "spark_df.groupBy('prediction').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-------+\n",
      "|prediction|gender|   age|friends|\n",
      "+----------+------+------+-------+\n",
      "|         0|     M|18.982|      7|\n",
      "|         2|     F|18.801|      0|\n",
      "|         0|     M|18.335|     69|\n",
      "|         0|     F|18.875|      0|\n",
      "|         3|    NA|18.995|     10|\n",
      "|         3|     F|  null|    142|\n",
      "|         0|     F| 18.93|     72|\n",
      "|         0|     M|18.322|     17|\n",
      "|         0|     F|19.055|     52|\n",
      "|         0|     F|18.708|     39|\n",
      "|         0|     F|18.543|      8|\n",
      "|         0|     F|19.463|     21|\n",
      "|         0|     F|18.097|     87|\n",
      "|         0|    NA|  null|      0|\n",
      "|         4|     F|18.398|      0|\n",
      "|         0|    NA|  null|      0|\n",
      "|         0|    NA|  null|    135|\n",
      "|         0|     F|18.987|     26|\n",
      "|         0|     F|17.158|     27|\n",
      "|         2|     F|18.497|    123|\n",
      "+----------+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## clusters a los que pertenecen los primeros patrones\n",
    "##\n",
    "spark_df.select([\"prediction\", \"gender\", \"age\", \"friends\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gradyear: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- friends: integer (nullable = true)\n",
      " |-- basketball: integer (nullable = true)\n",
      " |-- football: integer (nullable = true)\n",
      " |-- soccer: integer (nullable = true)\n",
      " |-- softball: integer (nullable = true)\n",
      " |-- volleyball: integer (nullable = true)\n",
      " |-- swimming: integer (nullable = true)\n",
      " |-- cheerleading: integer (nullable = true)\n",
      " |-- baseball: integer (nullable = true)\n",
      " |-- tennis: integer (nullable = true)\n",
      " |-- sports: integer (nullable = true)\n",
      " |-- cute: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- sexy: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- kissed: integer (nullable = true)\n",
      " |-- dance: integer (nullable = true)\n",
      " |-- band: integer (nullable = true)\n",
      " |-- marching: integer (nullable = true)\n",
      " |-- music: integer (nullable = true)\n",
      " |-- rock: integer (nullable = true)\n",
      " |-- god: integer (nullable = true)\n",
      " |-- church: integer (nullable = true)\n",
      " |-- jesus: integer (nullable = true)\n",
      " |-- bible: integer (nullable = true)\n",
      " |-- hair: integer (nullable = true)\n",
      " |-- dress: integer (nullable = true)\n",
      " |-- blonde: integer (nullable = true)\n",
      " |-- mall: integer (nullable = true)\n",
      " |-- shopping: integer (nullable = true)\n",
      " |-- clothes: integer (nullable = true)\n",
      " |-- hollister: integer (nullable = true)\n",
      " |-- abercrombie: integer (nullable = true)\n",
      " |-- die: integer (nullable = true)\n",
      " |-- death: integer (nullable = true)\n",
      " |-- drunk: integer (nullable = true)\n",
      " |-- drugs: integer (nullable = true)\n",
      " |-- age1319: double (nullable = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.join(age_df, spark_df.gradyear == age_df.gradyear)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|      avg(age1319)|\n",
      "+----------+------------------+\n",
      "|         1|16.982795681063113|\n",
      "|         3|17.393787091988127|\n",
      "|         4|17.115304945054945|\n",
      "|         2|17.101725897255488|\n",
      "|         0|17.292400662819276|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Características demográficas de los clusters.\n",
    "## Edad por cluster.\n",
    "##\n",
    "spark_df.groupby(\"prediction\").mean().select(['prediction', 'avg(age1319)']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Se agrega una columna indicadora para el genero\n",
    "##\n",
    "spark_df = spark_df.withColumn(\n",
    "    'isFemale', \n",
    "    when(spark_df['gender'] == 'F', 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|prediction|     avg(isFemale)|\n",
      "+----------+------------------+\n",
      "|         1|0.9067796610169492|\n",
      "|         3|0.7594221105527639|\n",
      "|         4|0.8304564633678557|\n",
      "|         2| 0.911335911930973|\n",
      "|         0|0.6890760169335542|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Cantidad de mujeres por cluster.\n",
    "##\n",
    "spark_df.groupby(\"prediction\").mean().select(['prediction', 'avg(isFemale)']).show()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
