{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operaciones SQL en PySpark\n",
    "===\n",
    "\n",
    "* *30 min* | Última modificación: Junio 22, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL es una interfaz para el procesamiento de datos estructurados usando el lenguaje SQL. En adición, Spark SQL también puede ser usado para leer datos de Apache Hive. Spark SQL opera sobre DataFrames, los cuales son Datasets (RDD) organizado por columnas identificadas por nombres, los cuales equivalen a tablas en los sistemas de bases de datos relacionales.\n",
    "\n",
    "Al finalizar este tutorial, el lector estará en capacidad de:\n",
    "\n",
    "* Crear DataFrames a partir de archivos en distintos formatos.\n",
    "\n",
    "* Aplicar operaciones de selección, filtrado y agregación a un DataFrame.\n",
    "\n",
    "* Aplicar consultas en SQL sobre un DataFrame.\n",
    "\n",
    "* Aplicar consultas en SQL directamente sobre archivos.\n",
    "\n",
    "* Escribir los resultados de operaciones al disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/18 04:45:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/18 04:45:14 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# findspark permite usar pyspark (interfaz de Python a Spark),\n",
    "# desde cualquier programa escrito en Python.\n",
    "#\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#\n",
    "# A continuación se inicializan las variables obligatorias\n",
    "# requeridas para trabajar con Spark desde Python:\n",
    "#\n",
    "#  SparkContext representa la conexión al cluster de Spark.\n",
    "#  SparkConf representa la configuración particular de una aplicación\n",
    "#     escrita en Spark.\n",
    "#  SparkSession representa la conexión para trabajar con SQL.\n",
    "#\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "sparkConf = SparkConf().setAppName(\"My SparkQL Application\")\n",
    "sc = SparkContext(conf=sparkConf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de DataFrames\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta la carga de DataFrames desde diferentes formatos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formato JSON\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un archivo en formato JSON en la máquina local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/people.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/people.json\n",
    "{\n",
    "    \"id\": 1,\n",
    "    \"firstname\": \"Vivian\",\n",
    "    \"surname\": \"Hamilton\",\n",
    "    \"birthdate\": \"1971-07-08\",\n",
    "    \"color\": \"green\",\n",
    "    \"quantity\": 1,\n",
    "}\n",
    "{\n",
    "    \"id\": 2,\n",
    "    \"firstname\": \"Karen\",\n",
    "    \"surname\": \"Holcomb\",\n",
    "    \"birthdate\": \"1974-05-23\",\n",
    "    \"color\": \"green\",\n",
    "    \"quantity\": 4,\n",
    "}\n",
    "{\n",
    "    \"id\": 3,\n",
    "    \"firstname\": \"Cody\",\n",
    "    \"surname\": \"Garrett\",\n",
    "    \"birthdate\": \"1973-04-22\",\n",
    "    \"color\": \"orange\",\n",
    "    \"quantity\": 1,\n",
    "}\n",
    "{\n",
    "    \"id\": 4,\n",
    "    \"firstname\": \"Roth\",\n",
    "    \"surname\": \"Fry\",\n",
    "    \"birthdate\": \"1975-01-29\",\n",
    "    \"color\": \"black\",\n",
    "    \"quantity\": 1,\n",
    "}\n",
    "{\n",
    "    \"id\": 5,\n",
    "    \"firstname\": \"Zoe\",\n",
    "    \"surname\": \"Conway\",\n",
    "    \"birthdate\": \"1974-07-03\",\n",
    "    \"color\": \"blue\",\n",
    "    \"quantity\": 2,\n",
    "}\n",
    "{\n",
    "    \"id\": 6,\n",
    "    \"firstname\": \"Gretchen\",\n",
    "    \"surname\": \"Kinney\",\n",
    "    \"birthdate\": \"1974-10-18\",\n",
    "    \"color\": \"violet\",\n",
    "    \"quantity\": 1,\n",
    "}\n",
    "{\n",
    "    \"id\": 7,\n",
    "    \"firstname\": \"Driscoll\",\n",
    "    \"surname\": \"Klein\",\n",
    "    \"birthdate\": \"1970-10-05\",\n",
    "    \"color\": \"blue\",\n",
    "    \"quantity\": 5,\n",
    "}\n",
    "{\n",
    "    \"id\": 8,\n",
    "    \"firstname\": \"Karyn\",\n",
    "    \"surname\": \"Diaz\",\n",
    "    \"birthdate\": \"1969-02-24\",\n",
    "    \"color\": \"red\",\n",
    "    \"quantity\": 1,\n",
    "}\n",
    "{\n",
    "    \"id\": 9,\n",
    "    \"firstname\": \"Merritt\",\n",
    "    \"surname\": \"Guy\",\n",
    "    \"birthdate\": \"1974-10-17\",\n",
    "    \"color\": \"indigo\",\n",
    "    \"quantity\": 4,\n",
    "}\n",
    "{\n",
    "    \"id\": 10,\n",
    "    \"firstname\": \"Kylan\",\n",
    "    \"surname\": \"Sexton\",\n",
    "    \"birthdate\": \"1975-02-28\",\n",
    "    \"color\": \"black\",\n",
    "    \"quantity\": 4,\n",
    "}\n",
    "{\n",
    "    \"id\": 11,\n",
    "    \"firstname\": \"Jordan\",\n",
    "    \"surname\": \"Estes\",\n",
    "    \"birthdate\": \"1969-12-07\",\n",
    "    \"color\": \"indigo\",\n",
    "    \"quantity\": 4,\n",
    "}\n",
    "{\n",
    "    \"id\": 12,\n",
    "    \"firstname\": \"Hope\",\n",
    "    \"surname\": \"Coffey\",\n",
    "    \"birthdate\": \"1973-12-24\",\n",
    "    \"color\": \"green\",\n",
    "    \"quantity\": 5,\n",
    "}\n",
    "{\n",
    "    \"id\": 13,\n",
    "    \"firstname\": \"Vivian\",\n",
    "    \"surname\": \"Crane\",\n",
    "    \"birthdate\": \"1970-08-27\",\n",
    "    \"color\": \"gray\",\n",
    "    \"quantity\": 5,\n",
    "}\n",
    "{\n",
    "    \"id\": 14,\n",
    "    \"firstname\": \"Clio\",\n",
    "    \"surname\": \"Noel\",\n",
    "    \"birthdate\": \"1972-12-12\",\n",
    "    \"color\": \"red\",\n",
    "    \"quantity\": 5,\n",
    "}\n",
    "{\n",
    "    \"id\": 15,\n",
    "    \"firstname\": \"Hope\",\n",
    "    \"surname\": \"Silva\",\n",
    "    \"birthdate\": \"1970-07-01\",\n",
    "    \"color\": \"blue\",\n",
    "    \"quantity\": 5,\n",
    "}\n",
    "{\n",
    "    \"id\": 16,\n",
    "    \"firstname\": \"Ayanna\",\n",
    "    \"surname\": \"Jarvis\",\n",
    "    \"birthdate\": \"1974-02-11\",\n",
    "    \"color\": \"orange\",\n",
    "    \"quantity\": 5,\n",
    "}\n",
    "{\n",
    "    \"id\": 17,\n",
    "    \"firstname\": \"Chanda\",\n",
    "    \"surname\": \"Boyer\",\n",
    "    \"birthdate\": \"1973-04-01\",\n",
    "    \"color\": \"green\",\n",
    "    \"quantity\": 4,\n",
    "}\n",
    "{\n",
    "    \"id\": 18,\n",
    "    \"firstname\": \"Chadwick\",\n",
    "    \"surname\": \"Knight\",\n",
    "    \"birthdate\": \"1973-04-29\",\n",
    "    \"color\": \"yellow\",\n",
    "    \"quantity\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia el archivo al HDFS\n",
    "!hdfs dfs -copyFromLocal  /tmp/people.json /tmp/people.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---+--------+--------+\n",
      "| birthdate| color|firstname| id|quantity| surname|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "|1971-07-08| green|   Vivian|  1|       1|Hamilton|\n",
      "|1974-05-23| green|    Karen|  2|       4| Holcomb|\n",
      "|1973-04-22|orange|     Cody|  3|       1| Garrett|\n",
      "|1975-01-29| black|     Roth|  4|       1|     Fry|\n",
      "|1974-07-03|  blue|      Zoe|  5|       2|  Conway|\n",
      "|1974-10-18|violet| Gretchen|  6|       1|  Kinney|\n",
      "|1970-10-05|  blue| Driscoll|  7|       5|   Klein|\n",
      "|1969-02-24|   red|    Karyn|  8|       1|    Diaz|\n",
      "|1974-10-17|indigo|  Merritt|  9|       4|     Guy|\n",
      "|1975-02-28| black|    Kylan| 10|       4|  Sexton|\n",
      "|1969-12-07|indigo|   Jordan| 11|       4|   Estes|\n",
      "|1973-12-24| green|     Hope| 12|       5|  Coffey|\n",
      "|1970-08-27|  gray|   Vivian| 13|       5|   Crane|\n",
      "|1972-12-12|   red|     Clio| 14|       5|    Noel|\n",
      "|1970-07-01|  blue|     Hope| 15|       5|   Silva|\n",
      "|1974-02-11|orange|   Ayanna| 16|       5|  Jarvis|\n",
      "|1973-04-01| green|   Chanda| 17|       4|   Boyer|\n",
      "|1973-04-29|yellow| Chadwick| 18|       1|  Knight|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# La función spark.read.json() carga directamente\n",
    "# el archivo en JSON con un DataFrame.\n",
    "#\n",
    "df = spark.read.json(\"/tmp/people.json\")\n",
    "\n",
    "#\n",
    "# La función show() permite imprimirlo en pantalla\n",
    "#\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formato CSV y TXT\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se ejemplifica como procesar un archivo de texto para convertirlo en un DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/people.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile  /tmp/people.csv\n",
    "1,Vivian,Hamilton,1971-07-08,green,1\n",
    "2,Karen,Holcomb,1974-05-23,green,4\n",
    "3,Cody,Garrett,1973-04-22,orange,1\n",
    "4,Roth,Fry,1975-01-29,black,1\n",
    "5,Zoe,Conway,1974-07-03,blue,2\n",
    "6,Gretchen,Kinney,1974-10-18,violet,1\n",
    "7,Driscoll,Klein,1970-10-05,blue,5\n",
    "8,Karyn,Diaz,1969-02-24,red,1\n",
    "9,Merritt,Guy,1974-10-17,indigo,4\n",
    "10,Kylan,Sexton,1975-02-28,black,4\n",
    "11,Jordan,Estes,1969-12-07,indigo,4\n",
    "12,Hope,Coffey,1973-12-24,green,5\n",
    "13,Vivian,Crane,1970-08-27,gray,5\n",
    "14,Clio,Noel,1972-12-12,red,5\n",
    "15,Hope,Silva,1970-07-01,blue,5\n",
    "16,Ayanna,Jarvis,1974-02-11,orange,5\n",
    "17,Chanda,Boyer,1973-04-01,green,4\n",
    "18,Chadwick,Knight,1973-04-29,yellow,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/tmp/people.csv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# copia el archivo al HDFS\n",
    "!hdfs dfs -rm /tmp/people.csv\n",
    "!hdfs dfs -copyFromLocal  /tmp/people.csv /tmp/people.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,Vivian,Hamilton,1971-07-08,green,1',\n",
       " '2,Karen,Holcomb,1974-05-23,green,4',\n",
       " '3,Cody,Garrett,1973-04-22,orange,1',\n",
       " '4,Roth,Fry,1975-01-29,black,1',\n",
       " '5,Zoe,Conway,1974-07-03,blue,2',\n",
       " '6,Gretchen,Kinney,1974-10-18,violet,1',\n",
       " '7,Driscoll,Klein,1970-10-05,blue,5',\n",
       " '8,Karyn,Diaz,1969-02-24,red,1',\n",
       " '9,Merritt,Guy,1974-10-17,indigo,4',\n",
       " '10,Kylan,Sexton,1975-02-28,black,4',\n",
       " '11,Jordan,Estes,1969-12-07,indigo,4',\n",
       " '12,Hope,Coffey,1973-12-24,green,5',\n",
       " '13,Vivian,Crane,1970-08-27,gray,5',\n",
       " '14,Clio,Noel,1972-12-12,red,5',\n",
       " '15,Hope,Silva,1970-07-01,blue,5',\n",
       " '16,Ayanna,Jarvis,1974-02-11,orange,5',\n",
       " '17,Chanda,Boyer,1973-04-01,green,4',\n",
       " '18,Chadwick,Knight,1973-04-29,yellow,1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Row representa una fila en un RDD\n",
    "#\n",
    "from pyspark.sql import Row\n",
    "\n",
    "#\n",
    "# Lectura del archivo como lineas de texto\n",
    "#\n",
    "rdd = sc.textFile(\"/tmp/people.csv\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Vivian', 'Hamilton', '1971-07-08', 'green', '1'],\n",
       " ['2', 'Karen', 'Holcomb', '1974-05-23', 'green', '4'],\n",
       " ['3', 'Cody', 'Garrett', '1973-04-22', 'orange', '1'],\n",
       " ['4', 'Roth', 'Fry', '1975-01-29', 'black', '1'],\n",
       " ['5', 'Zoe', 'Conway', '1974-07-03', 'blue', '2'],\n",
       " ['6', 'Gretchen', 'Kinney', '1974-10-18', 'violet', '1'],\n",
       " ['7', 'Driscoll', 'Klein', '1970-10-05', 'blue', '5'],\n",
       " ['8', 'Karyn', 'Diaz', '1969-02-24', 'red', '1'],\n",
       " ['9', 'Merritt', 'Guy', '1974-10-17', 'indigo', '4'],\n",
       " ['10', 'Kylan', 'Sexton', '1975-02-28', 'black', '4'],\n",
       " ['11', 'Jordan', 'Estes', '1969-12-07', 'indigo', '4'],\n",
       " ['12', 'Hope', 'Coffey', '1973-12-24', 'green', '5'],\n",
       " ['13', 'Vivian', 'Crane', '1970-08-27', 'gray', '5'],\n",
       " ['14', 'Clio', 'Noel', '1972-12-12', 'red', '5'],\n",
       " ['15', 'Hope', 'Silva', '1970-07-01', 'blue', '5'],\n",
       " ['16', 'Ayanna', 'Jarvis', '1974-02-11', 'orange', '5'],\n",
       " ['17', 'Chanda', 'Boyer', '1973-04-01', 'green', '4'],\n",
       " ['18', 'Chadwick', 'Knight', '1973-04-29', 'yellow', '1']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Partición de los strings por las comas\n",
    "#\n",
    "rdd = rdd.map(lambda row: row.split(\",\"))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='1', firstname='Vivian', surname='Hamilton', birthdate='1971-07-08', color='green', quantity=1),\n",
       " Row(id='2', firstname='Karen', surname='Holcomb', birthdate='1974-05-23', color='green', quantity=4),\n",
       " Row(id='3', firstname='Cody', surname='Garrett', birthdate='1973-04-22', color='orange', quantity=1),\n",
       " Row(id='4', firstname='Roth', surname='Fry', birthdate='1975-01-29', color='black', quantity=1),\n",
       " Row(id='5', firstname='Zoe', surname='Conway', birthdate='1974-07-03', color='blue', quantity=2),\n",
       " Row(id='6', firstname='Gretchen', surname='Kinney', birthdate='1974-10-18', color='violet', quantity=1),\n",
       " Row(id='7', firstname='Driscoll', surname='Klein', birthdate='1970-10-05', color='blue', quantity=5),\n",
       " Row(id='8', firstname='Karyn', surname='Diaz', birthdate='1969-02-24', color='red', quantity=1),\n",
       " Row(id='9', firstname='Merritt', surname='Guy', birthdate='1974-10-17', color='indigo', quantity=4),\n",
       " Row(id='10', firstname='Kylan', surname='Sexton', birthdate='1975-02-28', color='black', quantity=4),\n",
       " Row(id='11', firstname='Jordan', surname='Estes', birthdate='1969-12-07', color='indigo', quantity=4),\n",
       " Row(id='12', firstname='Hope', surname='Coffey', birthdate='1973-12-24', color='green', quantity=5),\n",
       " Row(id='13', firstname='Vivian', surname='Crane', birthdate='1970-08-27', color='gray', quantity=5),\n",
       " Row(id='14', firstname='Clio', surname='Noel', birthdate='1972-12-12', color='red', quantity=5),\n",
       " Row(id='15', firstname='Hope', surname='Silva', birthdate='1970-07-01', color='blue', quantity=5),\n",
       " Row(id='16', firstname='Ayanna', surname='Jarvis', birthdate='1974-02-11', color='orange', quantity=5),\n",
       " Row(id='17', firstname='Chanda', surname='Boyer', birthdate='1973-04-01', color='green', quantity=4),\n",
       " Row(id='18', firstname='Chadwick', surname='Knight', birthdate='1973-04-29', color='yellow', quantity=1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se transforma cada elemento del RDD usando la función Row().\n",
    "# Note que esta función agrega el nombre de la columna a la\n",
    "# que pertenece cada dato.\n",
    "#\n",
    "rdd = rdd.map(\n",
    "    lambda p: Row(\n",
    "        id=p[0],\n",
    "        firstname=p[1],\n",
    "        surname=p[2],\n",
    "        birthdate=p[3],\n",
    "        color=p[4],\n",
    "        quantity=int(p[5]),\n",
    "    )\n",
    ")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+------+--------+\n",
      "| id|firstname| surname| birthdate| color|quantity|\n",
      "+---+---------+--------+----------+------+--------+\n",
      "|  1|   Vivian|Hamilton|1971-07-08| green|       1|\n",
      "|  2|    Karen| Holcomb|1974-05-23| green|       4|\n",
      "|  3|     Cody| Garrett|1973-04-22|orange|       1|\n",
      "|  4|     Roth|     Fry|1975-01-29| black|       1|\n",
      "|  5|      Zoe|  Conway|1974-07-03|  blue|       2|\n",
      "|  6| Gretchen|  Kinney|1974-10-18|violet|       1|\n",
      "|  7| Driscoll|   Klein|1970-10-05|  blue|       5|\n",
      "|  8|    Karyn|    Diaz|1969-02-24|   red|       1|\n",
      "|  9|  Merritt|     Guy|1974-10-17|indigo|       4|\n",
      "| 10|    Kylan|  Sexton|1975-02-28| black|       4|\n",
      "| 11|   Jordan|   Estes|1969-12-07|indigo|       4|\n",
      "| 12|     Hope|  Coffey|1973-12-24| green|       5|\n",
      "| 13|   Vivian|   Crane|1970-08-27|  gray|       5|\n",
      "| 14|     Clio|    Noel|1972-12-12|   red|       5|\n",
      "| 15|     Hope|   Silva|1970-07-01|  blue|       5|\n",
      "| 16|   Ayanna|  Jarvis|1974-02-11|orange|       5|\n",
      "| 17|   Chanda|   Boyer|1973-04-01| green|       4|\n",
      "| 18| Chadwick|  Knight|1973-04-29|yellow|       1|\n",
      "+---+---------+--------+----------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# createDataFrame() permite crear un DataFrame a partir\n",
    "# de un RDD, una lista o un pandas.DataFrame\n",
    "#\n",
    "df = spark.createDataFrame(rdd)\n",
    "\n",
    "#\n",
    "# Crea o reemplaza una vista local del DataFrame\n",
    "# para poder aplicar funciones como show()\n",
    "#\n",
    "df.createOrReplaceTempView(\"miVista\")\n",
    "# también podría usarse createTempView()\n",
    "df.show()\n",
    "\n",
    "spark.catalog.dropTempView(\"miVista\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea un DataFrame a partir de un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/people.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile  /tmp/people.csv\n",
    "id,firstname,surname,birthdate,color,quantity\n",
    "1,Vivian,Hamilton,1971-07-08,green,1\n",
    "2,Karen,Holcomb,1974-05-23,green,4\n",
    "3,Cody,Garrett,1973-04-22,orange,1\n",
    "4,Roth,Fry,1975-01-29,black,1\n",
    "5,Zoe,Conway,1974-07-03,blue,2\n",
    "6,Gretchen,Kinney,1974-10-18,violet,1\n",
    "7,Driscoll,Klein,1970-10-05,blue,5\n",
    "8,Karyn,Diaz,1969-02-24,red,1\n",
    "9,Merritt,Guy,1974-10-17,indigo,4\n",
    "10,Kylan,Sexton,1975-02-28,black,4\n",
    "11,Jordan,Estes,1969-12-07,indigo,4\n",
    "12,Hope,Coffey,1973-12-24,green,5\n",
    "13,Vivian,Crane,1970-08-27,gray,5\n",
    "14,Clio,Noel,1972-12-12,red,5\n",
    "15,Hope,Silva,1970-07-01,blue,5\n",
    "16,Ayanna,Jarvis,1974-02-11,orange,5\n",
    "17,Chanda,Boyer,1973-04-01,green,4\n",
    "18,Chadwick,Knight,1973-04-29,yellow,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/people.csv\n"
     ]
    }
   ],
   "source": [
    "# Mueve el archivo al sistema hdfs\n",
    "!hdfs dfs -rm /tmp/people.csv\n",
    "!hdfs dfs -copyFromLocal  /tmp/people.csv /tmp/people.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+------+--------+\n",
      "| id|firstname| surname| birthdate| color|quantity|\n",
      "+---+---------+--------+----------+------+--------+\n",
      "|  1|   Vivian|Hamilton|1971-07-08| green|       1|\n",
      "|  2|    Karen| Holcomb|1974-05-23| green|       4|\n",
      "|  3|     Cody| Garrett|1973-04-22|orange|       1|\n",
      "|  4|     Roth|     Fry|1975-01-29| black|       1|\n",
      "|  5|      Zoe|  Conway|1974-07-03|  blue|       2|\n",
      "|  6| Gretchen|  Kinney|1974-10-18|violet|       1|\n",
      "|  7| Driscoll|   Klein|1970-10-05|  blue|       5|\n",
      "|  8|    Karyn|    Diaz|1969-02-24|   red|       1|\n",
      "|  9|  Merritt|     Guy|1974-10-17|indigo|       4|\n",
      "| 10|    Kylan|  Sexton|1975-02-28| black|       4|\n",
      "| 11|   Jordan|   Estes|1969-12-07|indigo|       4|\n",
      "| 12|     Hope|  Coffey|1973-12-24| green|       5|\n",
      "| 13|   Vivian|   Crane|1970-08-27|  gray|       5|\n",
      "| 14|     Clio|    Noel|1972-12-12|   red|       5|\n",
      "| 15|     Hope|   Silva|1970-07-01|  blue|       5|\n",
      "| 16|   Ayanna|  Jarvis|1974-02-11|orange|       5|\n",
      "| 17|   Chanda|   Boyer|1973-04-01| green|       4|\n",
      "| 18| Chadwick|  Knight|1973-04-29|yellow|       1|\n",
      "+---+---------+--------+----------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Crea un DataFrame a partir del archivo con\n",
    "# formato CSV\n",
    "#\n",
    "df = spark.read.load(\n",
    "    \"/tmp/people.csv\", format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\",\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operaciones sobre DataFrames\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- surname: string (nullable = true)\n",
      " |-- birthdate: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Imprime el esquema en formato de arbol\n",
    "#\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|firstname|\n",
      "+---------+\n",
      "|   Vivian|\n",
      "|    Karen|\n",
      "|     Cody|\n",
      "|     Roth|\n",
      "|      Zoe|\n",
      "| Gretchen|\n",
      "| Driscoll|\n",
      "|    Karyn|\n",
      "|  Merritt|\n",
      "|    Kylan|\n",
      "|   Jordan|\n",
      "|     Hope|\n",
      "|   Vivian|\n",
      "|     Clio|\n",
      "|     Hope|\n",
      "|   Ayanna|\n",
      "|   Chanda|\n",
      "| Chadwick|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Selección de una columna en particular\n",
    "#\n",
    "df.select(\"firstname\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname| surname|\n",
      "+---------+--------+\n",
      "|   Vivian|Hamilton|\n",
      "|    Karen| Holcomb|\n",
      "|     Cody| Garrett|\n",
      "|     Roth|     Fry|\n",
      "|      Zoe|  Conway|\n",
      "| Gretchen|  Kinney|\n",
      "| Driscoll|   Klein|\n",
      "|    Karyn|    Diaz|\n",
      "|  Merritt|     Guy|\n",
      "|    Kylan|  Sexton|\n",
      "|   Jordan|   Estes|\n",
      "|     Hope|  Coffey|\n",
      "|   Vivian|   Crane|\n",
      "|     Clio|    Noel|\n",
      "|     Hope|   Silva|\n",
      "|   Ayanna|  Jarvis|\n",
      "|   Chanda|   Boyer|\n",
      "| Chadwick|  Knight|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Selección de varias columnas\n",
    "#\n",
    "df.select([\"firstname\", \"surname\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+----------+-----+--------+\n",
      "| id|firstname|surname| birthdate|color|quantity|\n",
      "+---+---------+-------+----------+-----+--------+\n",
      "|  5|      Zoe| Conway|1974-07-03| blue|       2|\n",
      "|  7| Driscoll|  Klein|1970-10-05| blue|       5|\n",
      "| 15|     Hope|  Silva|1970-07-01| blue|       5|\n",
      "+---+---------+-------+----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Filtrado de registros usando condicionales\n",
    "#\n",
    "df.filter(df[\"color\"] == \"blue\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+-------------------+------+--------+\n",
      "| id|firstname| surname|          birthdate| color|quantity|\n",
      "+---+---------+--------+-------------------+------+--------+\n",
      "|  1|   Vivian|Hamilton|1971-07-08 00:00:00| green|       1|\n",
      "|  2|    Karen| Holcomb|1974-05-23 00:00:00| green|       4|\n",
      "|  3|     Cody| Garrett|1973-04-22 00:00:00|orange|       1|\n",
      "|  4|     Roth|     Fry|1975-01-29 00:00:00| black|       1|\n",
      "|  5|      Zoe|  Conway|1974-07-03 00:00:00|  blue|       2|\n",
      "|  6| Gretchen|  Kinney|1974-10-18 00:00:00|violet|       1|\n",
      "|  7| Driscoll|   Klein|1970-10-05 00:00:00|  blue|       5|\n",
      "|  8|    Karyn|    Diaz|1969-02-24 00:00:00|   red|       1|\n",
      "|  9|  Merritt|     Guy|1974-10-17 00:00:00|indigo|       4|\n",
      "| 10|    Kylan|  Sexton|1975-02-28 00:00:00| black|       4|\n",
      "| 11|   Jordan|   Estes|1969-12-07 00:00:00|indigo|       4|\n",
      "| 12|     Hope|  Coffey|1973-12-24 00:00:00| green|       5|\n",
      "| 13|   Vivian|   Crane|1970-08-27 00:00:00|  gray|       5|\n",
      "| 14|     Clio|    Noel|1972-12-12 00:00:00|   red|       5|\n",
      "| 15|     Hope|   Silva|1970-07-01 00:00:00|  blue|       5|\n",
      "| 16|   Ayanna|  Jarvis|1974-02-11 00:00:00|orange|       5|\n",
      "| 17|   Chanda|   Boyer|1973-04-01 00:00:00| green|       4|\n",
      "| 18| Chadwick|  Knight|1973-04-29 00:00:00|yellow|       1|\n",
      "+---+---------+--------+-------------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Consultas\n",
    "#   Se crea una vista temporal\n",
    "#   que desaparece cuando se cierra la\n",
    "#   sesión actual de Spark\n",
    "#\n",
    "df.createOrReplaceTempView(\"peopleview\")  # este es el nombre de la tabla\n",
    "\n",
    "# Se realiza la consulta usando directamente SQL\n",
    "spark.sql(\"SELECT * FROM peopleview\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+-------------------+------+--------+\n",
      "| id|firstname| surname|          birthdate| color|quantity|\n",
      "+---+---------+--------+-------------------+------+--------+\n",
      "|  1|   Vivian|Hamilton|1971-07-08 00:00:00| green|       1|\n",
      "|  2|    Karen| Holcomb|1974-05-23 00:00:00| green|       4|\n",
      "|  3|     Cody| Garrett|1973-04-22 00:00:00|orange|       1|\n",
      "|  4|     Roth|     Fry|1975-01-29 00:00:00| black|       1|\n",
      "|  5|      Zoe|  Conway|1974-07-03 00:00:00|  blue|       2|\n",
      "|  6| Gretchen|  Kinney|1974-10-18 00:00:00|violet|       1|\n",
      "|  7| Driscoll|   Klein|1970-10-05 00:00:00|  blue|       5|\n",
      "|  8|    Karyn|    Diaz|1969-02-24 00:00:00|   red|       1|\n",
      "|  9|  Merritt|     Guy|1974-10-17 00:00:00|indigo|       4|\n",
      "| 10|    Kylan|  Sexton|1975-02-28 00:00:00| black|       4|\n",
      "| 11|   Jordan|   Estes|1969-12-07 00:00:00|indigo|       4|\n",
      "| 12|     Hope|  Coffey|1973-12-24 00:00:00| green|       5|\n",
      "| 13|   Vivian|   Crane|1970-08-27 00:00:00|  gray|       5|\n",
      "| 14|     Clio|    Noel|1972-12-12 00:00:00|   red|       5|\n",
      "| 15|     Hope|   Silva|1970-07-01 00:00:00|  blue|       5|\n",
      "| 16|   Ayanna|  Jarvis|1974-02-11 00:00:00|orange|       5|\n",
      "| 17|   Chanda|   Boyer|1973-04-01 00:00:00| green|       4|\n",
      "| 18| Chadwick|  Knight|1973-04-29 00:00:00|yellow|       1|\n",
      "+---+---------+--------+-------------------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# En el siguiente fragmento de código se\n",
    "# crea una vista temporal que existe entre\n",
    "# sesiones y solo desaparece cuando se cierra\n",
    "# la aplicación actual de Spark\n",
    "#\n",
    "df.createGlobalTempView(\"peopleview\")\n",
    "\n",
    "# percatese de la forma de nombrar la tabla\n",
    "# en la consulta SQL\n",
    "spark.sql(\"SELECT * FROM global_temp.peopleview\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|quantity|count|\n",
      "+--------+-----+\n",
      "|       1|    6|\n",
      "|       5|    6|\n",
      "|       4|    5|\n",
      "|       2|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Cuenta cuandos registros hay por cada valor en\n",
    "# la columna quantity\n",
    "#\n",
    "df.groupBy(\"quantity\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(quantity)=5)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# La función agg recibe un diccionario que indica\n",
    "# con que función (valor del diccionario) se agrega\n",
    "# una determinada columna (clave del diccionario)\n",
    "#\n",
    "df.agg({\"quantity\": \"max\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(quantity)=5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Tmabien pueden usarse las funciones implementadas\n",
    "# en el modulo sql de pyspark. En el siguiente ejemplo\n",
    "# se carga el módulo de funciones con el nombre de F.\n",
    "# Se obtiene el valor máximo de la columna quantity\n",
    "#\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.agg(F.max(df.quantity)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones implementadas en el módulo pyspark.sql.functions se encuentran documentadas en http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#module-pyspark.sql.functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escritura de un resultado al HDFS\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Los resultados se escriben al disco con write.save().\n",
    "# El parámetro es el nombre del directorio. La llamada a\n",
    "# la función crea el archivo _SUCCESS que indica que la\n",
    "# función se ejecutó correctamente, y los archivos\n",
    "# con el resultado.\n",
    "#\n",
    "df.filter(df[\"color\"] == \"blue\").write.save(\"/tmp/demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup          0 2019-11-15 00:45 /tmp/demo/_SUCCESS\n",
      "-rw-r--r--   1 root supergroup       1553 2019-11-15 00:45 /tmp/demo/part-00000-8ed4efa5-937d-4917-83a0-e3e4d3a0924a-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/demo/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución de SQL directamente sobre archivos\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL permite ejecutar directamente SQL sobre archivos indicando el tipo de archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---+--------+--------+\n",
      "| birthdate| color|firstname| id|quantity| surname|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "|1971-07-08| green|   Vivian|  1|       1|Hamilton|\n",
      "|1974-05-23| green|    Karen|  2|       4| Holcomb|\n",
      "|1973-04-22|orange|     Cody|  3|       1| Garrett|\n",
      "|1975-01-29| black|     Roth|  4|       1|     Fry|\n",
      "|1974-07-03|  blue|      Zoe|  5|       2|  Conway|\n",
      "|1974-10-18|violet| Gretchen|  6|       1|  Kinney|\n",
      "|1970-10-05|  blue| Driscoll|  7|       5|   Klein|\n",
      "|1969-02-24|   red|    Karyn|  8|       1|    Diaz|\n",
      "|1974-10-17|indigo|  Merritt|  9|       4|     Guy|\n",
      "|1975-02-28| black|    Kylan| 10|       4|  Sexton|\n",
      "|1969-12-07|indigo|   Jordan| 11|       4|   Estes|\n",
      "|1973-12-24| green|     Hope| 12|       5|  Coffey|\n",
      "|1970-08-27|  gray|   Vivian| 13|       5|   Crane|\n",
      "|1972-12-12|   red|     Clio| 14|       5|    Noel|\n",
      "|1970-07-01|  blue|     Hope| 15|       5|   Silva|\n",
      "|1974-02-11|orange|   Ayanna| 16|       5|  Jarvis|\n",
      "|1973-04-01| green|   Chanda| 17|       4|   Boyer|\n",
      "|1973-04-29|yellow| Chadwick| 18|       1|  Knight|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# SQL sobre un archivo en formato JSON. Note que\n",
    "# en lugar de la tabla se especifica el formato del\n",
    "# archivo (json) y entre comillas `` el nombre del\n",
    "# archivo.\n",
    "#\n",
    "spark.sql(\"SELECT * FROM json.`/tmp/people.json`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+----------+------+--------+\n",
      "|_c0|      _c1|     _c2|       _c3|   _c4|     _c5|\n",
      "+---+---------+--------+----------+------+--------+\n",
      "| id|firstname| surname| birthdate| color|quantity|\n",
      "|  1|   Vivian|Hamilton|1971-07-08| green|       1|\n",
      "|  2|    Karen| Holcomb|1974-05-23| green|       4|\n",
      "|  3|     Cody| Garrett|1973-04-22|orange|       1|\n",
      "|  4|     Roth|     Fry|1975-01-29| black|       1|\n",
      "|  5|      Zoe|  Conway|1974-07-03|  blue|       2|\n",
      "|  6| Gretchen|  Kinney|1974-10-18|violet|       1|\n",
      "|  7| Driscoll|   Klein|1970-10-05|  blue|       5|\n",
      "|  8|    Karyn|    Diaz|1969-02-24|   red|       1|\n",
      "|  9|  Merritt|     Guy|1974-10-17|indigo|       4|\n",
      "| 10|    Kylan|  Sexton|1975-02-28| black|       4|\n",
      "| 11|   Jordan|   Estes|1969-12-07|indigo|       4|\n",
      "| 12|     Hope|  Coffey|1973-12-24| green|       5|\n",
      "| 13|   Vivian|   Crane|1970-08-27|  gray|       5|\n",
      "| 14|     Clio|    Noel|1972-12-12|   red|       5|\n",
      "| 15|     Hope|   Silva|1970-07-01|  blue|       5|\n",
      "| 16|   Ayanna|  Jarvis|1974-02-11|orange|       5|\n",
      "| 17|   Chanda|   Boyer|1973-04-01| green|       4|\n",
      "| 18| Chadwick|  Knight|1973-04-29|yellow|       1|\n",
      "+---+---------+--------+----------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# SQL sobre un archivo en formato CSV. Note que en este\n",
    "# caso, los nombres de las columnas se leen como parte\n",
    "# de la tabla.\n",
    "#\n",
    "spark.sql(\"SELECT * FROM csv.`/tmp/people.csv`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   _c4|\n",
      "+------+\n",
      "|violet|\n",
      "|orange|\n",
      "| green|\n",
      "|yellow|\n",
      "|indigo|\n",
      "|  gray|\n",
      "|   red|\n",
      "| color|\n",
      "| black|\n",
      "|  blue|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL sobre un archivo en formato CSV\n",
    "spark.sql(\"SELECT DISTINCT(_c4)  FROM csv.`/tmp/people.csv`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes ejemplos son realizados usando el archivo `people.json` creado al principio de este tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/tmp/people.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo 1\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccione las personas cuya fecha de nacimiento sea del año 1974 en adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---+--------+-------+\n",
      "| birthdate| color|firstname| id|quantity|surname|\n",
      "+----------+------+---------+---+--------+-------+\n",
      "|1974-05-23| green|    Karen|  2|       4|Holcomb|\n",
      "|1975-01-29| black|     Roth|  4|       1|    Fry|\n",
      "|1974-07-03|  blue|      Zoe|  5|       2| Conway|\n",
      "|1974-10-18|violet| Gretchen|  6|       1| Kinney|\n",
      "|1974-10-17|indigo|  Merritt|  9|       4|    Guy|\n",
      "|1975-02-28| black|    Kylan| 10|       4| Sexton|\n",
      "|1974-02-11|orange|   Ayanna| 16|       5| Jarvis|\n",
      "+----------+------+---------+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se usa la función filter() del DataFrame\n",
    "#\n",
    "df.filter(df[\"birthdate\"] >= \"1974\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---+--------+-------+\n",
      "| birthdate| color|firstname| id|quantity|surname|\n",
      "+----------+------+---------+---+--------+-------+\n",
      "|1974-05-23| green|    Karen|  2|       4|Holcomb|\n",
      "|1975-01-29| black|     Roth|  4|       1|    Fry|\n",
      "|1974-07-03|  blue|      Zoe|  5|       2| Conway|\n",
      "|1974-10-18|violet| Gretchen|  6|       1| Kinney|\n",
      "|1974-10-17|indigo|  Merritt|  9|       4|    Guy|\n",
      "|1975-02-28| black|    Kylan| 10|       4| Sexton|\n",
      "|1974-02-11|orange|   Ayanna| 16|       5| Jarvis|\n",
      "+----------+------+---------+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se crea una vista temporal para ejecutar\n",
    "# una consulta SQL sobre ella\n",
    "#\n",
    "df.createOrReplaceTempView(\"peopleview\")\n",
    "spark.sql(\"SELECT * FROM peopleview WHERE YEAR(birthdate) >= 1974\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo 2\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenga una lista de colores únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| color|\n",
      "+------+\n",
      "|violet|\n",
      "|orange|\n",
      "| green|\n",
      "|yellow|\n",
      "|indigo|\n",
      "|  gray|\n",
      "|   red|\n",
      "| black|\n",
      "|  blue|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se usa la función distinct() del DataFrame\n",
    "#\n",
    "df.select(\"color\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| color|\n",
      "+------+\n",
      "|violet|\n",
      "|orange|\n",
      "| green|\n",
      "|yellow|\n",
      "|indigo|\n",
      "|  gray|\n",
      "|   red|\n",
      "| black|\n",
      "|  blue|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Como una consulta\n",
    "#\n",
    "spark.sql(\"SELECT DISTINCT(color) FROM peopleview\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Ejemplo 3\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Ordene la tabla por cantidad y luego por color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---+--------+--------+\n",
      "| birthdate| color|firstname| id|quantity| surname|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "|1969-02-24|   red|    Karyn|  8|       1|    Diaz|\n",
      "|1973-04-29|yellow| Chadwick| 18|       1|  Knight|\n",
      "|1971-07-08| green|   Vivian|  1|       1|Hamilton|\n",
      "|1975-01-29| black|     Roth|  4|       1|     Fry|\n",
      "|1974-10-18|violet| Gretchen|  6|       1|  Kinney|\n",
      "|1973-04-22|orange|     Cody|  3|       1| Garrett|\n",
      "|1974-07-03|  blue|      Zoe|  5|       2|  Conway|\n",
      "|1975-02-28| black|    Kylan| 10|       4|  Sexton|\n",
      "|1973-04-01| green|   Chanda| 17|       4|   Boyer|\n",
      "|1974-10-17|indigo|  Merritt|  9|       4|     Guy|\n",
      "|1969-12-07|indigo|   Jordan| 11|       4|   Estes|\n",
      "|1974-05-23| green|    Karen|  2|       4| Holcomb|\n",
      "|1970-10-05|  blue| Driscoll|  7|       5|   Klein|\n",
      "|1972-12-12|   red|     Clio| 14|       5|    Noel|\n",
      "|1973-12-24| green|     Hope| 12|       5|  Coffey|\n",
      "|1970-07-01|  blue|     Hope| 15|       5|   Silva|\n",
      "|1970-08-27|  gray|   Vivian| 13|       5|   Crane|\n",
      "|1974-02-11|orange|   Ayanna| 16|       5|  Jarvis|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Note que las funciones se aplican de derecha\n",
    "# a izquierda\n",
    "#\n",
    "df.orderBy(\"color\").orderBy(\"quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---+--------+--------+\n",
      "| birthdate| color|firstname| id|quantity| surname|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "|1975-01-29| black|     Roth|  4|       1|     Fry|\n",
      "|1971-07-08| green|   Vivian|  1|       1|Hamilton|\n",
      "|1973-04-22|orange|     Cody|  3|       1| Garrett|\n",
      "|1969-02-24|   red|    Karyn|  8|       1|    Diaz|\n",
      "|1974-10-18|violet| Gretchen|  6|       1|  Kinney|\n",
      "|1973-04-29|yellow| Chadwick| 18|       1|  Knight|\n",
      "|1974-07-03|  blue|      Zoe|  5|       2|  Conway|\n",
      "|1975-02-28| black|    Kylan| 10|       4|  Sexton|\n",
      "|1973-04-01| green|   Chanda| 17|       4|   Boyer|\n",
      "|1974-05-23| green|    Karen|  2|       4| Holcomb|\n",
      "|1969-12-07|indigo|   Jordan| 11|       4|   Estes|\n",
      "|1974-10-17|indigo|  Merritt|  9|       4|     Guy|\n",
      "|1970-10-05|  blue| Driscoll|  7|       5|   Klein|\n",
      "|1970-07-01|  blue|     Hope| 15|       5|   Silva|\n",
      "|1970-08-27|  gray|   Vivian| 13|       5|   Crane|\n",
      "|1973-12-24| green|     Hope| 12|       5|  Coffey|\n",
      "|1974-02-11|orange|   Ayanna| 16|       5|  Jarvis|\n",
      "|1972-12-12|   red|     Clio| 14|       5|    Noel|\n",
      "+----------+------+---------+---+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Como una consulta de SQL\n",
    "#\n",
    "spark.sql(\"SELECT * FROM peopleview ORDER BY quantity, color\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza del directorio de trabajo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm people.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/people.csv\n",
      "Deleted /tmp/people.json\n",
      "Deleted /tmp/demo\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm /tmp/people*\n",
    "!hdfs dfs -rm -r -f /tmp/demo/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
