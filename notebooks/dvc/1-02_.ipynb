{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de78ef42-2bb8-4a1d-9fc1-0263dd5e2fe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "(Opcional) Paso 2: Data Pipelines en DVC\n",
    "===\n",
    "\n",
    "* Ultima modificación: Abril 4, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4669d-583d-4d8a-824b-cd1810161a20",
   "metadata": {},
   "source": [
    "**Este es un proyecto que desarrolla en varios pasos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ca005-9303-493a-bc76-2187b92c2f3d",
   "metadata": {},
   "source": [
    "**No funciona a gran escala, pero este es un buen ejemplo de pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce08dafd-5023-49bc-989d-ccf94936ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/dvcdemo\n"
     ]
    }
   ],
   "source": [
    "%cd dvcdemo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96d147-6a3d-4b0e-b4b0-41825226fa3e",
   "metadata": {},
   "source": [
    "Descarga del proyecto\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7043d12-d050-4fe8-821b-8f70f2bdbc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-07 16:40:57--  https://code.dvc.org/get-started/code.zip\n",
      "Resolving code.dvc.org (code.dvc.org)... 104.21.81.205, 172.67.164.76, 2606:4700:3036::6815:51cd, ...\n",
      "Connecting to code.dvc.org (code.dvc.org)|104.21.81.205|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://s3-us-east-2.amazonaws.com/dvc-public/code/get-started/code.zip [following]\n",
      "--2022-06-07 16:40:59--  https://s3-us-east-2.amazonaws.com/dvc-public/code/get-started/code.zip\n",
      "Resolving s3-us-east-2.amazonaws.com (s3-us-east-2.amazonaws.com)... 52.219.103.65\n",
      "Connecting to s3-us-east-2.amazonaws.com (s3-us-east-2.amazonaws.com)|52.219.103.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5800 (5.7K) [application/zip]\n",
      "Saving to: ‘code.zip’\n",
      "\n",
      "code.zip            100%[===================>]   5.66K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-06-07 16:41:02 (93.3 KB/s) - ‘code.zip’ saved [5800/5800]\n",
      "\n",
      "Archive:  code.zip\n",
      "  inflating: params.yaml             \n",
      "  inflating: src/evaluate.py         \n",
      "  inflating: src/featurization.py    \n",
      "  inflating: src/prepare.py          \n",
      "  inflating: src/requirements.txt    \n",
      "  inflating: src/train.py            \n",
      "   creating: .github/workflows/\n",
      "  inflating: .github/workflows/cml.yaml  \n",
      "  inflating: .devcontainer/Dockerfile  \n",
      "  inflating: .devcontainer/devcontainer.json  \n"
     ]
    }
   ],
   "source": [
    "!wget https://code.dvc.org/get-started/code.zip\n",
    "!unzip code.zip\n",
    "!rm -f code.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd1d4c7-463b-4785-85ad-9da98db4e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet -r  src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cf99a-e3f3-4746-a993-50d199802033",
   "metadata": {
    "tags": []
   },
   "source": [
    "Stage prepare\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea86c284-4489-4627-be13-32969e14c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 'dvc.yaml'                                                   core\u001b[39m>\n",
      "Adding stage 'prepare' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add data/.gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"\n",
    "dvc stage add -n prepare \\\n",
    "              -p prepare.seed,prepare.split \\\n",
    "              -d src/prepare.py \\\n",
    "              -d data/data.xml \\\n",
    "              -o data/prepared \\\n",
    "               python3 src/prepare.py data/data.xml\n",
    "\"\"\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9447d25d-169f-4fab-9e17-69a9fd1d83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - data/data.xml\n",
      "    - src/prepare.py\n",
      "    params:\n",
      "    - prepare.seed\n",
      "    - prepare.split\n",
      "    outs:\n",
      "    - data/prepared\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22e380-3b76-441e-b701-3e4cd824ce08",
   "metadata": {},
   "source": [
    "src/prepare.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60758b76-b61a-496e-8f91-53c99c7fba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mre\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxml\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36metree\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mElementTree\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36myaml\u001b[39;49;00m\n",
      "\n",
      "params = yaml.safe_load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))[\u001b[33m\"\u001b[39;49;00m\u001b[33mprepare\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m2\u001b[39;49;00m:\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments error. Usage:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mpython prepare.py data-file\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.exit(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m# Test data set split ratio\u001b[39;49;00m\n",
      "split = params[\u001b[33m\"\u001b[39;49;00m\u001b[33msplit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "random.seed(params[\u001b[33m\"\u001b[39;49;00m\u001b[33mseed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "\u001b[36minput\u001b[39;49;00m = sys.argv[\u001b[34m1\u001b[39;49;00m]\n",
      "output_train = os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mprepared\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "output_test = os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mprepared\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtest.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mprocess_posts\u001b[39;49;00m(fd_in, fd_out_train, fd_out_test, target_tag):\n",
      "    num = \u001b[34m1\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m line \u001b[35min\u001b[39;49;00m fd_in:\n",
      "        \u001b[34mtry\u001b[39;49;00m:\n",
      "            fd_out = fd_out_train \u001b[34mif\u001b[39;49;00m random.random() > split \u001b[34melse\u001b[39;49;00m fd_out_test\n",
      "            attr = xml.etree.ElementTree.fromstring(line).attrib\n",
      "\n",
      "            pid = attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mId\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            label = \u001b[34m1\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m target_tag \u001b[35min\u001b[39;49;00m attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mTags\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34melse\u001b[39;49;00m \u001b[34m0\u001b[39;49;00m\n",
      "            title = re.sub(\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33ms+\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mTitle\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)).strip()\n",
      "            body = re.sub(\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33ms+\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)).strip()\n",
      "            text = title + \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + body\n",
      "\n",
      "            fd_out.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(pid, label, text))\n",
      "\n",
      "            num += \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m ex:\n",
      "            sys.stderr.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mSkipping the broken line \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnum\u001b[33m}\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mex\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "os.makedirs(os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mprepared\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), exist_ok=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m io.open(\u001b[36minput\u001b[39;49;00m, encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd_in:\n",
      "    \u001b[34mwith\u001b[39;49;00m io.open(output_train, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd_out_train:\n",
      "        \u001b[34mwith\u001b[39;49;00m io.open(output_test, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd_out_test:\n",
      "            process_posts(fd_in, fd_out_train, fd_out_test, \u001b[33m\"\u001b[39;49;00m\u001b[33m<r>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40e0be-aad8-41d1-9a08-a435ed28a043",
   "metadata": {},
   "source": [
    "Stage featurize\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f567ecf7-9dbb-4990-abfa-55441b00a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding stage 'featurize' in 'dvc.yaml'                                core\u001b[39m>\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add data/.gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"\n",
    "dvc stage add -n featurize \\\n",
    "              -p featurize.max_features,featurize.ngrams \\\n",
    "              -d src/featurization.py \\\n",
    "              -d data/prepared \\\n",
    "              -o data/features \\\n",
    "              python3 src/featurization.py data/prepared data/features\n",
    "\"\"\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d0e57b-a197-4a5d-aa90-6e322a4f4abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - data/data.xml\n",
      "    - src/prepare.py\n",
      "    params:\n",
      "    - prepare.seed\n",
      "    - prepare.split\n",
      "    outs:\n",
      "    - data/prepared\n",
      "  featurize:\n",
      "    cmd: python3 src/featurization.py data/prepared data/features\n",
      "    deps:\n",
      "    - data/prepared\n",
      "    - src/featurization.py\n",
      "    params:\n",
      "    - featurize.max_features\n",
      "    - featurize.ngrams\n",
      "    outs:\n",
      "    - data/features\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ff022-7a6b-40b0-ab8a-1003bbdfbf65",
   "metadata": {},
   "source": [
    "src/featurization.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd25d158-b898-437d-b093-124bd0ac06c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mscipy\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msparse\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36msparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36myaml\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CountVectorizer, TfidfTransformer\n",
      "\n",
      "params = yaml.safe_load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))[\u001b[33m\"\u001b[39;49;00m\u001b[33mfeaturize\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "np.set_printoptions(suppress=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m3\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m5\u001b[39;49;00m:\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments error. Usage:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mpython featurization.py data-dir-path features-dir-path\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.exit(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "train_input = os.path.join(sys.argv[\u001b[34m1\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "test_input = os.path.join(sys.argv[\u001b[34m1\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtest.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "train_output = os.path.join(sys.argv[\u001b[34m2\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "test_output = os.path.join(sys.argv[\u001b[34m2\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtest.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "max_features = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_features\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "ngrams = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mngrams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_df\u001b[39;49;00m(data):\n",
      "    df = pd.read_csv(\n",
      "        data,\n",
      "        encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        header=\u001b[34mNone\u001b[39;49;00m,\n",
      "        delimiter=\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        names=[\u001b[33m\"\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "    )\n",
      "    sys.stderr.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mThe input data frame \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdata\u001b[33m}\u001b[39;49;00m\u001b[33m size is \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdf.shape\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m df\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_matrix\u001b[39;49;00m(df, matrix, names, output):\n",
      "    id_matrix = sparse.csr_matrix(df.id.astype(np.int64)).T\n",
      "    label_matrix = sparse.csr_matrix(df.label.astype(np.int64)).T\n",
      "\n",
      "    result = sparse.hstack([id_matrix, label_matrix, matrix], \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33mcsr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    msg = \u001b[33m\"\u001b[39;49;00m\u001b[33mThe output matrix \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m size is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m and data type is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    sys.stderr.write(msg.format(output, result.shape, result.dtype))\n",
      "\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(output, \u001b[33m\"\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd:\n",
      "        pickle.dump((result, names), fd)\n",
      "    \u001b[34mpass\u001b[39;49;00m\n",
      "\n",
      "\n",
      "os.makedirs(sys.argv[\u001b[34m2\u001b[39;49;00m], exist_ok=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m# Generate train feature matrix\u001b[39;49;00m\n",
      "df_train = get_df(train_input)\n",
      "train_words = np.array(df_train.text.str.lower().values.astype(\u001b[33m\"\u001b[39;49;00m\u001b[33mU\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "\n",
      "bag_of_words = CountVectorizer(\n",
      "    stop_words=\u001b[33m\"\u001b[39;49;00m\u001b[33menglish\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_features=max_features, ngram_range=(\u001b[34m1\u001b[39;49;00m, ngrams)\n",
      ")\n",
      "\n",
      "bag_of_words.fit(train_words)\n",
      "train_words_binary_matrix = bag_of_words.transform(train_words)\n",
      "feature_names = bag_of_words.get_feature_names_out()\n",
      "tfidf = TfidfTransformer(smooth_idf=\u001b[34mFalse\u001b[39;49;00m)\n",
      "tfidf.fit(train_words_binary_matrix)\n",
      "train_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n",
      "\n",
      "save_matrix(df_train, train_words_tfidf_matrix, feature_names, train_output)\n",
      "\n",
      "\u001b[37m# Generate test feature matrix\u001b[39;49;00m\n",
      "df_test = get_df(test_input)\n",
      "test_words = np.array(df_test.text.str.lower().values.astype(\u001b[33m\"\u001b[39;49;00m\u001b[33mU\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "test_words_binary_matrix = bag_of_words.transform(test_words)\n",
      "test_words_tfidf_matrix = tfidf.transform(test_words_binary_matrix)\n",
      "\n",
      "save_matrix(df_test, test_words_tfidf_matrix, feature_names, test_output)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/featurization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31158c1b-da18-48c3-87f5-c81c3e962ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Stage train\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e26e428-fb58-46ad-b7be-2ed55d83b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding stage 'train' in 'dvc.yaml'                                    core\u001b[39m>\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add .gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"\n",
    "dvc stage add -n train \\\n",
    "              -p train.seed,train.n_est,train.min_split \\\n",
    "              -d src/train.py \\\n",
    "              -d data/features \\\n",
    "              -o model.pkl \\\n",
    "              python3 src/train.py data/features model.pkl\n",
    "\"\"\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacc9626-15d2-47a7-a7f0-b3b55597190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - data/data.xml\n",
      "    - src/prepare.py\n",
      "    params:\n",
      "    - prepare.seed\n",
      "    - prepare.split\n",
      "    outs:\n",
      "    - data/prepared\n",
      "  featurize:\n",
      "    cmd: python3 src/featurization.py data/prepared data/features\n",
      "    deps:\n",
      "    - data/prepared\n",
      "    - src/featurization.py\n",
      "    params:\n",
      "    - featurize.max_features\n",
      "    - featurize.ngrams\n",
      "    outs:\n",
      "    - data/features\n",
      "  train:\n",
      "    cmd: python3 src/train.py data/features model.pkl\n",
      "    deps:\n",
      "    - data/features\n",
      "    - src/train.py\n",
      "    params:\n",
      "    - train.min_split\n",
      "    - train.n_est\n",
      "    - train.seed\n",
      "    outs:\n",
      "    - model.pkl\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3294a-8dd7-4bb8-85ed-0dd4092f1717",
   "metadata": {},
   "source": [
    "src/train.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1febdaf-2a81-4c80-bcfc-916222b933d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36myaml\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mensemble\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RandomForestClassifier\n",
      "\n",
      "params = yaml.safe_load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))[\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m3\u001b[39;49;00m:\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments error. Usage:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mpython train.py features model\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.exit(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\u001b[36minput\u001b[39;49;00m = sys.argv[\u001b[34m1\u001b[39;49;00m]\n",
      "output = sys.argv[\u001b[34m2\u001b[39;49;00m]\n",
      "seed = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mseed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "n_est = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_est\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "min_split = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mmin_split\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(\u001b[36minput\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd:\n",
      "    matrix, _ = pickle.load(fd)\n",
      "\n",
      "labels = np.squeeze(matrix[:, \u001b[34m1\u001b[39;49;00m].toarray())\n",
      "x = matrix[:, \u001b[34m2\u001b[39;49;00m:]\n",
      "\n",
      "sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mInput matrix size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(matrix.shape))\n",
      "sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mX matrix size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x.shape))\n",
      "sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mY matrix size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(labels.shape))\n",
      "\n",
      "clf = RandomForestClassifier(\n",
      "    n_estimators=n_est, min_samples_split=min_split, n_jobs=\u001b[34m2\u001b[39;49;00m, random_state=seed\n",
      ")\n",
      "\n",
      "clf.fit(x, labels)\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(output, \u001b[33m\"\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd:\n",
      "    pickle.dump(clf, fd)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240c691-cad1-4f75-a4d5-72beb551b8bf",
   "metadata": {},
   "source": [
    "Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c50c702-fa95-478b-a395-597cb9d4cb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR\u001b[39m: unexpected error - [Errno 17] File exists: 'data/data.xml'\n",
      "\n",
      "\u001b[33mHaving any troubles?\u001b[39m Hit us up at \u001b[34mhttps://dvc.org/support\u001b[39m, we are always happy to help!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Descarga los datos desde el repositorio de ejemplo de dvc\n",
    "#\n",
    "repo = \"https://github.com/iterative/dataset-registry\"\n",
    "src = \"get-started/data.xml\"\n",
    "dst = \"data/data.xml\"\n",
    "\n",
    "!dvc get {repo} {src} -o {dst}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a209f-21e3-44e3-995c-52a35bdc359f",
   "metadata": {},
   "source": [
    "Reproducción\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f472b0f-f551-4bf3-8827-bb8d0e29867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/dvcdemo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "574366c1-f557-446f-b988-ee85ca868814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying data sources in stage: 'data/data.xml.dvc'                  core\u001b[39m>\n",
      "                                                                                \n",
      "Running stage 'prepare':\n",
      "> python3 src/prepare.py data/data.xml\n",
      "  0% Transferring|                                   |0/3 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "  0%|          |e72f304d64c28867d884e798568460.dir 0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |e72f304d64c28867d884e798568460.di0.00/137 [00:00<?,        ?B/s]\u001b[A\n",
      "Generating lock file 'dvc.lock'                                                 \u001b[A\n",
      "Updating lock file 'dvc.lock'\n",
      "\n",
      "Running stage 'featurize':\n",
      "> python3 src/featurization.py data/prepared data/features\n",
      "The input data frame data/prepared/train.tsv size is (16011, 3)\n",
      "The output matrix data/features/train.pkl size is (16011, 102) and data type is float64\n",
      "The input data frame data/prepared/test.tsv size is (3989, 3)\n",
      "The output matrix data/features/test.pkl size is (3989, 102) and data type is float64\n",
      "  0% Transferring|                                   |0/3 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "  0%|          |28c4afe2ae56365ae96716fff987a5.dir 0.00/? [00:00<?,        ?B/s]\u001b[A\n",
      "  0%|          |28c4afe2ae56365ae96716fff987a5.di0.00/137 [00:00<?,        ?B/s]\u001b[A\n",
      "Updating lock file 'dvc.lock'                                                   \u001b[A\n",
      "\n",
      "Running stage 'train':\n",
      "> python3 src/train.py data/features model.pkl\n",
      "Input matrix size (16011, 102)\n",
      "X matrix size (16011, 100)\n",
      "Y matrix size (16011,)\n",
      "Updating lock file 'dvc.lock'                                                   \n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add data/data.xml.dvc dvc.lock\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "Use `dvc push` to send your updates to remote storage.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55d167c-c08a-49e5-b811-c2083c7daf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema: '2.0'\n",
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - path: data/data.xml\n",
      "      md5: 079fbd15fa2c32c539c4c4e3675b514a\n",
      "      size: 28890194\n",
      "    - path: src/prepare.py\n",
      "      md5: f09ea0c15980b43010257ccb9f0055e2\n",
      "      size: 1576\n",
      "    params:\n",
      "      params.yaml:\n",
      "        prepare.seed: 20170428\n",
      "        prepare.split: 0.2\n",
      "    outs:\n",
      "    - path: data/prepared\n",
      "      md5: 2fe72f304d64c28867d884e798568460.dir\n",
      "      size: 16874726\n",
      "      nfiles: 2\n",
      "  featurize:\n",
      "    cmd: python3 src/featurization.py data/prepared data/features\n",
      "    deps:\n",
      "    - path: data/prepared\n",
      "      md5: 2fe72f304d64c28867d884e798568460.dir\n",
      "      size: 16874726\n",
      "      nfiles: 2\n",
      "    - path: src/featurization.py\n",
      "      md5: e0265fc22f056a4b86d85c3056bc2894\n",
      "      size: 2490\n",
      "    params:\n",
      "      params.yaml:\n",
      "        featurize.max_features: 100\n",
      "        featurize.ngrams: 1\n",
      "    outs:\n",
      "    - path: data/features\n",
      "      md5: 1e28c4afe2ae56365ae96716fff987a5.dir\n",
      "      size: 3122242\n",
      "      nfiles: 2\n",
      "  train:\n",
      "    cmd: python3 src/train.py data/features model.pkl\n",
      "    deps:\n",
      "    - path: data/features\n",
      "      md5: 1e28c4afe2ae56365ae96716fff987a5.dir\n",
      "      size: 3122242\n",
      "      nfiles: 2\n",
      "    - path: src/train.py\n",
      "      md5: c3961d777cfbd7727f9fde4851896006\n",
      "      size: 967\n",
      "    params:\n",
      "      params.yaml:\n",
      "        train.min_split: 0.01\n",
      "        train.n_est: 50\n",
      "        train.seed: 20170428\n",
      "    outs:\n",
      "    - path: model.pkl\n",
      "      md5: b1a7524da7b6b2552b6f3e402ac6aa77\n",
      "      size: 1873894\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb6944-7db1-407c-bdee-067d9c4b52ba",
   "metadata": {},
   "source": [
    "Visualización\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7c991e3-126b-4fd3-a7e4-5f6128c29e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+  \n",
      "| data/data.xml.dvc |  \n",
      "+-------------------+  \n",
      "          *            \n",
      "          *            \n",
      "          *            \n",
      "     +---------+       \n",
      "     | prepare |       \n",
      "     +---------+       \n",
      "          *            \n",
      "          *            \n",
      "          *            \n",
      "    +-----------+      \n",
      "    | featurize |      \n",
      "    +-----------+      \n",
      "          *            \n",
      "          *            \n",
      "          *            \n",
      "      +-------+        \n",
      "      | train |        \n",
      "      +-------+        \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc dag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
