{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de78ef42-2bb8-4a1d-9fc1-0263dd5e2fe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Data Pipelines en DVC --- 0:00 min\n",
    "===\n",
    "\n",
    "* 0:00 min | Ultima modificación: Abril 4, 2022 | YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ca005-9303-493a-bc76-2187b92c2f3d",
   "metadata": {},
   "source": [
    "**No funciona a gran escala, pero este es un buen ejemplo de pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50690e86-cae1-4ede-a46d-ecca541ec8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Limpieza del área de trabajo\n",
    "#\n",
    "!rm -rf /tmp/pipeline /tmp/dvcstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2d974-017f-49ee-a55a-a91c7bbacb0f",
   "metadata": {},
   "source": [
    "Creación de una carpeta temporal para el demo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae17353-4f61-46ec-823a-d94a5eb2b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/pipeline\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tmp/pipeline\n",
    "!mkdir /tmp/pipeline/data\n",
    "%cd /tmp/pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85a4e8-426b-42ca-bb01-d4c3ab7ef38f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Inicializacion de git\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde1bf4e-6326-42fe-8066-b19b2fcc4795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in /tmp/pipeline/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!git config user.email jdvelasq@unal.edu.co\n",
    "!git config user.name jdvelasq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0b23f-7257-41f3-a575-9de12ce33c07",
   "metadata": {},
   "source": [
    "Inicialización de DVC\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52856bee-56f9-48c5-97f4-a9768b6d9228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1760d80-ec72-465a-89bb-86ecb4e8524b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Descarga del proyecto ejemplo de DVC\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113e47fa-4a0f-461e-9731-232459298516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-23 03:44:30--  https://code.dvc.org/get-started/code.zip\n",
      "Resolving code.dvc.org (code.dvc.org)... 172.67.164.76, 104.21.81.205, 2606:4700:3033::ac43:a44c, ...\n",
      "Connecting to code.dvc.org (code.dvc.org)|172.67.164.76|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://s3-us-east-2.amazonaws.com/dvc-public/code/get-started/code.zip [following]\n",
      "--2022-04-23 03:44:31--  https://s3-us-east-2.amazonaws.com/dvc-public/code/get-started/code.zip\n",
      "Resolving s3-us-east-2.amazonaws.com (s3-us-east-2.amazonaws.com)... 52.219.99.65\n",
      "Connecting to s3-us-east-2.amazonaws.com (s3-us-east-2.amazonaws.com)|52.219.99.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5405 (5.3K) [application/zip]\n",
      "Saving to: ‘code.zip’\n",
      "\n",
      "code.zip            100%[===================>]   5.28K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-04-23 03:44:31 (206 MB/s) - ‘code.zip’ saved [5405/5405]\n",
      "\n",
      "Archive:  code.zip\n",
      "  inflating: params.yaml             \n",
      "  inflating: src/evaluate.py         \n",
      "  inflating: src/featurization.py    \n",
      "  inflating: src/prepare.py          \n",
      "  inflating: src/requirements.txt    \n",
      "  inflating: src/train.py            \n",
      "   creating: .github/workflows/\n",
      "  inflating: .github/workflows/cml.yaml  \n",
      "  inflating: .devcontainer/Dockerfile  \n",
      "  inflating: .devcontainer/devcontainer.json  \n",
      "data\n",
      "params.yaml\n",
      "src\n"
     ]
    }
   ],
   "source": [
    "!wget https://code.dvc.org/get-started/code.zip\n",
    "!unzip code.zip\n",
    "!rm -f code.zip\n",
    "!ls -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95faa64-5f51-4c88-bb3d-656b30b63df9",
   "metadata": {},
   "source": [
    "Instalación paquetes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a6dab6-fbd1-4fd1-b161-1837b94e3cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n",
      "pyaml\n",
      "scikit-learn\n",
      "scipy\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install --quiet -r src/requirements.txt\n",
    "!cat src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cf99a-e3f3-4746-a993-50d199802033",
   "metadata": {
    "tags": []
   },
   "source": [
    "Stage prepare\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea86c284-4489-4627-be13-32969e14c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 'dvc.yaml'                                                   core\u001b[39m>\n",
      "Adding stage 'prepare' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add data/.gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"\n",
    "dvc stage add -n prepare \\\n",
    "              -p prepare.seed,prepare.split \\\n",
    "              -d src/prepare.py \\\n",
    "              -d data/data.xml \\\n",
    "              -o data/prepared \\\n",
    "               python3 src/prepare.py data/data.xml\n",
    "\"\"\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9447d25d-169f-4fab-9e17-69a9fd1d83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - data/data.xml\n",
      "    - src/prepare.py\n",
      "    params:\n",
      "    - prepare.seed\n",
      "    - prepare.split\n",
      "    outs:\n",
      "    - data/prepared\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22e380-3b76-441e-b701-3e4cd824ce08",
   "metadata": {},
   "source": [
    "src/prepare.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60758b76-b61a-496e-8f91-53c99c7fba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mrandom\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mre\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxml\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36metree\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mElementTree\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36myaml\u001b[39;49;00m\n",
      "\n",
      "params = yaml.safe_load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))[\u001b[33m\"\u001b[39;49;00m\u001b[33mprepare\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m2\u001b[39;49;00m:\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments error. Usage:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mpython prepare.py data-file\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.exit(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m# Test data set split ratio\u001b[39;49;00m\n",
      "split = params[\u001b[33m\"\u001b[39;49;00m\u001b[33msplit\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "random.seed(params[\u001b[33m\"\u001b[39;49;00m\u001b[33mseed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "\n",
      "\u001b[36minput\u001b[39;49;00m = sys.argv[\u001b[34m1\u001b[39;49;00m]\n",
      "output_train = os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mprepared\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "output_test = os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mprepared\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtest.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mprocess_posts\u001b[39;49;00m(fd_in, fd_out_train, fd_out_test, target_tag):\n",
      "    num = \u001b[34m1\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m line \u001b[35min\u001b[39;49;00m fd_in:\n",
      "        \u001b[34mtry\u001b[39;49;00m:\n",
      "            fd_out = fd_out_train \u001b[34mif\u001b[39;49;00m random.random() > split \u001b[34melse\u001b[39;49;00m fd_out_test\n",
      "            attr = xml.etree.ElementTree.fromstring(line).attrib\n",
      "\n",
      "            pid = attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mId\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            label = \u001b[34m1\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m target_tag \u001b[35min\u001b[39;49;00m attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mTags\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34melse\u001b[39;49;00m \u001b[34m0\u001b[39;49;00m\n",
      "            title = re.sub(\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33ms+\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mTitle\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)).strip()\n",
      "            body = re.sub(\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\\u001b[39;49;00m\u001b[33ms+\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, attr.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)).strip()\n",
      "            text = title + \u001b[33m\"\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + body\n",
      "\n",
      "            fd_out.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(pid, label, text))\n",
      "\n",
      "            num += \u001b[34m1\u001b[39;49;00m\n",
      "        \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m ex:\n",
      "            sys.stderr.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mSkipping the broken line \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mnum\u001b[33m}\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mex\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "os.makedirs(os.path.join(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mprepared\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), exist_ok=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m io.open(\u001b[36minput\u001b[39;49;00m, encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd_in:\n",
      "    \u001b[34mwith\u001b[39;49;00m io.open(output_train, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd_out_train:\n",
      "        \u001b[34mwith\u001b[39;49;00m io.open(output_test, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd_out_test:\n",
      "            process_posts(fd_in, fd_out_train, fd_out_test, \u001b[33m\"\u001b[39;49;00m\u001b[33m<python>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40e0be-aad8-41d1-9a08-a435ed28a043",
   "metadata": {},
   "source": [
    "Stage featurize\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f567ecf7-9dbb-4990-abfa-55441b00a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding stage 'featurize' in 'dvc.yaml'                                core\u001b[39m>\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add dvc.yaml data/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"\n",
    "dvc stage add -n featurize \\\n",
    "              -p featurize.max_features,featurize.ngrams \\\n",
    "              -d src/featurization.py \\\n",
    "              -d data/prepared \\\n",
    "              -o data/features \\\n",
    "              python3 src/featurization.py data/prepared data/features\n",
    "\"\"\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d0e57b-a197-4a5d-aa90-6e322a4f4abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - data/data.xml\n",
      "    - src/prepare.py\n",
      "    params:\n",
      "    - prepare.seed\n",
      "    - prepare.split\n",
      "    outs:\n",
      "    - data/prepared\n",
      "  featurize:\n",
      "    cmd: python3 src/featurization.py data/prepared data/features\n",
      "    deps:\n",
      "    - data/prepared\n",
      "    - src/featurization.py\n",
      "    params:\n",
      "    - featurize.max_features\n",
      "    - featurize.ngrams\n",
      "    outs:\n",
      "    - data/features\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ff022-7a6b-40b0-ab8a-1003bbdfbf65",
   "metadata": {},
   "source": [
    "src/featurization.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd25d158-b898-437d-b093-124bd0ac06c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mscipy\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msparse\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36msparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36myaml\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CountVectorizer, TfidfTransformer\n",
      "\n",
      "params = yaml.safe_load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))[\u001b[33m\"\u001b[39;49;00m\u001b[33mfeaturize\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "np.set_printoptions(suppress=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m3\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m5\u001b[39;49;00m:\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments error. Usage:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mpython featurization.py data-dir-path features-dir-path\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.exit(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "train_input = os.path.join(sys.argv[\u001b[34m1\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "test_input = os.path.join(sys.argv[\u001b[34m1\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtest.tsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "train_output = os.path.join(sys.argv[\u001b[34m2\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "test_output = os.path.join(sys.argv[\u001b[34m2\u001b[39;49;00m], \u001b[33m\"\u001b[39;49;00m\u001b[33mtest.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "max_features = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_features\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "ngrams = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mngrams\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_df\u001b[39;49;00m(data):\n",
      "    df = pd.read_csv(\n",
      "        data,\n",
      "        encoding=\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        header=\u001b[34mNone\u001b[39;49;00m,\n",
      "        delimiter=\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        names=[\u001b[33m\"\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "    )\n",
      "    sys.stderr.write(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mThe input data frame \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdata\u001b[33m}\u001b[39;49;00m\u001b[33m size is \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdf.shape\u001b[33m}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m df\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_matrix\u001b[39;49;00m(df, matrix, output):\n",
      "    id_matrix = sparse.csr_matrix(df.id.astype(np.int64)).T\n",
      "    label_matrix = sparse.csr_matrix(df.label.astype(np.int64)).T\n",
      "\n",
      "    result = sparse.hstack([id_matrix, label_matrix, matrix], \u001b[36mformat\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33mcsr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    msg = \u001b[33m\"\u001b[39;49;00m\u001b[33mThe output matrix \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m size is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m and data type is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    sys.stderr.write(msg.format(output, result.shape, result.dtype))\n",
      "\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(output, \u001b[33m\"\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd:\n",
      "        pickle.dump(result, fd)\n",
      "    \u001b[34mpass\u001b[39;49;00m\n",
      "\n",
      "\n",
      "os.makedirs(sys.argv[\u001b[34m2\u001b[39;49;00m], exist_ok=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "\u001b[37m# Generate train feature matrix\u001b[39;49;00m\n",
      "df_train = get_df(train_input)\n",
      "train_words = np.array(df_train.text.str.lower().values.astype(\u001b[33m\"\u001b[39;49;00m\u001b[33mU\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "\n",
      "bag_of_words = CountVectorizer(\n",
      "    stop_words=\u001b[33m\"\u001b[39;49;00m\u001b[33menglish\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, max_features=max_features, ngram_range=(\u001b[34m1\u001b[39;49;00m, ngrams)\n",
      ")\n",
      "\n",
      "bag_of_words.fit(train_words)\n",
      "train_words_binary_matrix = bag_of_words.transform(train_words)\n",
      "tfidf = TfidfTransformer(smooth_idf=\u001b[34mFalse\u001b[39;49;00m)\n",
      "tfidf.fit(train_words_binary_matrix)\n",
      "train_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n",
      "\n",
      "save_matrix(df_train, train_words_tfidf_matrix, train_output)\n",
      "\n",
      "\u001b[37m# Generate test feature matrix\u001b[39;49;00m\n",
      "df_test = get_df(test_input)\n",
      "test_words = np.array(df_test.text.str.lower().values.astype(\u001b[33m\"\u001b[39;49;00m\u001b[33mU\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "test_words_binary_matrix = bag_of_words.transform(test_words)\n",
      "test_words_tfidf_matrix = tfidf.transform(test_words_binary_matrix)\n",
      "\n",
      "save_matrix(df_test, test_words_tfidf_matrix, test_output)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/featurization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31158c1b-da18-48c3-87f5-c81c3e962ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Stage train\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e26e428-fb58-46ad-b7be-2ed55d83b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding stage 'train' in 'dvc.yaml'                                    core\u001b[39m>\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add .gitignore dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"\n",
    "dvc stage add -n train \\\n",
    "              -p train.seed,train.n_est,train.min_split \\\n",
    "              -d src/train.py \\\n",
    "              -d data/features \\\n",
    "              -o model.pkl \\\n",
    "              python3 src/train.py data/features model.pkl\n",
    "\"\"\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bacc9626-15d2-47a7-a7f0-b3b55597190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - data/data.xml\n",
      "    - src/prepare.py\n",
      "    params:\n",
      "    - prepare.seed\n",
      "    - prepare.split\n",
      "    outs:\n",
      "    - data/prepared\n",
      "  featurize:\n",
      "    cmd: python3 src/featurization.py data/prepared data/features\n",
      "    deps:\n",
      "    - data/prepared\n",
      "    - src/featurization.py\n",
      "    params:\n",
      "    - featurize.max_features\n",
      "    - featurize.ngrams\n",
      "    outs:\n",
      "    - data/features\n",
      "  train:\n",
      "    cmd: python3 src/train.py data/features model.pkl\n",
      "    deps:\n",
      "    - data/features\n",
      "    - src/train.py\n",
      "    params:\n",
      "    - train.min_split\n",
      "    - train.n_est\n",
      "    - train.seed\n",
      "    outs:\n",
      "    - model.pkl\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3294a-8dd7-4bb8-85ed-0dd4092f1717",
   "metadata": {},
   "source": [
    "src/train.py\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1febdaf-2a81-4c80-bcfc-916222b933d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36myaml\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mensemble\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RandomForestClassifier\n",
      "\n",
      "params = yaml.safe_load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mparams.yaml\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))[\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) != \u001b[34m3\u001b[39;49;00m:\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mArguments error. Usage:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mpython train.py features model\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    sys.exit(\u001b[34m1\u001b[39;49;00m)\n",
      "\n",
      "\u001b[36minput\u001b[39;49;00m = sys.argv[\u001b[34m1\u001b[39;49;00m]\n",
      "output = sys.argv[\u001b[34m2\u001b[39;49;00m]\n",
      "seed = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mseed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "n_est = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mn_est\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "min_split = params[\u001b[33m\"\u001b[39;49;00m\u001b[33mmin_split\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(\u001b[36minput\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd:\n",
      "    matrix = pickle.load(fd)\n",
      "\n",
      "labels = np.squeeze(matrix[:, \u001b[34m1\u001b[39;49;00m].toarray())\n",
      "x = matrix[:, \u001b[34m2\u001b[39;49;00m:]\n",
      "\n",
      "sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mInput matrix size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(matrix.shape))\n",
      "sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mX matrix size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(x.shape))\n",
      "sys.stderr.write(\u001b[33m\"\u001b[39;49;00m\u001b[33mY matrix size \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(labels.shape))\n",
      "\n",
      "clf = RandomForestClassifier(\n",
      "    n_estimators=n_est, min_samples_split=min_split, n_jobs=\u001b[34m2\u001b[39;49;00m, random_state=seed\n",
      ")\n",
      "\n",
      "clf.fit(x, labels)\n",
      "\n",
      "\u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(output, \u001b[33m\"\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m fd:\n",
      "    pickle.dump(clf, fd)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240c691-cad1-4f75-a4d5-72beb551b8bf",
   "metadata": {},
   "source": [
    "Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c50c702-fa95-478b-a395-597cb9d4cb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m                                                                            "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Descarga los datos desde el repositorio de ejemplo de dvc\n",
    "#\n",
    "repo = \"https://github.com/iterative/dataset-registry\"\n",
    "src = \"get-started/data.xml\"\n",
    "dst = \"data/data.xml\"\n",
    "\n",
    "!dvc get {repo} {src} -o {dst}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a209f-21e3-44e3-995c-52a35bdc359f",
   "metadata": {},
   "source": [
    "Reproducción\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "574366c1-f557-446f-b988-ee85ca868814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data frame data/prepared/train.tsv size is (20017, 3)\n",
      "The output matrix data/features/train.pkl size is (20017, 502) and data type is float64\n",
      "The input data frame data/prepared/test.tsv size is (4983, 3)\n",
      "The output matrix data/features/test.pkl size is (4983, 502) and data type is float64\n",
      "Input matrix size (20017, 502)\n",
      "X matrix size (20017, 500)\n",
      "Y matrix size (20017,)\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc repro --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55d167c-c08a-49e5-b811-c2083c7daf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema: '2.0'\n",
      "stages:\n",
      "  prepare:\n",
      "    cmd: python3 src/prepare.py data/data.xml\n",
      "    deps:\n",
      "    - path: data/data.xml\n",
      "      md5: a304afb96060aad90176268345e10355\n",
      "      size: 37891850\n",
      "    - path: src/prepare.py\n",
      "      md5: 51549a1c87b182ebdd785704f56ffaf1\n",
      "      size: 1581\n",
      "    params:\n",
      "      params.yaml:\n",
      "        prepare.seed: 20170428\n",
      "        prepare.split: 0.2\n",
      "    outs:\n",
      "    - path: data/prepared\n",
      "      md5: 20b786b6e6f80e2b3fcf17827ad18597.dir\n",
      "      size: 23861319\n",
      "      nfiles: 2\n",
      "  featurize:\n",
      "    cmd: python3 src/featurization.py data/prepared data/features\n",
      "    deps:\n",
      "    - path: data/prepared\n",
      "      md5: 20b786b6e6f80e2b3fcf17827ad18597.dir\n",
      "      size: 23861319\n",
      "      nfiles: 2\n",
      "    - path: src/featurization.py\n",
      "      md5: 61c592707fd1b33e27819c87cf93f80a\n",
      "      size: 2391\n",
      "    params:\n",
      "      params.yaml:\n",
      "        featurize.max_features: 500\n",
      "        featurize.ngrams: 1\n",
      "    outs:\n",
      "    - path: data/features\n",
      "      md5: b4d13e5525577c1e4cbd31eafd1623d0.dir\n",
      "      size: 7083901\n",
      "      nfiles: 2\n",
      "  train:\n",
      "    cmd: python3 src/train.py data/features model.pkl\n",
      "    deps:\n",
      "    - path: data/features\n",
      "      md5: b4d13e5525577c1e4cbd31eafd1623d0.dir\n",
      "      size: 7083901\n",
      "      nfiles: 2\n",
      "    - path: src/train.py\n",
      "      md5: 9ab95496b29b6ea3418bbf20b9fe3473\n",
      "      size: 964\n",
      "    params:\n",
      "      params.yaml:\n",
      "        train.min_split: 2\n",
      "        train.n_est: 50\n",
      "        train.seed: 20170428\n",
      "    outs:\n",
      "    - path: model.pkl\n",
      "      md5: d06b15b6838fbee027b49c132e30afae\n",
      "      size: 2658186\n"
     ]
    }
   ],
   "source": [
    "!cat dvc.lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb6944-7db1-407c-bdee-067d9c4b52ba",
   "metadata": {},
   "source": [
    "Visualización\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c991e3-126b-4fd3-a7e4-5f6128c29e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +---------+   \n",
      " | prepare |   \n",
      " +---------+   \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      "+-----------+  \n",
      "| featurize |  \n",
      "+-----------+  \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      "  +-------+    \n",
      "  | train |    \n",
      "  +-------+    \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc dag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
