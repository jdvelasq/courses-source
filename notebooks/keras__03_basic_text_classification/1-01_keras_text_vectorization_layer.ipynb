{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e5f765-9a55-4ce9-a6ee-8a542738a238",
   "metadata": {
    "tags": []
   },
   "source": [
    "Capas de preprocesamiento de texto --- 0:00 min\n",
    "===\n",
    "\n",
    "* Última modificación: Marzo 7, 2022 | YouTube\n",
    "\n",
    "* Adaptado de: https://keras.io/api/layers/preprocessing_layers/text/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578314f-ee1f-4d6c-a254-68db875e1713",
   "metadata": {
    "tags": []
   },
   "source": [
    "Importación de librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95746764-2b16-43b7-88f9-bd507af1bad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848005c-fb31-4495-b987-0ef2bfe98150",
   "metadata": {},
   "source": [
    "Capa TextVectorization\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a4ee6-c37c-4dbd-a126-5ee89b764a1c",
   "metadata": {},
   "source": [
    "* Estandarización: minúsculas + eliminación de signos de puntuación\n",
    "\n",
    "* Particionamiento en strings (usualmente palabras)\n",
    "\n",
    "* Recombinación de strings (usualmente n-gramas)\n",
    "\n",
    "* Indexación de tokens (asociación de un único entero con cada token)\n",
    "\n",
    "* Transformación de cada ejemplo usando su índice, usualmente en un vector de enteros o en un vector flotante denso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb0807-15ca-4fe3-a02d-22295310845d",
   "metadata": {},
   "source": [
    "**Ejemplo 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15d7f5c-3b78-4fed-acb2-2808c830da51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 4, 0],\n",
       "       [1, 3, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Texto de ejemplo\n",
    "#\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    [\n",
    "        \"foo\",\n",
    "        \"bar\",\n",
    "        \"baz\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "#\n",
    "# Tamaño máximo del vocabulario\n",
    "#\n",
    "max_features = 5000\n",
    "\n",
    "#\n",
    "# Tamaño máximo de la secuencia\n",
    "#\n",
    "max_len = 4\n",
    "\n",
    "#\n",
    "# Creación de la capa\n",
    "#\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_len,\n",
    ")\n",
    "\n",
    "#\n",
    "# Se llama a `adapt` sobre un dataset de texto para crear el vocabulario.\n",
    "#\n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#\n",
    "# Se crea una capa de enetrada de tamaño (1,), ya que se necesita garantizar\n",
    "# que hay exactamente un string de entrada por batch, y de tipo `string`\n",
    "#\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "#\n",
    "# Se adiciona la capa de vectorización (despues de aprendido el vocabularo).\n",
    "# Como salida se obtiene un tensor de tamaño de (batch_size, max_len) y que\n",
    "# contiene los indices al vocabulario\n",
    "#\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "#\n",
    "# El modelo obtenido puede mapear strings a enteros; se suele adicionar una\n",
    "# capa embedding para mapear los enteros al embedding.\n",
    "#\n",
    "input_data = [\n",
    "    [\"foo qux bar\"],\n",
    "    [\"qux baz\"],\n",
    "]\n",
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efa8f7d-d6a4-4597-9fc0-49eef5555eb9",
   "metadata": {},
   "source": [
    "**Ejemplo 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "855c177c-8249-4429-a8b4-c8893fa37672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'earth', 'wind', 'and', 'fire']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_data = [\n",
    "    \"earth\",\n",
    "    \"wind\",\n",
    "    \"and\",\n",
    "    \"fire\",\n",
    "]\n",
    "max_len = 4\n",
    "\n",
    "#\n",
    "# Se crea una capa pasando directamente el vocabulario. También se puede\n",
    "# indicar el vocabulario con una palabra por línea\n",
    "#\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_len,\n",
    "    vocabulary=vocab_data,\n",
    ")\n",
    "\n",
    "#\n",
    "# Ya que se paso el vocabulario directamente, no hay necesidad de llamar a\n",
    "# `adapt`. El vocabulario contiene el padding token ('') y el OOV token\n",
    "# ('[UNK]'), y los tokens pasados.\n",
    "#\n",
    "vectorize_layer.get_vocabulary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
