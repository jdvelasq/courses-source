{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Creating TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "root_dir = \"datasets\"\n",
    "tfrecords_dir = \"tfrecords\"\n",
    "images_dir = os.path.join(root_dir, \"val2017\")\n",
    "annotations_dir = os.path.join(root_dir, \"annotations\")\n",
    "annotation_file = os.path.join(annotations_dir, \"instances_val2017.json\")\n",
    "images_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "annotations_url = (\n",
    "    \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    ")\n",
    "\n",
    "# Download image files\n",
    "if not os.path.exists(images_dir):\n",
    "    image_zip = tf.keras.utils.get_file(\n",
    "        \"images.zip\",\n",
    "        cache_dir=os.path.abspath(\".\"),\n",
    "        origin=images_url,\n",
    "        extract=True,\n",
    "    )\n",
    "    os.remove(image_zip)\n",
    "\n",
    "# Download caption annotation files\n",
    "if not os.path.exists(annotations_dir):\n",
    "    annotation_zip = tf.keras.utils.get_file(\n",
    "        \"captions.zip\",\n",
    "        cache_dir=os.path.abspath(\".\"),\n",
    "        origin=annotations_url,\n",
    "        extract=True,\n",
    "    )\n",
    "    os.remove(annotation_zip)\n",
    "\n",
    "print(\"The COCO dataset has been downloaded and extracted successfully.\")\n",
    "\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    annotations = json.load(f)[\"annotations\"]\n",
    "\n",
    "print(f\"Number of images: {len(annotations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "pprint.pprint(annotations[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_samples = 4096\n",
    "num_tfrecods = len(annotations) // num_samples\n",
    "if len(annotations) % num_samples:\n",
    "    num_tfrecods += 1  # add one record if there are any remaining samples\n",
    "\n",
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(tfrecords_dir)  # creating TFRecords output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n",
    "    )\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def create_example(image, path, example):\n",
    "    feature = {\n",
    "        \"image\": image_feature(image),\n",
    "        \"path\": bytes_feature(path),\n",
    "        \"area\": float_feature(example[\"area\"]),\n",
    "        \"bbox\": float_feature_list(example[\"bbox\"]),\n",
    "        \"category_id\": int64_feature(example[\"category_id\"]),\n",
    "        \"id\": int64_feature(example[\"id\"]),\n",
    "        \"image_id\": int64_feature(example[\"image_id\"]),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"path\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"area\": tf.io.FixedLenFeature([], tf.float32),\n",
    "        \"bbox\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"category_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    example[\"bbox\"] = tf.sparse.to_dense(example[\"bbox\"])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for tfrec_num in range(num_tfrecods):\n",
    "    samples = annotations[(tfrec_num * num_samples) : ((tfrec_num + 1) * num_samples)]\n",
    "\n",
    "    with tf.io.TFRecordWriter(\n",
    "        tfrecords_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(samples))\n",
    "    ) as writer:\n",
    "        for sample in samples:\n",
    "            image_path = f\"{images_dir}/{sample['image_id']:012d}.jpg\"\n",
    "            image = tf.io.decode_jpeg(tf.io.read_file(image_path))\n",
    "            example = create_example(image, image_path, sample)\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(f\"{tfrecords_dir}/file_00-{num_samples}.tfrec\")\n",
    "parsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n",
    "\n",
    "for features in parsed_dataset.take(1):\n",
    "    for key in features.keys():\n",
    "        if key != \"image\":\n",
    "            print(f\"{key}: {features[key]}\")\n",
    "\n",
    "    print(f\"Image shape: {features['image'].shape}\")\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(features[\"image\"].numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def prepare_sample(features):\n",
    "    image = tf.image.resize(features[\"image\"], size=(224, 224))\n",
    "    return image, features[\"category_id\"]\n",
    "\n",
    "\n",
    "def get_dataset(filenames, batch_size):\n",
    "    dataset = (\n",
    "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(prepare_sample, num_parallel_calls=AUTOTUNE)\n",
    "        .shuffle(batch_size * 10)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_filenames = tf.io.gfile.glob(f\"{tfrecords_dir}/*.tfrec\")\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "steps_per_epoch = 50\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "input_tensor = tf.keras.layers.Input(shape=(224, 224, 3), name=\"image\")\n",
    "model = tf.keras.applications.EfficientNetB0(\n",
    "    input_tensor=input_tensor, weights=None, classes=91\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x=get_dataset(train_filenames, batch_size),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "creating_tfrecords",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
