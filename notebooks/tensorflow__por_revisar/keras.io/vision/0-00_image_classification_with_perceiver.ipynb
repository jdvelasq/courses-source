{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Image Classification with Perceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "dropout_rate = 0.2\n",
    "image_size = 64  # We'll resize input images to this size.\n",
    "patch_size = 2  # Size of the patches to be extract from the input images.\n",
    "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
    "latent_dim = 256  # Size of the latent array.\n",
    "projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n",
    "num_heads = 8  # Number of Transformer heads.\n",
    "ffn_units = [\n",
    "    projection_dim,\n",
    "    projection_dim,\n",
    "]  # Size of the Transformer Feedforward network.\n",
    "num_transformer_blocks = 4\n",
    "num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n",
    "classifier_units = [\n",
    "    projection_dim,\n",
    "    num_classes,\n",
    "]  # Size of the Feedforward network of the final classifier.\n",
    "\n",
    "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
    "print(f\"Patches per image: {num_patches}\")\n",
    "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n",
    "print(f\"Latent array shape: {latent_dim} X {projection_dim}\")\n",
    "print(f\"Data array shape: {num_patches} X {projection_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.Resizing(image_size, image_size),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def create_ffn(hidden_units, dropout_rate):\n",
    "    ffn_layers = []\n",
    "    for units in hidden_units[:-1]:\n",
    "        ffn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "\n",
    "    ffn_layers.append(layers.Dense(units=hidden_units[-1]))\n",
    "    ffn_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "    ffn = keras.Sequential(ffn_layers)\n",
    "    return ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patches):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def create_cross_attention_module(\n",
    "    latent_dim, data_dim, projection_dim, ffn_units, dropout_rate\n",
    "):\n",
    "\n",
    "    inputs = {\n",
    "        # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n",
    "        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim)),\n",
    "        # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n",
    "        \"data_array\": layers.Input(shape=(data_dim, projection_dim)),\n",
    "    }\n",
    "\n",
    "    # Apply layer norm to the inputs\n",
    "    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n",
    "    data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n",
    "\n",
    "    # Create query tensor: [1, latent_dim, projection_dim].\n",
    "    query = layers.Dense(units=projection_dim)(latent_array)\n",
    "    # Create key tensor: [batch_size, data_dim, projection_dim].\n",
    "    key = layers.Dense(units=projection_dim)(data_array)\n",
    "    # Create value tensor: [batch_size, data_dim, projection_dim].\n",
    "    value = layers.Dense(units=projection_dim)(data_array)\n",
    "\n",
    "    # Generate cross-attention outputs: [batch_size, latent_dim, projection_dim].\n",
    "    attention_output = layers.Attention(use_scale=True, dropout=0.1)(\n",
    "        [query, key, value], return_attention_scores=False\n",
    "    )\n",
    "    # Skip connection 1.\n",
    "    attention_output = layers.Add()([attention_output, latent_array])\n",
    "\n",
    "    # Apply layer norm.\n",
    "    attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "    # Apply Feedforward network.\n",
    "    ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n",
    "    outputs = ffn(attention_output)\n",
    "    # Skip connection 2.\n",
    "    outputs = layers.Add()([outputs, attention_output])\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def create_transformer_module(\n",
    "    latent_dim,\n",
    "    projection_dim,\n",
    "    num_heads,\n",
    "    num_transformer_blocks,\n",
    "    ffn_units,\n",
    "    dropout_rate,\n",
    "):\n",
    "\n",
    "    # input_shape: [1, latent_dim, projection_dim]\n",
    "    inputs = layers.Input(shape=(latent_dim, projection_dim))\n",
    "\n",
    "    x0 = inputs\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        # Apply layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x0)\n",
    "        # Create a multi-head self-attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x0])\n",
    "        # Apply layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # Apply Feedforward network.\n",
    "        ffn = create_ffn(hidden_units=ffn_units, dropout_rate=dropout_rate)\n",
    "        x3 = ffn(x3)\n",
    "        # Skip connection 2.\n",
    "        x0 = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=x0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Perceiver(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size,\n",
    "        data_dim,\n",
    "        latent_dim,\n",
    "        projection_dim,\n",
    "        num_heads,\n",
    "        num_transformer_blocks,\n",
    "        ffn_units,\n",
    "        dropout_rate,\n",
    "        num_iterations,\n",
    "        classifier_units,\n",
    "    ):\n",
    "        super(Perceiver, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.data_dim = data_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_transformer_blocks = num_transformer_blocks\n",
    "        self.ffn_units = ffn_units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.classifier_units = classifier_units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create latent array.\n",
    "        self.latent_array = self.add_weight(\n",
    "            shape=(self.latent_dim, self.projection_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Create patching module.\n",
    "        self.patcher = Patches(self.patch_size)\n",
    "\n",
    "        # Create patch encoder.\n",
    "        self.patch_encoder = PatchEncoder(self.data_dim, self.projection_dim)\n",
    "\n",
    "        # Create cross-attenion module.\n",
    "        self.cross_attention = create_cross_attention_module(\n",
    "            self.latent_dim,\n",
    "            self.data_dim,\n",
    "            self.projection_dim,\n",
    "            self.ffn_units,\n",
    "            self.dropout_rate,\n",
    "        )\n",
    "\n",
    "        # Create Transformer module.\n",
    "        self.transformer = create_transformer_module(\n",
    "            self.latent_dim,\n",
    "            self.projection_dim,\n",
    "            self.num_heads,\n",
    "            self.num_transformer_blocks,\n",
    "            self.ffn_units,\n",
    "            self.dropout_rate,\n",
    "        )\n",
    "\n",
    "        # Create global average pooling layer.\n",
    "        self.global_average_pooling = layers.GlobalAveragePooling1D()\n",
    "\n",
    "        # Create a classification head.\n",
    "        self.classification_head = create_ffn(\n",
    "            hidden_units=self.classifier_units, dropout_rate=self.dropout_rate\n",
    "        )\n",
    "\n",
    "        super(Perceiver, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Augment data.\n",
    "        augmented = data_augmentation(inputs)\n",
    "        # Create patches.\n",
    "        patches = self.patcher(augmented)\n",
    "        # Encode patches.\n",
    "        encoded_patches = self.patch_encoder(patches)\n",
    "        # Prepare cross-attention inputs.\n",
    "        cross_attention_inputs = {\n",
    "            \"latent_array\": tf.expand_dims(self.latent_array, 0),\n",
    "            \"data_array\": encoded_patches,\n",
    "        }\n",
    "        # Apply the cross-attention and the Transformer modules iteratively.\n",
    "        for _ in range(num_iterations):\n",
    "            # Apply cross-attention from the latent array to the data array.\n",
    "            latent_array = self.cross_attention(cross_attention_inputs)\n",
    "            # Apply self-attention Transformer to the latent array.\n",
    "            latent_array = self.transformer(latent_array)\n",
    "            # Set the latent array of the next iteration.\n",
    "            cross_attention_inputs[\"latent_array\"] = latent_array\n",
    "\n",
    "        # Apply global average pooling to generate a [batch_size, projection_dim] repesentation tensor.\n",
    "        representation = self.global_average_pooling(latent_array)\n",
    "        # Generate logits.\n",
    "        logits = self.classification_head(representation)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "\n",
    "    # Create LAMB optimizer with weight decay.\n",
    "    optimizer = tfa.optimizers.LAMB(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay_rate=weight_decay,\n",
    "    )\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Create a learning rate scheduler callback.\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.2, patience=3\n",
    "    )\n",
    "\n",
    "    # Create an early stopping callback.\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=15, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "    )\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    # Return history to plot learning curves.\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "perceiver_classifier = Perceiver(\n",
    "    patch_size,\n",
    "    num_patches,\n",
    "    latent_dim,\n",
    "    projection_dim,\n",
    "    num_heads,\n",
    "    num_transformer_blocks,\n",
    "    ffn_units,\n",
    "    dropout_rate,\n",
    "    num_iterations,\n",
    "    classifier_units,\n",
    ")\n",
    "\n",
    "\n",
    "history = run_experiment(perceiver_classifier)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "perceiver_image_classification",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
