{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# RandAugment for Image Classification for Improved Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "tf.random.set_seed(42)\n",
    "ia.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(f\"Total training examples: {len(x_train)}\")\n",
    "print(f\"Total test examples: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "IMAGE_SIZE = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "rand_aug = iaa.RandAugment(n=3, m=7)\n",
    "\n",
    "\n",
    "def augment(images):\n",
    "    # Input to `augment()` is a TensorFlow tensor which\n",
    "    # is not supported by `imgaug`. This is why we first\n",
    "    # convert it to its `numpy` variant.\n",
    "    images = tf.cast(images, tf.uint8)\n",
    "    return rand_aug(images=images.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_ds_rand = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(BATCH_SIZE * 100)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(\n",
    "        lambda x, y: (tf.image.resize(x, (IMAGE_SIZE, IMAGE_SIZE)), y),\n",
    "        num_parallel_calls=AUTO,\n",
    "    )\n",
    "    .map(\n",
    "        lambda x, y: (tf.py_function(augment, [x], [tf.float32])[0], y),\n",
    "        num_parallel_calls=AUTO,\n",
    "    )\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(\n",
    "        lambda x, y: (tf.image.resize(x, (IMAGE_SIZE, IMAGE_SIZE)), y),\n",
    "        num_parallel_calls=AUTO,\n",
    "    )\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "simple_aug = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "        layers.experimental.preprocessing.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Now, map the augmentation pipeline to our training dataset\n",
    "train_ds_simple = (\n",
    "    tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    .shuffle(BATCH_SIZE * 100)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(lambda x, y: (simple_aug(x), y), num_parallel_calls=AUTO)\n",
    "    .prefetch(AUTO)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "sample_images, _ = next(iter(train_ds_rand))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"int\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "sample_images, _ = next(iter(train_ds_simple))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(sample_images[:9]):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"int\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def get_training_model():\n",
    "    resnet50_v2 = tf.keras.applications.ResNet50V2(\n",
    "        weights=None,\n",
    "        include_top=True,\n",
    "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "        classes=10,\n",
    "    )\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.Input((IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
    "            layers.experimental.preprocessing.Rescaling(scale=1.0 / 127.5, offset=-1),\n",
    "            resnet50_v2,\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "get_training_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "initial_model = get_training_model()\n",
    "initial_model.save_weights(\"initial_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "rand_aug_model = get_training_model()\n",
    "rand_aug_model.load_weights(\"initial_weights.h5\")\n",
    "rand_aug_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "rand_aug_model.fit(train_ds_rand, validation_data=test_ds, epochs=EPOCHS)\n",
    "_, test_acc = rand_aug_model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "simple_aug_model = get_training_model()\n",
    "simple_aug_model.load_weights(\"initial_weights.h5\")\n",
    "simple_aug_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "simple_aug_model.fit(train_ds_simple, validation_data=test_ds, epochs=EPOCHS)\n",
    "_, test_acc = simple_aug_model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Load and prepare the CIFAR-10-C dataset\n",
    "# (If it's not already downloaded, it takes ~10 minutes of time to download)\n",
    "cifar_10_c = tfds.load(\"cifar10_corrupted/saturate_5\", split=\"test\", as_supervised=True)\n",
    "cifar_10_c = cifar_10_c.batch(BATCH_SIZE).map(\n",
    "    lambda x, y: (tf.image.resize(x, (IMAGE_SIZE, IMAGE_SIZE)), y),\n",
    "    num_parallel_calls=AUTO,\n",
    ")\n",
    "\n",
    "# Evaluate `rand_aug_model`\n",
    "_, test_acc = rand_aug_model.evaluate(cifar_10_c, verbose=0)\n",
    "print(\n",
    "    \"Accuracy with RandAugment on CIFAR-10-C (saturate_5): {:.2f}%\".format(\n",
    "        test_acc * 100\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate `simple_aug_model`\n",
    "_, test_acc = simple_aug_model.evaluate(cifar_10_c, verbose=0)\n",
    "print(\n",
    "    \"Accuracy with simple_aug on CIFAR-10-C (saturate_5): {:.2f}%\".format(\n",
    "        test_acc * 100\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "randaugment",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
