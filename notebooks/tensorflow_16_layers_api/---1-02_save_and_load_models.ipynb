{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a96a43a-3363-4068-918b-55a8773470e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Almacenamiento y carga de modelos --- 0:00 min\n",
    "===\n",
    "\n",
    "* Última modificación: Marzo 7, 2022 | YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ee4f5-15fb-4669-9eba-1f3dfbd3b897",
   "metadata": {
    "tags": []
   },
   "source": [
    "Importación de librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b41e63-667a-491d-9be7-c00271a4c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223d5246-d5b5-4a4b-97b7-ee7dc3656487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --quiet pyyaml h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff260cb-ccb7-44fd-87d2-5a68f94fd824",
   "metadata": {},
   "source": [
    "Dataset\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f224733-b77f-4b03-b43c-721a0b042ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (\n",
    "    test_images,\n",
    "    test_labels,\n",
    ") = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f8920c-1c95-49ac-bfd3-069578524ebf",
   "metadata": {},
   "source": [
    "Definición del modelo\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77b2ed5-8407-46f5-8e06-770378f3a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec83aac-c8f5-4e6e-ba88-b9a4204f2559",
   "metadata": {},
   "source": [
    "Almacenamiento de checkpoints durante el entrenamiento\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861916f-4acb-432b-b506-8854e9390d01",
   "metadata": {},
   "source": [
    "**Checkpoint callback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3c94fd-cd5b-4245-b93d-67913f8f926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/32 [==============>...............] - ETA: 0s - loss: 1.5381 - sparse_categorical_accuracy: 0.5508\n",
      "Epoch 1: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 1s 10ms/step - loss: 1.1611 - sparse_categorical_accuracy: 0.6620 - val_loss: 0.7098 - val_sparse_categorical_accuracy: 0.7690\n",
      "Epoch 2/10\n",
      "19/32 [================>.............] - ETA: 0s - loss: 0.4294 - sparse_categorical_accuracy: 0.8668\n",
      "Epoch 2: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4251 - sparse_categorical_accuracy: 0.8810 - val_loss: 0.5491 - val_sparse_categorical_accuracy: 0.8240\n",
      "Epoch 3/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.2984 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 3: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2940 - sparse_categorical_accuracy: 0.9240 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.1988 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 4: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2119 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.4356 - val_sparse_categorical_accuracy: 0.8570\n",
      "Epoch 5/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.1523 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 5: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1524 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.4285 - val_sparse_categorical_accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.1206 - sparse_categorical_accuracy: 0.9757\n",
      "Epoch 6: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9770 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.0828 - sparse_categorical_accuracy: 0.9861\n",
      "Epoch 7: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.3971 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 8/10\n",
      "18/32 [===============>..............] - ETA: 0s - loss: 0.0691 - sparse_categorical_accuracy: 0.9931\n",
      "Epoch 8: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0669 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.4110 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.0511 - sparse_categorical_accuracy: 0.9968\n",
      "Epoch 9: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.4142 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 10/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.0392 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10: saving model to /tmp/training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc33ac86d00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/tmp/training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[cp_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d44a734-ebb6-49af-a29d-9a97291c982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adffd57b-ca5d-4ae2-afd4-29289868de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3158 - sparse_categorical_accuracy: 0.1040 - 147ms/epoch - 5ms/step\n",
      "Untrained model, accuracy: 10.40%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a212bcf7-37f2-418d-869e-5327698253c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4131 - sparse_categorical_accuracy: 0.8720 - 69ms/epoch - 2ms/step\n",
      "Restored model, accuracy: 87.20%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "loss, acc = model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b302c-3a29-453c-97bf-c7e7b7110977",
   "metadata": {},
   "source": [
    "**Opciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdec282-1d0e-4446-995f-d6ed3f095521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "\n",
      "Epoch 5: saving model to /tmp/training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 10: saving model to /tmp/training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 15: saving model to /tmp/training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 20: saving model to /tmp/training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 25: saving model to /tmp/training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 30: saving model to /tmp/training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 35: saving model to /tmp/training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 40: saving model to /tmp/training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 45: saving model to /tmp/training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 50: saving model to /tmp/training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc337821e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/tmp/training_2/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5 * batch_size,\n",
    ")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[cp_callback],\n",
    "    validation_data=(test_images, test_labels),\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665259a4-0630-4729-b39e-da936beb3035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "cp-0000.ckpt.data-00000-of-00001\n",
      "cp-0000.ckpt.index\n",
      "cp-0005.ckpt.data-00000-of-00001\n",
      "cp-0005.ckpt.index\n",
      "cp-0010.ckpt.data-00000-of-00001\n",
      "cp-0010.ckpt.index\n",
      "cp-0015.ckpt.data-00000-of-00001\n",
      "cp-0015.ckpt.index\n",
      "cp-0020.ckpt.data-00000-of-00001\n",
      "cp-0020.ckpt.index\n",
      "cp-0025.ckpt.data-00000-of-00001\n",
      "cp-0025.ckpt.index\n",
      "cp-0030.ckpt.data-00000-of-00001\n",
      "cp-0030.ckpt.index\n",
      "cp-0035.ckpt.data-00000-of-00001\n",
      "cp-0035.ckpt.index\n",
      "cp-0040.ckpt.data-00000-of-00001\n",
      "cp-0040.ckpt.index\n",
      "cp-0045.ckpt.data-00000-of-00001\n",
      "cp-0045.ckpt.index\n",
      "cp-0050.ckpt.data-00000-of-00001\n",
      "cp-0050.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "!ls -1 {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f3f2b6-140d-449b-a564-56c259f7a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/training_2/cp-0050.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb0a75c-9ea7-4630-98af-09fa0410b88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4824 - sparse_categorical_accuracy: 0.8800 - 146ms/epoch - 5ms/step\n",
      "Restored model, accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.load_weights(latest)\n",
    "\n",
    "loss, acc = model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb6c1a-ebe6-424b-9b62-a0fa5ac5fe40",
   "metadata": {},
   "source": [
    "Almacenamiento manual de los pesos\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "535d6201-2d2d-40fc-a528-b6576e839637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4824 - sparse_categorical_accuracy: 0.8800 - 143ms/epoch - 4ms/step\n",
      "Restored model, accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"/tmp/checkpoints/my_checkpoint\")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.load_weights(\"/tmp/checkpoints/my_checkpoint\")\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92712792-bca0-440e-b6d5-0d8ab2c70929",
   "metadata": {},
   "source": [
    "Almacenamiento del modelo completo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7533d-285e-4e9d-b8a3-32da8dfc2ec9",
   "metadata": {},
   "source": [
    "**Formato SavedModel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4c1c01-6360-4235-915e-2769d7a59e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.2063 - sparse_categorical_accuracy: 0.6720\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4161 - sparse_categorical_accuracy: 0.8890\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3037 - sparse_categorical_accuracy: 0.9170\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2115 - sparse_categorical_accuracy: 0.9390\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9700\n",
      "INFO:tensorflow:Assets written to: /tmp/saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "!mkdir -p /tmp/saved_model\n",
    "model.save(\"/tmp/saved_model/my_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9444ad7-cd03-4770-a1ed-8ea60f4b6ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\n"
     ]
    }
   ],
   "source": [
    "!ls /tmp/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c23e0737-417d-4b45-ab24-c63f097a01fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\n",
      "keras_metadata.pb\n",
      "saved_model.pb\n",
      "variables\n"
     ]
    }
   ],
   "source": [
    "!ls -1 /tmp/saved_model/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58682472-e738-40f8-999f-bb10eb35025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"/tmp/saved_model/my_model/\")\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdbdd4f2-d553-479d-803f-5ce6e7b61e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4529 - sparse_categorical_accuracy: 0.8520 - 150ms/epoch - 5ms/step\n",
      "Restored model, accuracy: 85.20%\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa220906-200a-4585-b062-1ea4eb254a27",
   "metadata": {},
   "source": [
    "**Formato HDF5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65246338-f6eb-4b02-9969-549f37be0b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1487 - sparse_categorical_accuracy: 0.6820\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4128 - sparse_categorical_accuracy: 0.8820\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2748 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1979 - sparse_categorical_accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1412 - sparse_categorical_accuracy: 0.9690\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    ")\n",
    "model.save(\"/tmp/my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66206e28-b034-4274-a59a-ded5e8c119b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"/tmp/my_model.h5\")\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "374983b2-a6f3-4b80-8989-eff451d00b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4456 - sparse_categorical_accuracy: 0.8580 - 144ms/epoch - 4ms/step\n",
      "Restored model, accuracy: 85.80%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2,\n",
    ")\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
