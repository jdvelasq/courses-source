{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f840df1-29dd-4b41-a766-79bcb6e2d54a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Extracción de características de texto\n",
    "===\n",
    "\n",
    "* 13:14 min | Ultima modificación: Abril 19, 2021 | [YouTube]Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0fafa2b-000b-4d45-ad81-03fac2370698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         1      0   1    0       2    1      0     1\n",
       "2    1         0      0   0    1       0    1      1     0\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option(\"display.notebook_repr_html\", False)\n",
    "\n",
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This is the second second document.\",\n",
    "    \"And the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(corpus)\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    columns=vectorizer.get_feature_names(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c71b87-90a2-4e0e-904d-62ba051e7c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af64cbc0-3dac-45f1-b715-014c2a245f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff19763-f622-4094-b26e-b0a43d69c321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'text', 'document', 'to', 'analyze']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a326ec-3a10-4e41-992b-f49ab10ea286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f193085-4532-4535-8753-aa2f860ad2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
    "                                    token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b628a8ef-d546-4bad-828c-47a75c8bf80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   and  and the  document  first  first document  is  is the  is this  one  \\\n",
       "0    0        0         1      1               1   1       1        0    0   \n",
       "1    0        0         1      0               0   1       1        0    0   \n",
       "2    1        1         0      0               0   0       0        0    1   \n",
       "3    0        0         1      1               1   1       0        1    0   \n",
       "\n",
       "   second  ...  second second  the  the first  the second  the third  third  \\\n",
       "0       0  ...              0    1          1           0          0      0   \n",
       "1       2  ...              1    1          0           1          0      0   \n",
       "2       0  ...              0    1          0           0          1      1   \n",
       "3       0  ...              0    1          1           0          0      0   \n",
       "\n",
       "   third one  this  this is  this the  \n",
       "0          0     1        1         0  \n",
       "1          0     1        1         0  \n",
       "2          1     0        0         0  \n",
       "3          0     1        0         1  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer.fit(corpus)\n",
    "X_2 = bigram_vectorizer.transform(corpus)\n",
    "pd.DataFrame(\n",
    "    X_2.toarray(),\n",
    "    columns=bigram_vectorizer.get_feature_names(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b40dd3a3-3c92-43c3-80ce-052fe93761b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_index = bigram_vectorizer.vocabulary_.get('is this')\n",
    "X_2[:, feature_index].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d536fc-1924-40c6-b482-66116416a59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81940995, 0.        , 0.57320793],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.47330339, 0.88089948, 0.        ],\n",
       "       [0.58149261, 0.        , 0.81355169]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "\n",
    "counts = [[3, 0, 1],\n",
    "          [2, 0, 0],\n",
    "          [3, 0, 0],\n",
    "          [4, 0, 0],\n",
    "          [3, 2, 0],\n",
    "          [3, 0, 2]]\n",
    "\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ab2f1-57ea-4cb9-8f47-c6096616190a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06ce43-5bf5-4820-9983-874607885072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
