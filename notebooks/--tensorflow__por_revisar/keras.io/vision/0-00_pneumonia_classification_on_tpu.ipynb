{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Pneumonia Classification on TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 25 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [180, 180]\n",
    "CLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = tf.data.TFRecordDataset(\n",
    "    \"gs://download.tensorflow.org/data/ChestXRay2017/train/images.tfrec\"\n",
    ")\n",
    "train_paths = tf.data.TFRecordDataset(\n",
    "    \"gs://download.tensorflow.org/data/ChestXRay2017/train/paths.tfrec\"\n",
    ")\n",
    "\n",
    "ds = tf.data.Dataset.zip((train_images, train_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "COUNT_NORMAL = len(\n",
    "    [\n",
    "        filename\n",
    "        for filename in train_paths\n",
    "        if \"NORMAL\" in filename.numpy().decode(\"utf-8\")\n",
    "    ]\n",
    ")\n",
    "print(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n",
    "\n",
    "COUNT_PNEUMONIA = len(\n",
    "    [\n",
    "        filename\n",
    "        for filename in train_paths\n",
    "        if \"PNEUMONIA\" in filename.numpy().decode(\"utf-8\")\n",
    "    ]\n",
    ")\n",
    "print(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, \"/\")\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == \"PNEUMONIA\"\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, IMAGE_SIZE)\n",
    "\n",
    "\n",
    "def process_path(image, path):\n",
    "    label = get_label(path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = decode_img(image)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "ds = ds.shuffle(10000)\n",
    "train_ds = ds.take(4200)\n",
    "val_ds = ds.skip(4200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "test_images = tf.data.TFRecordDataset(\n",
    "    \"gs://download.tensorflow.org/data/ChestXRay2017/test/images.tfrec\"\n",
    ")\n",
    "test_paths = tf.data.TFRecordDataset(\n",
    "    \"gs://download.tensorflow.org/data/ChestXRay2017/test/paths.tfrec\"\n",
    ")\n",
    "test_ds = tf.data.Dataset.zip((test_images, test_paths))\n",
    "\n",
    "test_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(train_ds)\n",
    "val_ds = prepare_for_training(val_ds)\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(image_batch[n] / 255)\n",
    "        if label_batch[n]:\n",
    "            plt.title(\"PNEUMONIA\")\n",
    "        else:\n",
    "            plt.title(\"NORMAL\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "def conv_block(filters, inputs):\n",
    "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.MaxPool2D()(x)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def dense_block(units, dropout_rate, inputs):\n",
    "    x = layers.Dense(units, activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "    x = preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "\n",
    "    x = conv_block(32, x)\n",
    "    x = conv_block(64, x)\n",
    "\n",
    "    x = conv_block(128, x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = conv_block(256, x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = dense_block(512, 0.7, x)\n",
    "    x = dense_block(128, 0.5, x)\n",
    "    x = dense_block(64, 0.3, x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "initial_bias = np.log([COUNT_PNEUMONIA / COUNT_NORMAL])\n",
    "print(\"Initial bias: {:.5f}\".format(initial_bias[0]))\n",
    "\n",
    "TRAIN_IMG_COUNT = COUNT_NORMAL + COUNT_PNEUMONIA\n",
    "weight_for_0 = (1 / COUNT_NORMAL) * (TRAIN_IMG_COUNT) / 2.0\n",
    "weight_for_1 = (1 / COUNT_PNEUMONIA) * (TRAIN_IMG_COUNT) / 2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print(\"Weight for class 0: {:.2f}\".format(weight_for_0))\n",
    "print(\"Weight for class 1: {:.2f}\".format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\", save_best_only=True)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.015\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model()\n",
    "\n",
    "    METRICS = [\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history[\"val_\" + met])\n",
    "    ax[i].set_title(\"Model {}\".format(met))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend([\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "for image, label in test_ds.take(1):\n",
    "    plt.imshow(image[0] / 255.0)\n",
    "    plt.title(CLASS_NAMES[label[0].numpy()])\n",
    "\n",
    "prediction = model.predict(test_ds.take(1))[0]\n",
    "scores = [1 - prediction, prediction]\n",
    "\n",
    "for score, name in zip(scores, CLASS_NAMES):\n",
    "    print(\"This image is %.2f percent %s\" % ((100 * score), name))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "xray_classification_with_tpus",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
