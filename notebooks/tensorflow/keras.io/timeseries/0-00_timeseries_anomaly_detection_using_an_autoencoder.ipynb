{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Timeseries anomaly detection using an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(df_small_noise.head())\n",
    "\n",
    "print(df_daily_jumpsup.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_small_noise.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Normalize and save the mean and std we get,\n",
    "# for normalizing test data.\n",
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_train[0])\n",
    "plt.plot(x_train_pred[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "df_test_value = (df_daily_jumpsup - training_mean) / training_std\n",
    "fig, ax = plt.subplots()\n",
    "df_test_value.plot(legend=False, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Create sequences from test values.\n",
    "x_test = create_sequences(df_test_value.values)\n",
    "print(\"Test input shape: \", x_test.shape)\n",
    "\n",
    "# Get test MAE loss.\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
    "test_mae_loss = test_mae_loss.reshape((-1))\n",
    "\n",
    "plt.hist(test_mae_loss, bins=50)\n",
    "plt.xlabel(\"test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Detect all the samples which are anomalies.\n",
    "anomalies = test_mae_loss > threshold\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
    "anomalous_data_indices = []\n",
    "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
    "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
    "        anomalous_data_indices.append(data_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "df_subset = df_daily_jumpsup.iloc[anomalous_data_indices]\n",
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "df_subset.plot(legend=False, ax=ax, color=\"r\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_anomaly_detection",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
