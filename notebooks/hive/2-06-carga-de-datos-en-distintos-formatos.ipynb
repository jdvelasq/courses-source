{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos en distintos formatos\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *30 min* | Última modificación: Junio 22, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hive permite la lectura de archivos en distintos formatos. Al finalizar este tutorial, el lector estará en capacidad de leer archivos en formatos de texto, CSV y JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Se carga la librería para interactuar con Hive desde Jupyter.\n",
    "## \n",
    "%load_ext bigdata\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/drivers\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Crea la carpeta drivers en el HDFS\n",
    "##\n",
    "!hdfs dfs -rm -r -f /tmp/drivers\n",
    "!hdfs dfs -mkdir    /tmp/drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de formato JSON desde un archivo cargado como texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta estrategía de carga de datos, el archivo original con formato JSON es cargado como texto, donde cada registro de la tabla corresponde a una línea del archivo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Copia el archivo al HDFS para su importación posterior a Hive\n",
    "##\n",
    "!hdfs dfs -copyFromLocal drivers/drivers.json  /tmp/drivers/drivers.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, se crea la tabla `drivers_raw_json`, la cual tiene una única columna llamada `textcol`. Luego, el archivo `drivers.json` es cargado en dicha tabla. Finalmente, se visualizan los primeros cinco registros para verificar que la lectura fue correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS drivers_raw_json;\n",
      "OK\n",
      "Time taken: 8.193 seconds\n",
      "CREATE TABLE drivers_raw_json (\n",
      "    textcol STRING\n",
      ") \n",
      "STORED AS TEXTFILE;\n",
      "OK\n",
      "Time taken: 0.557 seconds\n",
      "LOAD DATA INPATH \n",
      "    '/tmp/drivers/drivers.json' \n",
      "OVERWRITE INTO TABLE drivers_raw_json;\n",
      "Loading data to table default.drivers_raw_json\n",
      "OK\n",
      "Time taken: 0.889 seconds\n",
      "SELECT * FROM drivers_raw_json LIMIT 5;\n",
      "OK\n",
      "{\"driverId\":10,\"name\":\"George Vetticaden\",\"ssn\":621011971,\"location\":\"244-4532 Nulla Rd.\",\"certified\":\"N\",\"wage-plan\":\"miles\"}\n",
      "{\"driverId\":11,\"name\":\"Jamie Engesser\",\"ssn\":262112338,\"location\":\"366-4125 Ac Street\",\"certified\":\"N\",\"wage-plan\":\"miles\"}\n",
      "{\"driverId\":12,\"name\":\"Paul Coddin\",\"ssn\":198041975,\"location\":\"Ap #622-957 Risus. Street\",\"certified\":\"Y\",\"wage-plan\":\"hours\"}\n",
      "{\"driverId\":13,\"name\":\"Joe Niemiec\",\"ssn\":139907145,\"location\":\"2071 Hendrerit. Ave\",\"certified\":\"Y\",\"wage-plan\":\"hours\"}\n",
      "{\"driverId\":14,\"name\":\"Adis Cesir\",\"ssn\":820812209,\"location\":\"Ap #810-1228 In St.\",\"certified\":\"Y\",\"wage-plan\":\"hours\"}\n",
      "Time taken: 1.254 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS drivers_raw_json;\n",
    "\n",
    "CREATE TABLE drivers_raw_json (\n",
    "    textcol STRING\n",
    ") \n",
    "STORED AS TEXTFILE;\n",
    "\n",
    "LOAD DATA INPATH \n",
    "    '/tmp/drivers/drivers.json' \n",
    "OVERWRITE INTO TABLE drivers_raw_json;\n",
    "\n",
    "SELECT * FROM drivers_raw_json LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que en la salida anterior, cada fila corresponde a un registro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura usando get_json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de los campos pueden ser extraídos usando la función `get_json_object`, cuyos parámetros son el nombre del campo en la tabla y el nombre del campo en la estructura JSON. En el siguiente fragmento de código, se utiliza una consulta para extraer los campos `driverId`, `name`  y `ssn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    GET_JSON_OBJECT(textcol,'$.driverId'),\n",
      "    GET_JSON_OBJECT(textcol,'$.name'),\n",
      "    GET_JSON_OBJECT(textcol,'$.ssn')\n",
      "FROM \n",
      "    drivers_raw_json \n",
      "LIMIT \n",
      "    10;\n",
      "OK\n",
      "10\tGeorge Vetticaden\t621011971\n",
      "11\tJamie Engesser\t262112338\n",
      "12\tPaul Coddin\t198041975\n",
      "13\tJoe Niemiec\t139907145\n",
      "14\tAdis Cesir\t820812209\n",
      "15\tRohit Bakshi\t239005227\n",
      "16\tTom McCuch\t363303105\n",
      "17\tEric Mizell\t123808238\n",
      "18\tGrant Liu\t171010151\n",
      "19\tAjay Singh\t160005158\n",
      "Time taken: 0.361 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT\n",
    "    GET_JSON_OBJECT(textcol,'$.driverId'),\n",
    "    GET_JSON_OBJECT(textcol,'$.name'),\n",
    "    GET_JSON_OBJECT(textcol,'$.ssn')\n",
    "FROM \n",
    "    drivers_raw_json \n",
    "LIMIT \n",
    "    10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de json_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función cumple el mismo objetivo de la anterior, pero es mucho más eficiente ya que el registro es procesado únicamente una vez para realizar la extracción de la información requerida. Ya que `json_tuple` es una UDF, debe usarse `LATERAL VIEW` para realizar la consulta, tal como se ejemplifica a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    t1.driverId,\n",
      "    t1.name,\n",
      "    t1.ssn\n",
      "FROM\n",
      "    drivers_raw_json  t0\n",
      "LATERAL VIEW\n",
      "    JSON_TUPLE(t0.textcol, 'driverId', 'name', 'ssn') t1\n",
      "    AS driverId, name, ssn\n",
      "LIMIT 5;\n",
      "OK\n",
      "10\tGeorge Vetticaden\t621011971\n",
      "11\tJamie Engesser\t262112338\n",
      "12\tPaul Coddin\t198041975\n",
      "13\tJoe Niemiec\t139907145\n",
      "14\tAdis Cesir\t820812209\n",
      "Time taken: 0.079 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "SELECT\n",
    "    t1.driverId,\n",
    "    t1.name,\n",
    "    t1.ssn\n",
    "FROM\n",
    "    drivers_raw_json  t0\n",
    "LATERAL VIEW\n",
    "    JSON_TUPLE(t0.textcol, 'driverId', 'name', 'ssn') t1\n",
    "    AS driverId, name, ssn\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de archivos en formato JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hive también permite la importación directa de archivos en formato JSON usando el serde `JsonSerDe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Se copia el archivo al sistema HDFS\n",
    "##\n",
    "!hdfs dfs -copyFromLocal drivers/drivers.json  /tmp/drivers/drivers.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, se crea la tabla `drivers_json` donde el formato de cada registro es especificado como JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS drivers_json;\n",
      "OK\n",
      "Time taken: 0.083 seconds\n",
      "CREATE TABLE drivers_json (\n",
      "    driverId  INT, \n",
      "    name      STRING, \n",
      "    ssn       BIGINT,\n",
      "    location  STRING, \n",
      "    certified STRING, \n",
      "    wageplan  STRING)\n",
      "ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'\n",
      "STORED AS TEXTFILE\n",
      "LOCATION '/tmp/drivers-json';\n",
      "OK\n",
      "Time taken: 0.074 seconds\n",
      "json;\n",
      "Loading data to table default.drivers_json\n",
      "OK\n",
      "Time taken: 0.559 seconds\n",
      "SELECT * FROM drivers_json LIMIT 5;\n",
      "OK\n",
      "10\tGeorge Vetticaden\t621011971\t244-4532 Nulla Rd.\tN\tNULL\n",
      "11\tJamie Engesser\t262112338\t366-4125 Ac Street\tN\tNULL\n",
      "12\tPaul Coddin\t198041975\tAp #622-957 Risus. Street\tY\tNULL\n",
      "13\tJoe Niemiec\t139907145\t2071 Hendrerit. Ave\tY\tNULL\n",
      "14\tAdis Cesir\t820812209\tAp #810-1228 In St.\tY\tNULL\n",
      "Time taken: 0.116 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS drivers_json;\n",
    "\n",
    "CREATE TABLE drivers_json (\n",
    "    driverId  INT, \n",
    "    name      STRING, \n",
    "    ssn       BIGINT,\n",
    "    location  STRING, \n",
    "    certified STRING, \n",
    "    wageplan  STRING)\n",
    "ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/tmp/drivers-json';\n",
    "\n",
    "LOAD DATA INPATH '/tmp/drivers/drivers.json' OVERWRITE INTO TABLE drivers_json;\n",
    "\n",
    "SELECT * FROM drivers_json LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de archivos en formato CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo se usa el serde `OpenCSVSerde` para leer archivo en formato CSV. Note que se usa la cláusula `with serdeproperties` para indicar las características del formato CSV utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Se copia el archivo al sistema HDFS\n",
    "##\n",
    "!hdfs dfs -copyFromLocal drivers/drivers.csv  /tmp/drivers/drivers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS drivers_csv;\n",
      "OK\n",
      "Time taken: 0.065 seconds\n",
      "CREATE TABLE drivers_csv (driverId  INT, \n",
      "                         name      STRING, \n",
      "                         ssn       BIGINT,\n",
      "                         location  STRING, \n",
      "                         certified STRING, \n",
      "                         wageplan  STRING)\n",
      "ROW FORMAT SERDE \n",
      "    'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
      "WITH SERDEPROPERTIES (\n",
      "   'separatorChar' = \",\",\n",
      "   'quoteChar'     = '\\'',\n",
      "   'escapeChar'    = \"\\\\\");\n",
      "OK\n",
      "Time taken: 0.046 seconds\n",
      "sv;\n",
      "Loading data to table default.drivers_csv\n",
      "OK\n",
      "Time taken: 0.483 seconds\n",
      "SELECT * FROM drivers_csv LIMIT 5;\n",
      "OK\n",
      "driverId\tname\tssn\tlocation\tcertified\twage-plan\n",
      "10\tGeorge Vetticaden\t621011971\t244-4532 Nulla Rd.\tN\tmiles\n",
      "11\tJamie Engesser\t262112338\t366-4125 Ac Street\tN\tmiles\n",
      "12\tPaul Coddin\t198041975\tAp #622-957 Risus. Street\tY\thours\n",
      "13\tJoe Niemiec\t139907145\t2071 Hendrerit. Ave\tY\thours\n",
      "Time taken: 0.107 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS drivers_csv;\n",
    "\n",
    "CREATE TABLE drivers_csv (driverId  INT, \n",
    "                         name      STRING, \n",
    "                         ssn       BIGINT,\n",
    "                         location  STRING, \n",
    "                         certified STRING, \n",
    "                         wageplan  STRING)\n",
    "ROW FORMAT SERDE \n",
    "    'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "   'separatorChar' = \",\",\n",
    "   'quoteChar'     = '\\'',\n",
    "   'escapeChar'    = \"\\\\\");\n",
    "\n",
    "LOAD DATA INPATH '/tmp/drivers/drivers.csv' OVERWRITE INTO TABLE drivers_csv;\n",
    "\n",
    "SELECT * FROM drivers_csv LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga usando expresiones regulaes y RegexSerDe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se realiza la carga de datos especificando los campos mediante el uso de expresiones regulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Copia los archivos al HDFS\n",
    "##\n",
    "!hdfs dfs -copyFromLocal drivers/drivers.csv  /tmp/drivers/drivers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS drivers_regex;\n",
      "OK\n",
      "Time taken: 0.052 seconds\n",
      "CREATE TABLE drivers_regex(\n",
      "    driverId  INT, \n",
      "    name      STRING, \n",
      "    ssn       BIGINT,\n",
      "    location  STRING, \n",
      "    certified STRING, \n",
      "    wageplan  STRING)\n",
      "ROW FORMAT SERDE \n",
      "    'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
      "WITH SERDEPROPERTIES (\n",
      "   'input.regex' = '(\\\\d+),([^,]*),(\\\\d+),([^,]*),([^,]*),([^,]*)')\n",
      "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\n",
      "OK\n",
      "Time taken: 0.049 seconds\n",
      "egex;\n",
      "Loading data to table default.drivers_regex\n",
      "OK\n",
      "Time taken: 0.438 seconds\n",
      "SELECT * FROM drivers_regex LIMIT 5;\n",
      "OK\n",
      "10\tGeorge Vetticaden\t621011971\t244-4532 Nulla Rd.\tN\tmiles\n",
      "11\tJamie Engesser\t262112338\t366-4125 Ac Street\tN\tmiles\n",
      "12\tPaul Coddin\t198041975\tAp #622-957 Risus. Street\tY\thours\n",
      "13\tJoe Niemiec\t139907145\t2071 Hendrerit. Ave\tY\thours\n",
      "14\tAdis Cesir\t820812209\tAp #810-1228 In St.\tY\thours\n",
      "Time taken: 0.102 seconds, Fetched: 5 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%hive\n",
    "DROP TABLE IF EXISTS drivers_regex;\n",
    "\n",
    "CREATE TABLE drivers_regex(\n",
    "    driverId  INT, \n",
    "    name      STRING, \n",
    "    ssn       BIGINT,\n",
    "    location  STRING, \n",
    "    certified STRING, \n",
    "    wageplan  STRING)\n",
    "ROW FORMAT SERDE \n",
    "    'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES (\n",
    "   'input.regex' = '(\\\\d+),([^,]*),(\\\\d+),([^,]*),([^,]*),([^,]*)')\n",
    "TBLPROPERTIES (\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "LOAD DATA INPATH '/tmp/drivers/drivers.csv' OVERWRITE INTO TABLE drivers_regex;\n",
    "\n",
    "SELECT * FROM drivers_regex LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión regular usada es la siguiente: \n",
    "\n",
    "    (\\\\d+),([^,]*),(\\\\d+),([^,]*),([^,]*),([^,]*)`\n",
    "\n",
    "donde:\n",
    "\n",
    "* Los paréntesis indica los campos, esto es, `(\\\\d+)` es el primer campo, `([^,]*)` es el segundo y así sucesivamente.\n",
    "\n",
    "* Se indica que la coma es el separador entre campos.\n",
    "\n",
    "* `(\\\\d+)` representa una cadena de uno o más dígitos.\n",
    "\n",
    "* `[...]` representan uno o más posibles caracteres, de tal forma que `[^,]` indica cualquier caracter excepto una coma. Finalmente, el * indica cero, una o más ocurrencias. Es así como `[^,]*` representa cualquier cadena de caracteres que no contenga una coma.\n",
    "\n",
    "* La expresión regular usada indica que los campos 1 y 3 son numéricos, y los restantes son texto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
