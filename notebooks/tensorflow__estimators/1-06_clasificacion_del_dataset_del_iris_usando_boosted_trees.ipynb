{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación del dataset del iris usando boosted trees\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *30 min* | Última modificación: Abril 6, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "#\n",
    "# Establece el nivel de reporte en\n",
    "# pantalla de TensorFlow\n",
    "#\n",
    "import logging\n",
    "\n",
    "logger = tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y configuración del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 21\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SepalLength  100 non-null    float64\n",
      " 1   SepalWidth   100 non-null    float64\n",
      " 2   PetalLength  100 non-null    float64\n",
      " 3   PetalWidth   100 non-null    float64\n",
      " 4   Species      100 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 4.7 KB\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"]\n",
    "\n",
    "target_dimensions = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
    "\n",
    "training_data_path = tf.keras.utils.get_file(\n",
    "    \"iris_ training.csv\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\",\n",
    ")\n",
    "\n",
    "test_data_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\",\n",
    ")\n",
    "\n",
    "training = pd.read_csv(training_data_path, names=col_names, header=0)\n",
    "training = training[training[\"Species\"] >= 1]\n",
    "training[\"Species\"] = training[\"Species\"].replace([1, 2], [0, 1])\n",
    "training.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test = pd.read_csv(test_data_path, names=col_names, header=0)\n",
    "test = test[test[\"Species\"] >= 1]\n",
    "test[\"Species\"] = test[\"Species\"].replace([1, 2], [0, 1])\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.concat([training, test], axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#\n",
    "#  Partición de los datos. La función retorno un objeto\n",
    "#  pandas.DataFrame para X y un objeto pandas.Series para\n",
    "#  y\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[[c for c in df.columns if c != \"Species\"]], df[\"Species\"], test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#\n",
    "#  El preprocesador retorna una numpy.ndarray y debe\n",
    "#  transformarse nuevamente en un pandas.DataFrame\n",
    "#\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns).astype(\n",
    "    np.float32\n",
    ")\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns).astype(\n",
    "    np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificación de los parámetros del estimador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "\n",
    "    return input_function\n",
    "\n",
    "\n",
    "train_input_fn = make_input_fn(X_train, y_train, num_epochs=1, shuffle=False)\n",
    "\n",
    "test_input_fn = make_input_fn(X_test, y_test, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Crea una lista con los tipos de las columnas\n",
    "#  del dataframe de entrada\n",
    "#\n",
    "feature_columns = [tf.feature_column.numeric_column(m) for m in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x7f77ac596390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btree_model = tf.estimator.BoostedTreesClassifier(\n",
    "    feature_columns=feature_columns, n_batches_per_layer=1\n",
    ")\n",
    "btree_model.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronósticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = btree_model.predict(train_input_fn)\n",
    "train_predictions = pd.Series(\n",
    "    [p[\"classes\"][0].decode(\"utf-8\") for p in train_predictions]\n",
    ")\n",
    "\n",
    "test_predictions = btree_model.predict(test_input_fn)\n",
    "test_predictions = pd.Series(\n",
    "    [p[\"classes\"][0].decode(\"utf-8\") for p in test_predictions]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Accuracy =  0.9375\n",
      "Training Data Score =  0.9743589743589743\n",
      "Training Data Recall =  0.9047619047619048\n",
      "\n",
      "Testing Data Accuracy =  0.9\n",
      "Testing Data Score =  0.8\n",
      "Testing Data Recall =  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def calculate_errors_and_r2(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred.astype(\"int64\"))\n",
    "    precision = precision_score(y_true, y_pred.astype(\"int64\"))\n",
    "    recall = recall_score(y_true, y_pred.astype(\"int64\"))\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "\n",
    "(\n",
    "    train_accuracy_score,\n",
    "    train_precision_score,\n",
    "    train_recall_score,\n",
    ") = calculate_errors_and_r2(y_train, train_predictions)\n",
    "\n",
    "(\n",
    "    test_accuracy_score,\n",
    "    test_precision_score,\n",
    "    test_recall_score,\n",
    ") = calculate_errors_and_r2(y_test, test_predictions)\n",
    "\n",
    "print(\"Training Data Accuracy = \", train_accuracy_score)\n",
    "print(\"Training Data Score = \", train_precision_score)\n",
    "print(\"Training Data Recall = \", train_recall_score)\n",
    "print()\n",
    "print(\"Testing Data Accuracy = \", test_accuracy_score)\n",
    "print(\"Testing Data Score = \", test_precision_score)\n",
    "print(\"Testing Data Recall = \", test_recall_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
