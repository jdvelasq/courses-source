{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ffebef7-195c-415c-8b23-4d8511bb7f70",
   "metadata": {
    "tags": []
   },
   "source": [
    "Entrenamiento personalizado con tf.distribute.Strategy --- 0:00 min\n",
    "===\n",
    "\n",
    "* Última modificación: Marzo 1, 2022 | YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc48073-ceee-46d0-9b5a-ba0cb29ec56f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Importación de librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e20dd6-aa07-45fb-ba8f-51c609c98a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177674e9-a7e7-4b80-87b8-078286e27fab",
   "metadata": {},
   "source": [
    "Descarga de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a02678-83fe-41a5-85dd-1bfc8606d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "40960/29515 [=========================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 5s 0us/step\n",
      "26435584/26421880 [==============================] - 5s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 5s 1us/step\n",
      "4431872/4422102 [==============================] - 5s 1us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m train_images \u001b[38;5;241m=\u001b[39m train_images[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m      7\u001b[0m test_images \u001b[38;5;241m=\u001b[39m test_images[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m---> 10\u001b[0m train_images \u001b[38;5;241m=\u001b[39m train_images \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     11\u001b[0m test_images \u001b[38;5;241m=\u001b[39m test_images \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), (\n",
    "    test_images,\n",
    "    test_labels,\n",
    ") = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images[..., None]\n",
    "test_images = test_images[..., None]\n",
    "\n",
    "\n",
    "train_images = train_images / np.float32(255)\n",
    "test_images = test_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd60e92-4d7c-4716-8e68-17ba5b38dcf0",
   "metadata": {},
   "source": [
    "Creación de la estrategia\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a249f43e-e15a-4f1c-aab2-616bf17a4ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5eb82b-dc63-425a-9048-db641054f370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba63e02-2f08-40d5-9324-909dffaa2cef",
   "metadata": {},
   "source": [
    "Tubería de entrada\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f57d0b-3ae0-4675-8416-e54300cdafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_images)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e9379a-c60a-4031-a4b0-a4bbc38b5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(GLOBAL_BATCH_SIZE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(\n",
    "    GLOBAL_BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085901cd-2d5e-45d3-90c8-c590db6be2c9",
   "metadata": {},
   "source": [
    "Creación del modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "748c79bf-faff-4be7-80bf-85d911ecc370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a8df77-2c76-47ae-a636-609acaa091b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Directorio para almacenar los checkpoints\n",
    "#\n",
    "checkpoint_dir = \"/tmp/training_checkpoints\"\n",
    "\n",
    "#\n",
    "# Nombres de los archivos\n",
    "#\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52a792-af0b-4b4c-8a06-585cc1033ba9",
   "metadata": {},
   "source": [
    "Definición de la función de pérdida\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5c7d36-0533-4aba-89a3-da8d65ec8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(\n",
    "            per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af770a-1326-4fe9-9c02-66f86776716f",
   "metadata": {},
   "source": [
    "Métricas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7da4d68-3c2a-4303-8f65-97d7a257fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a122db-4b64-403b-8012-a9d6df0b8c3e",
   "metadata": {},
   "source": [
    "Ciclo de entrenamiento\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d8c91e-c277-4347-84dd-c29d5556524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78387a14-125a-4169-8924-6960cf206040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "\n",
    "    images, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test_step(inputs):\n",
    "\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1bf6fa4-2d6e-442d-9a86-cf705bbcbb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: in user code:\n",
      "\n",
      "    File \"/tmp/ipykernel_2148/3476027335.py\", line 6, in train_step  *\n",
      "        predictions = model(images, training=True)\n",
      "    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "    TypeError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n",
      "    \n",
      "    Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n",
      "    \n",
      "    Call arguments received:\n",
      "      • inputs=tf.Tensor(shape=(64, 28, 28, 1), dtype=uint8)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\n",
      "    yield\n",
      "  File \"/usr/local/lib/python3.9/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 342, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "TypeError: in user code:\n",
      "\n",
      "    File \"/tmp/ipykernel_2148/3476027335.py\", line 6, in train_step  *\n",
      "        predictions = model(images, training=True)\n",
      "    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "    TypeError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n",
      "    \n",
      "    Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n",
      "    \n",
      "    Call arguments received:\n",
      "      • inputs=tf.Tensor(shape=(64, 28, 28, 1), dtype=uint8)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_2148/4171982643.py\", line 3, in distributed_train_step  *\n        per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n    File \"/tmp/ipykernel_2148/3476027335.py\", line 6, in train_step  *\n        predictions = model(images, training=True)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n    \n    Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(64, 28, 28, 1), dtype=uint8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train_dist_dataset:\n\u001b[0;32m---> 19\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m distributed_train_step(x)\n\u001b[1;32m     20\u001b[0m     num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m num_batches\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_2148/4171982643.py\", line 3, in distributed_train_step  *\n        per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n    File \"/tmp/ipykernel_2148/3476027335.py\", line 6, in train_step  *\n        predictions = model(images, training=True)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n    \n    Value passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(64, 28, 28, 1), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    #\n",
    "    # Entrenamiento\n",
    "    #\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for x in train_dist_dataset:\n",
    "        total_loss += distributed_train_step(x)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    #\n",
    "    # Prueba\n",
    "    #\n",
    "    for x in test_dist_dataset:\n",
    "        distributed_test_step(x)\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\"\n",
    "    print(\n",
    "        template.format(\n",
    "            epoch + 1,\n",
    "            train_loss,\n",
    "            train_accuracy.result() * 100,\n",
    "            test_loss.result(),\n",
    "            test_accuracy.result() * 100,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e12e1-0f38-4c93-9945-ff5c6e0b4e27",
   "metadata": {},
   "source": [
    "Restauración del modelo desde el último checkpoint y prueba\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef56266-0bbb-4ba3-b96a-d3821e2f0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"eval_accuracy\")\n",
    "\n",
    "new_model = create_model()\n",
    "new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(\n",
    "    GLOBAL_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb071767-7cf6-4f1c-aafd-f22c11c02309",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(images, labels):\n",
    "    predictions = new_model(images, training=False)\n",
    "    eval_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6bf86-cff0-44c8-a947-383b9330ffaf",
   "metadata": {},
   "source": [
    "Mecanismos alternativos para iterar sobre un dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ccdc8-7f73-4731-b303-91b22047f048",
   "metadata": {},
   "source": [
    "**Iteradores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab941fe8-fe18-47ab-9c08-95fffe02b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    train_iter = iter(train_dist_dataset)\n",
    "\n",
    "    for _ in range(10):\n",
    "        total_loss += distributed_train_step(next(train_iter))\n",
    "        num_batches += 1\n",
    "    average_train_loss = total_loss / num_batches\n",
    "\n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}\"\n",
    "    print(template.format(epoch + 1, average_train_loss, train_accuracy.result() * 100))\n",
    "    train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48395cf-6c59-471d-ba9e-2da7d4a582c5",
   "metadata": {},
   "source": [
    "**Iteración dentro de tf.function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ccacb-c10c-49a2-968b-7f8d684dc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def distributed_train_epoch(dataset):\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for x in dataset:\n",
    "        per_replica_losses = strategy.run(train_step, args=(x,))\n",
    "        total_loss += strategy.reduce(\n",
    "            tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None\n",
    "        )\n",
    "        num_batches += 1\n",
    "    return total_loss / tf.cast(num_batches, dtype=tf.float32)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = distributed_train_epoch(train_dist_dataset)\n",
    "\n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}\"\n",
    "    print(template.format(epoch + 1, train_loss, train_accuracy.result() * 100))\n",
    "\n",
    "    train_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
