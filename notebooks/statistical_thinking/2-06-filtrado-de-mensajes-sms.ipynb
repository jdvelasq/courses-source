{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrado de spam en mensajes de texto SMS --- 31:12 min\n",
    "===\n",
    "\n",
    "* 31:12 min | Última modificación: Abril 5, 2021 | [YouTube](https://youtu.be/bl361y9rFNUhttps://youtu.be/bl361y9rFNU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliografía.** Machine Learning with R. Brett Lantz, Packt Publishing, Second Edition, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los clasificadores Bayesianos ingenuos son herramientas de gran utilidad para la construcción de sistemas de clasificación, como ya se discutio en los tutoriales anteriores. En este tutorial se utiliza un clasificador Bayesiano ingenuo para determinar si un mensaje SMS es válido o es spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/sms-spam.csv\",\n",
    "    sep=\",\",\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5574</td>\n",
       "      <td>5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4827</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                    text\n",
       "count   5574                    5574\n",
       "unique     2                    5160\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4827                      30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Verifica la lectura de los datos\n",
    "#\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteo de cantidad de mensajes por tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4827\n",
       "spam     747\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se obtiene la cantidad de casos para\n",
    "# cada tipo de mensaje.\n",
    "#\n",
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.type.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.6\n",
       "spam    13.4\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se convierte el conteo anterior en probabilidades.\n",
    "#\n",
    "round(100 * df.type.value_counts() / sum(df.type.value_counts()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point, crazy.. avail onli in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar... joke wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri in 2 a wkli comp to win FA cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so earli hor... U c alreadi then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah I don't think he goe to usf, he live aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey there darl it' been 3 week' now an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>As per your request 'mell mell (oru minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner!! As a valu network custom you have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>had your mobil 11 month or more? U R entitl to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6   ham  Even my brother is not like to speak with me. ...   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8  spam  WINNER!! As a valued network customer you have...   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  Go until jurong point, crazy.. avail onli in b...  \n",
       "1                        Ok lar... joke wif u oni...  \n",
       "2  free entri in 2 a wkli comp to win FA cup fina...  \n",
       "3  U dun say so earli hor... U c alreadi then say...  \n",
       "4  nah I don't think he goe to usf, he live aroun...  \n",
       "5  freemsg hey there darl it' been 3 week' now an...  \n",
       "6  even my brother is not like to speak with me. ...  \n",
       "7  As per your request 'mell mell (oru minnaminun...  \n",
       "8  winner!! As a valu network custom you have bee...  \n",
       "9  had your mobil 11 month or more? U R entitl to...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#\n",
    "# Se construye un stemmer que reduce una palabra a su raiz o 'stem'.\n",
    "# {llorar, lloramos, lloraron} -> llorar\n",
    "# {biblioteca, bibliotecario} -> bibliotec\n",
    "#\n",
    "stemmer = PorterStemmer()\n",
    "df[\"stemmed\"] = df.text.apply(lambda x: \" \".join([stemmer.stem(w) for w in x.split()]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Términos del Documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 1540)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Matriz de términos del documento en Python\n",
    "#\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#\n",
    "# Stopwords: \n",
    "#   i  me  my  myself  we  our  ours  ourselves ....\n",
    "#   am  is  are  was  were  be  been  being  have \n",
    "#   has  had  having  do  does  did  doing  ...\n",
    "#   a  an  the  and  but  if  or  because  as  until\n",
    "#   while  of  at  by  for  with  about  against ...\n",
    "#   ...\n",
    "#\n",
    "# token_pattern:\n",
    "# https://docs.python.org/3/howto/regex.html#regex-howto\n",
    "#\n",
    "#   \\w cualquier caracter alfanumerico [a-zA-Z0-9_]\n",
    "#   \\w\\w+ cadenas de dos o mas caracteres \n",
    "#   \\b  word boundary\n",
    "#\n",
    "count_vect = CountVectorizer(\n",
    "    analyzer=\"word\",                # a nivel de palabra\n",
    "    lowercase=True,                 # convierte a minúsculas\n",
    "    stop_words=\"english\",           # stop_words en inglés\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\", # patrones a reconocer\n",
    "    binary=True,                    # Los valores distintos de cero son fijados en 1\n",
    "    max_df=1.0,                     # máxima frecuencia a considerar\n",
    "    min_df=5,                       # ignora palabras con baja frecuencia\n",
    ")\n",
    "\n",
    "#\n",
    "# Aplica la función al texto\n",
    "#\n",
    "dtm = count_vect.fit_transform(df.stemmed)\n",
    "\n",
    "#\n",
    "# Las filas contienen los mensajes\n",
    "# y las clomunas los términos\n",
    "#\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Palabras aprendidas de los mensajes de texto\n",
    "#\n",
    "vocabulary = count_vect.get_feature_names()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '06',\n",
       " '0800',\n",
       " '08000839402',\n",
       " '08000930705',\n",
       " '0870']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Primeras palabras del vocabulario\n",
    "#\n",
    "vocabulary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 1423)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se puede mejorar diciendo que solo se reconozcan\n",
    "# palabras formadas por letras\n",
    "#\n",
    "count_vect = CountVectorizer(\n",
    "    analyzer=\"word\",                \n",
    "    lowercase=True,                 \n",
    "    stop_words=\"english\",           \n",
    "    token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\", \n",
    "    binary=True,                    \n",
    "    max_df=1.0,                     \n",
    "    min_df=5,                       \n",
    ")\n",
    "\n",
    "dtm = count_vect.fit_transform(df.stemmed)\n",
    "\n",
    "#\n",
    "# Las filas contienen los mensajes\n",
    "# y las clomunas los términos\n",
    "#\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aathi',\n",
       " 'abiola',\n",
       " 'abl',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'acc',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'account',\n",
       " 'act']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = count_vect.get_feature_names()\n",
    "vocabulary[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org:  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Mod:  avail bugi cine got great la onli point wat world\n",
      "\n",
      "Org:  Ok lar... Joking wif u oni...\n",
      "Mod:  joke lar ok wif\n",
      "\n",
      "Org:  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "Mod:  appli comp cup entri final free question rate receiv std text txt win wkli\n",
      "\n",
      "Org:  U dun say so early hor... U c already then say...\n",
      "Mod:  alreadi dun earli say\n",
      "\n",
      "Org:  Nah I don't think he goes to usf, he lives around here though\n",
      "Mod:  don goe live nah think usf\n",
      "\n",
      "Org:  FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\n",
      "Mod:  darl freemsg fun hey like ok send std week word xxx\n",
      "\n",
      "Org:  Even my brother is not like to speak with me. They treat me like aids patent.\n",
      "Mod:  brother like speak treat\n",
      "\n",
      "Org:  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "Mod:  callers callertun copi friend ha press request set\n",
      "\n",
      "Org:  WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "Mod:  claim code custom hour network prize reward select valid valu winner\n",
      "\n",
      "Org:  Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "Mod:  camera colour entitl free latest mobil month updat\n",
      "\n",
      "Org:  I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "Mod:  don gonna home soon stuff talk thi today tonight want\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Recupera los mensajes de la dtm\n",
    "#\n",
    "def dtm2words(dtm, vocabulary, index):\n",
    "    as_list = dtm[index, :].toarray().tolist()\n",
    "    docs = []\n",
    "    for i in index:\n",
    "        k = [vocabulary[iword] for iword, ifreq in enumerate(as_list[i]) if ifreq > 0]\n",
    "        docs += [k]\n",
    "    return docs\n",
    "\n",
    "\n",
    "for i, x in enumerate(dtm2words(dtm, vocabulary, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])):\n",
    "    print(\"Org: \", df.text[i])\n",
    "    print(\"Mod: \", \" \".join(x))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.5\n",
       "spam    13.5\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Creación de los conjuntos de entrenamiento y prueba.\n",
    "#\n",
    "X_train = dtm[\n",
    "    0:4168,\n",
    "]\n",
    "X_test = dtm[\n",
    "    4169:,\n",
    "]\n",
    "\n",
    "y_train_true = df.type[0:4168]\n",
    "y_test_true = df.type[4169:]\n",
    "\n",
    "#\n",
    "# Distribución de los datos en el conjunto de entrenamiento.\n",
    "#\n",
    "round(100 * y_train_true.value_counts() / sum(y_train_true.value_counts()), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     87.0\n",
       "spam    13.0\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Distribución de los datos en el conjunto de entrenamiento.\n",
    "#\n",
    "round(100 * y_test_true.value_counts() / sum(y_test_true.value_counts()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#\n",
    "# Se crea un clasificador Naive Bayes (NB)\n",
    "#\n",
    "clf = BernoulliNB()\n",
    "\n",
    "#\n",
    "# Se entrena el clasificador\n",
    "#\n",
    "clf.fit(X_train.toarray(), y_train_true)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se pronostica para los datos de prueba.\n",
    "#\n",
    "y_test_pred = clf.predict(X_test.toarray())\n",
    "y_test_pred_prob = clf.predict_proba(X_test.toarray())\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1213,    9],\n",
       "       [  17,  166]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Métricas de desempeño\n",
    "#\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true=y_test_true, y_pred=y_test_pred)\n",
    "\n",
    "#\n",
    "# Pronostico en las columnas\n",
    "# Real en las filas\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.56782069e-11, 1.00000000e+00],\n",
       "       [9.97507164e-01, 2.49283632e-03],\n",
       "       [9.97748935e-01, 2.25106470e-03],\n",
       "       ...,\n",
       "       [9.99944765e-01, 5.52350469e-05],\n",
       "       [9.99580765e-01, 4.19235040e-04],\n",
       "       [9.99850227e-01, 1.49773007e-04]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_type</th>\n",
       "      <th>predict_type</th>\n",
       "      <th>prob_ham</th>\n",
       "      <th>prob_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>2.567821e-11</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>9.975072e-01</td>\n",
       "      <td>2.492836e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>9.977489e-01</td>\n",
       "      <td>2.251065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.382815e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>4.133793e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual_type predict_type      prob_ham     prob_spam\n",
       "4169        spam         spam  2.567821e-11  1.000000e+00\n",
       "4170         ham          ham  9.975072e-01  2.492836e-03\n",
       "4171         ham          ham  9.977489e-01  2.251065e-03\n",
       "4172         ham          ham  1.000000e+00  1.382815e-08\n",
       "4173         ham          ham  9.999996e-01  4.133793e-07"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Resulta más conveniente preparar una nueva tabla que\n",
    "# muestre la clasificación y no únicamente las\n",
    "# probabilidades.\n",
    "#\n",
    "results = pd.DataFrame(\n",
    "    data={\n",
    "        \"actual_type\": y_test_true,\n",
    "        \"predict_type\": y_test_pred,\n",
    "        \"prob_ham\": [v[0] for v in y_test_pred_prob],\n",
    "        \"prob_spam\": [v[1] for v in y_test_pred_prob],\n",
    "    }\n",
    ")\n",
    "\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_type</th>\n",
       "      <th>predict_type</th>\n",
       "      <th>prob_ham</th>\n",
       "      <th>prob_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.996469</td>\n",
       "      <td>0.003531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.862745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.831411</td>\n",
       "      <td>0.168589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.783809</td>\n",
       "      <td>0.216191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.075089</td>\n",
       "      <td>0.924911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.950103</td>\n",
       "      <td>0.049897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.932296</td>\n",
       "      <td>0.067704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.086534</td>\n",
       "      <td>0.913466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.619568</td>\n",
       "      <td>0.380432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.998462</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.691872</td>\n",
       "      <td>0.308128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>0.985124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.999896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.582984</td>\n",
       "      <td>0.417016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.924987</td>\n",
       "      <td>0.075013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.995243</td>\n",
       "      <td>0.004757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.997742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.443998</td>\n",
       "      <td>0.556002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.266868</td>\n",
       "      <td>0.733132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.990915</td>\n",
       "      <td>0.009085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>0.838561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.998762</td>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.959811</td>\n",
       "      <td>0.040189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.818033</td>\n",
       "      <td>0.181967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.001882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual_type predict_type  prob_ham  prob_spam\n",
       "4213        spam          ham  0.996469   0.003531\n",
       "4253         ham         spam  0.137255   0.862745\n",
       "4256        spam          ham  0.831411   0.168589\n",
       "4295        spam          ham  0.783809   0.216191\n",
       "4344         ham         spam  0.075089   0.924911\n",
       "4373        spam          ham  0.950103   0.049897\n",
       "4394        spam          ham  0.932296   0.067704\n",
       "4399         ham         spam  0.086534   0.913466\n",
       "4475        spam          ham  0.619568   0.380432\n",
       "4514        spam          ham  0.998462   0.001538\n",
       "4527        spam          ham  0.691872   0.308128\n",
       "4729         ham         spam  0.014876   0.985124\n",
       "4773         ham         spam  0.000104   0.999896\n",
       "4821        spam          ham  0.582984   0.417016\n",
       "4914        spam          ham  0.924987   0.075013\n",
       "4968        spam          ham  0.995243   0.004757\n",
       "5046         ham         spam  0.002258   0.997742\n",
       "5056         ham         spam  0.443998   0.556002\n",
       "5106         ham         spam  0.266868   0.733132\n",
       "5112        spam          ham  0.990915   0.009085\n",
       "5326         ham         spam  0.161439   0.838561\n",
       "5383        spam          ham  0.998667   0.001333\n",
       "5429        spam          ham  0.998762   0.001238\n",
       "5451        spam          ham  0.959811   0.040189\n",
       "5468        spam          ham  0.818033   0.181967\n",
       "5542        spam          ham  0.998118   0.001882"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Mensajes con clasificación errónea.\n",
    "# Resulta muy importante determinar porque los\n",
    "# mensajes están mal clasificados\n",
    "#\n",
    "results[results[\"actual_type\"] != results[\"predict_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_type</th>\n",
       "      <th>predict_type</th>\n",
       "      <th>prob_ham</th>\n",
       "      <th>prob_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.582984</td>\n",
       "      <td>0.417016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.443998</td>\n",
       "      <td>0.556002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.462431</td>\n",
       "      <td>0.537569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual_type predict_type  prob_ham  prob_spam\n",
       "4821        spam          ham  0.582984   0.417016\n",
       "5056         ham         spam  0.443998   0.556002\n",
       "5122        spam         spam  0.462431   0.537569"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Sin embargo, es mucho más intersante extraer\n",
    "# mensajes con probabilidades numéricamente\n",
    "# cercanas a 0.5. Estos podrían generar ambiguedad\n",
    "# en la clasificación.\n",
    "#\n",
    "results[(results[\"prob_spam\"] > 0.4) & (results[\"prob_spam\"] < 0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_type</th>\n",
       "      <th>predict_type</th>\n",
       "      <th>prob_ham</th>\n",
       "      <th>prob_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.582984</td>\n",
       "      <td>0.417016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.443998</td>\n",
       "      <td>0.556002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual_type predict_type  prob_ham  prob_spam\n",
       "4821        spam          ham  0.582984   0.417016\n",
       "5056         ham         spam  0.443998   0.556002"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Mensajes mal clasificados con probabilidad cercana a 0.5\n",
    "#\n",
    "results[\n",
    "    (results[\"prob_spam\"] > 0.4)\n",
    "    & (results[\"prob_spam\"] < 0.6)\n",
    "    & (results[\"actual_type\"] != results[\"predict_type\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta.---** Si en la construcción del clasificador se hace `laplace = 1`, en cuanto mejora la precisión del modelo. "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
