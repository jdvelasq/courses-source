{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Probabilidad condicional, Naive Bayes y Clasificadores de Texto --- 42:12 min\n",
    "===\n",
    "\n",
    "* 40:12 min | Ultima modificación: Abril 5, 2021 | [YouTube](https://youtu.be/T4x6KNfOQek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los [clasificadores bayesianos ingenuos](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo) son un tipo de clasificador probabilistico en el que se considera que cada característica de una instancia contribuye independientemente de las demás a que un objeto pertenezca a una clase determinada. Mientras que en la inducción de reglas de asociación (algoritmo 1R) solamente se considera una sola característica para determinar a que clase pertence una instancia, en un clasificador ingenuo se consideran simultáneamente todas las características. En este tutorial se describen los fundamentos matemáticos en que se soporta este tipo de clasificadores y como se aplican a casos reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Definición del problema \n",
    "\n",
    "En este tutorial se aborda el problema de determinar si un mensaje de texto es válido o spam. Este es un problema típico de minería de texto. Desde el punto de vista del negocio, la recepción de publicidad no deseada y mensajes fraudulentos es un problema que afecta a muchos usuarios; y es por ello, que las compañias prestadoras de servicios desean filtrar este tipo de mensajes con el fin de evitar el consumo de espacio en su infraestructura y la molestia para el usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Se tiene una muestra conformada por los siguientes mensajes:\n",
    "\n",
    "\n",
    "     #  Tipo    Mensaje\n",
    "    ---------------------------------------\n",
    "     1  spam    w1 w3 \n",
    "     2  spam    w1 w2 w1 w3\n",
    "     3  ham     w2 w4 \n",
    "     4  ham     w4 w5 w2\n",
    "     5  ham     w2 w4 w2\n",
    "\n",
    "\n",
    "El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítimo o spam, a partir del análisis de las palabras que contiente; se supone que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conceptos y Definiciones Básicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De los tutoriales anteriores, se sabe que si las variables $x_i$ representan los eventos posibles, entonces:\n",
    "\n",
    "* Todas las probabilidades deben estar entre $0$ y $1$: \n",
    "\n",
    "\n",
    "$$0 \\le \\text{Pr}(x_i) \\le 1$$\n",
    "\n",
    "\n",
    "* Las probabilidades de eventos mutuamente exclusivos (no pueden ocurrir simultáneamente) y colectivamente exhaustivos (cubren todo el universo de casos posibles) deben sumar la unidad:\n",
    "\n",
    "$$\\sum_{i=1}^n \\text{Pr}(x_i) = 1$$\n",
    "\n",
    "En las siguientes figuras, los eventos F1, F2 y F3, y V1 y V2 están definidos sobre el mismo universo; y son mutuamente exclusivos y colectivamente exhaustivos, tal que se cumplen las dos propiedades anteriores\n",
    "\n",
    "![assets/eventos-conjuntos-2.jpg](assets/eventos-conjuntos-2.jpg)\n",
    "\n",
    "\n",
    "$$\\text{Pr}(F1) + \\text{Pr}(F2) + \\text{Pr}(F3) = 1, \\quad \\qquad \\text{Pr}(V1) + \\text{Pr}(V2) = 1$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilidad conjunta\n",
    "\n",
    "Los eventos considerados ocurren simultáneamente. En la siguiente figura, los eventos F1 y V2 ocurren simultáneamente (área sombreada de la figura), tal que su probabilidad conjunta es:\n",
    "\n",
    "$$\\text{Pr}(F1~\\text{and}~V2)$$\n",
    "\n",
    "![assets/probabilidad-conjunta-3.jpg](assets/probabilidad-conjunta-3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Probabilidad condicional\n",
    "\n",
    "Es la probabilidad de que ocurra un evento sabiendo que el otro ya ocurrio. En la siguiente figura el evento V2 es condicionar a la ocurrencia F1. Noté que en la siguiente figura, el universo no es el rectángulo anterior que cubre todos los eventos, si no el evento F1. De esta forma, la probabilidad condicional es sólo la proporción de V2 que se intercepta con F1, la cual corresponde a la porción sombreada de la figura de abajo. La siguiente expresión matemática permite calcular la probabilidad condicional en términos de la probabilidad conjunta.\n",
    "\n",
    "$$\\text{Pr}(V2 \\; | \\; F1) = \\text{Pr}(F1 \\; \\text{and} \\; V2) \\; / \\; \\text{Pr}(F1)$$\n",
    "\n",
    "En otras palabras, \n",
    "\n",
    "$$\\text{Pr}(A \\; | \\; B) * \\text{Pr}(B) = \\text{Pr}(A \\; \\text{and} \\; B)$$\n",
    "\n",
    "para dos eventos A y B.\n",
    "\n",
    "![assets/probabilidad-condicional.jpg](assets/probabilidad-condicional.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independencia\n",
    "\n",
    "Si los eventos $A$ y $B$ son independientes, la probabilidad condicional del evento A dado que ocurrio el evento B es igual a la probabilidad del evento A:\n",
    "\n",
    "$$\\text{Pr}(A \\; |  \\; B) = \\text{Pr}(A)$$\n",
    "\n",
    "De la definición de probabilidad condicional:\n",
    "\n",
    "$$\\text{Pr}(A  \\; |  \\; B) = \\text{Pr}(A) = \\frac{\\text{Pr}(A\\text{ and }B)}{\\text{Pr}(B)}$$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\\text{Pr}(A\\text{ and } B) \\; =  \\; \\text{Pr}(A) \\; * \\; \\text{Pr}(B)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilidad marginal \n",
    "\n",
    "Sea $X_1$ con $i = 1, ... , n$ , un conjunto de eventos mutuamente exclusivos y colectivamente exhaustivos. La probabilidad de un evento $A$ es:\n",
    "\n",
    "$$\\text{Pr}(A) = \\sum_{i=1}^n \\text{Pr}(A\\text{ and }X_i)$$\n",
    "\n",
    "En la siguiente figura se puede observar que para cualquiera de los tres eventos $F_j$ (para $j=1,2,3$)\n",
    "\n",
    "$$\\text{Pr}(F_j) = \\text{Pr}(F_j\\text{ and }V_1) + \\text{Pr}(F_j\\text{ and }V_2)$$\n",
    "\n",
    "y que para los dos eventos $V_i$ ($i=1,2$):\n",
    "\n",
    "$$\\text{Pr}(V_i) = \\text{Pr}(V_i\\text{ and }F_1) + \\text{Pr}(V_i\\text{ and }F_2) + \\text{Pr}(V_i\\text{ and }F_3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![assets/eventos-conjuntos.jpg](assets/eventos-conjuntos.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unión (OR)\n",
    "\n",
    "Para dos eventos $A$ y $B$:\n",
    "\n",
    "$$\\text{Pr}(A \\text{ or } B) = \\text{Pr}(A) + \\text{Pr}(B) - \\text{Pr}(A\\text{ and }B)$$\n",
    "\n",
    "En la figura de abajo se observa que al unir las regiones de los eventos F1 y V2, las áreas se traslapan y por tanto hay que restar la intersección.\n",
    "\n",
    "![assets/probabilidad-conjunta.jpg](assets/probabilidad-conjunta-3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Complemento o negación\n",
    "\n",
    "$$\\text{Pr}(\\text{not } A) = 1 - \\text{Pr}(A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Probabilidad total\n",
    "\n",
    "La probabilidad total indica que la probabilidad de un evento A puede calcularse como la probabilidad de que ocurran los eventos A y B simultáneamente más la probabilidad de que ocurran los evento A y *not* B (el complemento de B:\n",
    "\n",
    "$$\\text{Pr}(A) = \\text{Pr}(A\\text{ and } B) + \\text{Pr}(A\\text{ and } \\text{not }B) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la siguiente figura: \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{Pr}(V_2) \n",
    "    & = \\text{Pr}(V_2 \\text{ and } F_1) + \\text{Pr}(V_2 \\text{ and not } F_1) \\\\ \\\\\n",
    "    & = \\text{Pr}(V_2 \\text{ and } F_1) + \\text{Pr}(V_2 \\text{ and } (F_2 \\cup F_3)) \\\\ \\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![assets/eventos-conjuntos.jpg](assets/eventos-conjuntos.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La ecuación anterior puede expresarse en términos de probabilidades condicionales, tal que:\n",
    "\n",
    "$$\\text{Pr}(A) = \\text{Pr}(A \\; | \\; B) \\; \\text{Pr}(B)  \\; + \\;  \\text{Pr}(A \\; | \\; \\text{not }B)\\text{ Pr}(\\text{not }B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Teorema de Bayes\n",
    "\n",
    "A partir de \n",
    "\n",
    "$$\\text{Pr}(A  \\; |  \\; B) = \\frac{\\text{Pr}(A\\text{ and }B)}{\\text{Pr}(B)},  \n",
    "\\quad \n",
    "\\text{Pr}(B  \\; |  \\; A) = \\frac{\\text{Pr}(A\\text{ and }B)}{\\text{Pr}(A)} $$\n",
    "\n",
    "Se obtiene que:\n",
    "\n",
    "$$\\text{Pr}(A \\; | \\; B)\\text{ Pr}({B}) =  \\text{Pr}(B \\; | \\; A) \\; \\text{Pr}({A})$$\n",
    "\n",
    "Despejando $\\text{Pr}(B \\; | \\; A)$,\n",
    "\n",
    "$$\\text{Pr}(B \\; | \\; A) = \n",
    "    \\frac{\\text{Pr}(A \\; | \\; B) \\; \\text{Pr}(B)}{\\text{Pr}(A)} = \n",
    "    \\frac{\\text{Pr}(A \\; | \\; B)~\\text{Pr}(B)} {\\text{Pr}(A \\; | \\; B) \\; \\text{Pr}(B)  \\; + \\;  \\text{Pr}(A \\; | \\; \\text{not }B) \\; \\text{Pr}(\\text{not }B)}$$\n",
    "    \n",
    "En la última ecuación, se aplica el teorema de probabilidad total para el evento A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Actividad.---** Complete las siguientes tablas de probabilidades:\n",
    "\n",
    "\n",
    "*Probabilidades totales*:\n",
    "\n",
    "\n",
    "               F1    F2    F3  Prob(V)\n",
    "     ----------------------------------\n",
    "         V1   0.10     ?  0.03       ?\n",
    "         V2      ?  0.26  0.14    0.62\n",
    "     ----------------------------------\n",
    "      Prob(F)    ?     ?     ?        \n",
    "    \n",
    "    \n",
    "*Probabilidades condicionales*:\n",
    "\n",
    "    Prob(F|V)                 Prob(V|F)\n",
    "\n",
    "            F1    F2    F3            F1    F2    F3  \n",
    "    ----------------------    ----------------------\n",
    "      V1 10/38     ?     ?      V1     ? 25/51     ?        \n",
    "      V2     ?     ? 14/62      V2     ?     ?     ?  \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Actividad.---** Verifique las dos tablas de probabilidades condicionales calculadas en el ejercicio anterior usando el teorema de Bayes (es decir, calcule `Prob(V|F)` a partir de `Prob(F|V)` y viceversa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación al problema propuesto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En términos del problema de filtrado de mensajes de texto, V1 se interpreta como \"Es spam\" y V2 como NOT \"Es spam\", ya que son eventos mutuamente exclusivos y colectivamente exhaustivos. Si F es la ocurrencia de una determinada palabra en el texto, como por ejemplo \"Viagra\", entonces F1 sería \"Viagra\"(\"viagra\" aparece en el mensaje) y F2 sería NOT \"Viagra\" (\"viagra\" no aparece en el mensaje).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "De acuerdo con el teorema de Bayes:\n",
    "\n",
    "$$\\text{Pr}(\\text{spam} \\; | \\; \\text{viagra}) = \\frac{\\text{Pr}(\\text{viagra} \\, | \\, \n",
    "\\text{spam})*\\text{Pr}(\\text{spam})}{\\text{Pr}(\\text{viagra})}$$\n",
    "\n",
    "* $\\text{Pr}(\\text{spam} \\, | \\, \\text{viagra})$ es la probabilidad posterior.\n",
    "\n",
    "\n",
    "* $\\text{Pr}(\\text{viagra} \\, | \\, \\text{spam})$ es la verosimilitud.\n",
    "\n",
    "\n",
    "* $\\text{Pr}(\\text{spam})$ es la probabilidad prior, es decir, la probabilidad de que un mensaje sea spam sin conocer el texto que contiene.\n",
    "\n",
    "\n",
    "* $\\text{Pr}(\\text{viagra})$ es la verosimilitud marginal.\n",
    "\n",
    "El cálculo de cada una de las probabilidades se realiza tal como se hizo en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para el caso analizado, se tiene una muestra de ejemplos de mensajes que han sido catalogados como spam y válidos (no spam): \n",
    "\n",
    "     #  Tipo    Mensaje\n",
    "    ---------------------------------------\n",
    "     1  spam    w1 w3 \n",
    "     2  spam    w1 w2 w1 w3\n",
    "     3  ham     w2 w4 \n",
    "     4  ham     w4 w5 w2\n",
    "     5  ham     w2 w4 w2\n",
    "\n",
    "Para realizar la clasificación se tienen cuatro palabras $w_1$, $w_2$, $w_3$, $w_4$ y $w_5$ que pueden estar o no en cada uno de los mensajes de texto. La probabilidad de que la palabra $w_1$ este en el mensaje se nota como $\\text{Pr}(w_1)$, y de que no este como $\\text{Pr}(\\text{not }w_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Actividad.---** Calcule las tablas de probabilidades:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probabilidad individual** $\\text{Pr}(w_i)$:\n",
    "\n",
    "\n",
    "     Evento          w1    w2    w3    w4    w5\n",
    "    ------------------------------------------------\n",
    "     Ocurre       3/14     ?     ?     ?   1/14\n",
    "     No ocurre       ?     ?   12/14   ?     ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probabilidad conjunta** $\\text{Pr}(w_i, \\text{Tipo})$:\n",
    "\n",
    "\n",
    "     Tipo     w1    w2    w3    w4    w5  Pr(tipo)\n",
    "    ----------------------------------------------     \n",
    "     spam   3/14     ?     ?     ?     ?     6/14 \n",
    "     ham       ?     ?  0/14     ?     ?        ?\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "     \n",
    "**Probabilidad condicional** $\\text{Pr}(w_i \\, | \\, \\text{Tipo})$:\n",
    "\n",
    "\n",
    "      Tipo     w1    w2    w3    w4    w5 \n",
    "      ---------------------------------------------     \n",
    "      spam    3/6     ?     ?     ?     ?   \n",
    "      ham       ?     ?     ?   3/8     ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probabilidad condicional** $\\text{Pr}(\\text{not } w_i \\, |  \\, \\text{Tipo})$:\n",
    "\n",
    "\n",
    "      Tipo     w1    w2    w3    w4    w5 \n",
    "      ---------------------------------------------     \n",
    "      spam      ?   5/6     ?     ?     ?   \n",
    "      ham       ?     ?     ?     ?   7/8      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación se usará el teorema de Bayes para determine si el mensaje $w_1 w_4$ es spam. Ya que este mensaje contiene las palabras $w_1$ y $w_4$ y no contiene las palabras $w_2$, $w_3$ y $w_5$, la probabilidad de que sea spam es:\n",
    "\n",
    "$$\\text{Pr}(\\text{spam}~|~w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5)$$\n",
    "\n",
    "Por el teorema de Bayes, la ecuación anterior se transforma en:\n",
    "\n",
    "$$\\frac{\\text{Pr}(w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5 |~\\text{spam}) * \\text{Pr}(\\text{spam})}\n",
    "{\\text{Pr}(~w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se tiene en cuenta que la ocurrencia de la palabras $w_1$, $w_2$, $w_3$, $w_4$ y $w_5$ son eventos independientes, es decir, que la ocurrencia de una palabra es independiente de la ocurrencia de las otras, entonces, el término $\\text{Pr}(w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4 ~\\text{and}~\\text{not}~w_5|~\\text{spam})$ puede aproximarse como:\n",
    "\n",
    "$$\n",
    "\\text{Pr}(w_1~|~\\text{spam})*\n",
    "\\text{Pr}(\\text{not}~w_2~|~\\text{spam})*\n",
    "\\text{Pr}(\\text{not}~w_3|~\\text{spam})*\n",
    "\\text{Pr}(w_4~|~\\text{spam})*\n",
    "\\text{Pr}(\\text{not}~w_5|~\\text{spam})\n",
    "$$\n",
    "\n",
    "Estas cantidades ya fueron computadas en la actividad anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Actividad.---** Calcule la probabilidad de que el mensaje $w_1 w_4$ sea spam, es decir, calcule la siguiente probabilidad:\n",
    "\n",
    "$$\\text{Pr}(\\text{spam}~|~w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Actividad.---** Calcule la probabilidad de que el mensaje $w_1 w_4$ sea ham, es decir, calcule la siguiente probabilidad:\n",
    "\n",
    "$$\\text{Pr}(\\text{ham}~|~w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5)$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actividad.---** Con base en los resultados anteriores, ¿El mensaje es ham o spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La ecuación \n",
    "\n",
    "$$\n",
    "\\text{Pr}(w_1~|~\\text{spam})*\n",
    "\\text{Pr}(\\text{not}~w_2~|~\\text{spam})*\n",
    "\\text{Pr}(\\text{not}~w_3|~\\text{spam})*\n",
    "\\text{Pr}(w_4~|~\\text{spam})*\n",
    "\\text{Pr}(\\text{not}~w_5|~\\text{spam})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "es la usada en la implementación computacional del algoritmo Naive Bayes para el cómputo de las probabilidades posteriores. En general, la ecuación anterior se puede escribir como:\n",
    "\n",
    "$$\\text{Pr}(C_L~|~F_1, ...,F_n) = \\frac{1}{Z}\\text{Pr}(C_L)\\prod_{i=1}^n \\text{Pr}(F_i~|~C_L)$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $F_i$ son las características (las $x_i$).\n",
    "\n",
    "\n",
    "* $1/Z$ es un factor de escala.\n",
    "\n",
    "\n",
    "* $C_L$ representa el nivel $L$ de la clase $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Estimador de Laplace**\n",
    "\n",
    "Al construir la tabla de probabilidades de las ocurrencias de las palabras, es posible que una palabra $w_k$ aparezca únicamente en los mensajes válidos y no aparezca en los mensajes spam. De esta forma si se calcula la probabilidad posterior de un nuevo mensaje que no la contiene, el resultado es cero para spam y uno para válido. Para prevernir esta situación, se hace que el conteo inicial no arranque en cero con el fin de que la probabilidad de ocurrencia sea siempre mayor que cero. Esto equivale a tener un mensaje para cada clase conformado por todas las palabras posibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actividad.---** Realice nuevamente el ejercicio anterior usando el estimador de Laplace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilidad individual $\\text{Pr}(w_i)$:\n",
    "\n",
    "\n",
    "                      w1    w2    w3    w4    w5\n",
    "      ----------------------------------------------\n",
    "      Ocurre        5/24     ?     ?     ?   3/24\n",
    "      No ocurre        ?     ?   20/24   ?     ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete la tabla de probabilidad conjunta:\n",
    "\n",
    "\n",
    "      Tipo     w1    w2    w3    w4    w5  Pr(tipo)\n",
    "      ----------------------------------------------     \n",
    "      spam   4/24     ?     ?     ?     ?    11/24 \n",
    "      ham       ?     ?  1/24     ?     ?        ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete la tabla de probabilidad condicional $\\text{Pr}(w_i \\, | \\, \\text{Tipo})$:\n",
    "\n",
    "\n",
    "      Tipo     w1    w2    w3    w4    w5   \n",
    "      ----------------------------------------------    \n",
    "      spam   4/11     ?     ?     ?   1/11    \n",
    "      ham       ?     ?   1/13     ?    ?      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete la tabla de probabilidad condicional $\\text{Pr}(\\text{not } w_i \\, |  \\, \\text{Tipo})$:\n",
    "\n",
    "\n",
    "      Tipo     w1    w2    w3    w4    w5   \n",
    "      ----------------------------------------------     \n",
    "      spam      ?  9/11     ?     ?     ?         \n",
    "      ham       ?     ?     ?     ?  11/13          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule la probabilidad de que el mensaje $w_1w_4$ sea spam:\n",
    "\n",
    "$$\\text{Pr}(\\text{spam}~|~w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5)$$\n",
    " \n",
    "R/ 36.56% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule la probabilidad de que el mensaje sea $w_1w_4$ válido:\n",
    "\n",
    "$$\\text{Pr}(\\text{ham}~|~w_1~\\text{and}~\\text{not}~w_2~\\text{and}~\\text{not}~w_3~\\text{and}~w_4~\\text{and}~\\text{not}~w_5)$$\n",
    "\n",
    "R/ 27.49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementación de la solución en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta la solución usando el lenguaje Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.csv\n",
    "texto,tipo\n",
    "ww1 ww3,spam\n",
    "ww1 ww2 ww1 ww3,spam\n",
    "ww2 ww4,ham\n",
    "ww4 ww5 ww2,ham\n",
    "ww2 ww4 ww2,ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ww1 ww3</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ww1 ww2 ww1 ww3</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ww2 ww4</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ww4 ww5 ww2</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ww2 ww4 ww2</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             texto  tipo\n",
       "0          ww1 ww3  spam\n",
       "1  ww1 ww2 ww1 ww3  spam\n",
       "2          ww2 ww4   ham\n",
       "3      ww4 ww5 ww2   ham\n",
       "4      ww2 ww4 ww2   ham"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"data.csv\",\n",
    "    sep=\",\",         # separador de campos\n",
    "    thousands=None,  # separador de miles para números\n",
    "    decimal=\".\",     # separador de los decimales para números\n",
    ")  \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            ww1 ww3\n",
       "1    ww1 ww2 ww1 ww3\n",
       "2            ww2 ww4\n",
       "3        ww4 ww5 ww2\n",
       "4        ww2 ww4 ww2\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se preparan los datos. El conjunto de\n",
    "# datos es una lista de strings donde cada\n",
    "# string es un mensaje\n",
    "#\n",
    "df.texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    spam\n",
       "1    spam\n",
       "2     ham\n",
       "3     ham\n",
       "4     ham\n",
       "Name: tipo, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# La clase a la que pertenece cada mensaje\n",
    "# también se representa como una lista de strings\n",
    "#\n",
    "df.tipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se importa la librería\n",
    "#\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#\n",
    "# La representación DocumentTermMatrix corresponde a \n",
    "# a una matriz en la que cada fila corresponde\n",
    "# a un mensaje y cada columna es una palabra.\n",
    "#\n",
    "#        | ww1 ww2 ww3 ww4 ww5\n",
    "#  -----------------------------\n",
    "#  msg 0 |   1   0   1   0   0\n",
    "#      1 |   2   1   1   0   0\n",
    "#      2 |   0   1   0   1   0\n",
    "#      3 |   0   1   0   1   1\n",
    "#      4 |   0   2   0   1   0\n",
    "#     \n",
    "#\n",
    "# A continuación se crea un transformador\n",
    "#\n",
    "vectorizer = CountVectorizer(input=\"content\")\n",
    "\n",
    "#\n",
    "# Se aplica el transformador al texto para convertirlo\n",
    "# a DTM.\n",
    "#\n",
    "X = vectorizer.fit_transform(df.texto)\n",
    "\n",
    "#\n",
    "# También se genera una variable para el tipo\n",
    "#\n",
    "y = df.tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ww1', 'ww2', 'ww3', 'ww4', 'ww5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## Se imprimen los nombres de las columnas\n",
    "##\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0]\n",
      " [2 1 1 0 0]\n",
      " [0 1 0 1 0]\n",
      " [0 1 0 1 1]\n",
      " [0 2 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se imprime la matriz de términos y documentos\n",
    "#\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1, 0, 0],\n",
       " [1, 1, 1, 0, 0],\n",
       " [0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 1, 1],\n",
       " [0, 1, 0, 1, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Ya que lo que interesa es la presencia o no de la palabra\n",
    "# y no interesa la cantidad de veces que aparece, entonces\n",
    "# se aplica una transformación a la matriz\n",
    "#\n",
    "X = [[1 if element > 1 else element for element in row] for row in X.toarray()]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se importa la libreria\n",
    "#\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#\n",
    "# Se crea un clasificador Gaussiano ingenuo\n",
    "#\n",
    "gnb = BernoulliNB(\n",
    "    alpha=1.0,        # Laplace parameter\n",
    "    binarize=0.0,\n",
    "    fit_prior=True,\n",
    "    class_prior=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se entrena el clasificador\n",
    "#\n",
    "gnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Se pronostica la clasificación de los\n",
    "# mensajes para los datos de entrada\n",
    "#\n",
    "df[\"predicted\"] = gnb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>tipo</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ww1 ww3</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ww1 ww2 ww1 ww3</td>\n",
       "      <td>spam</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ww2 ww4</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ww4 ww5 ww2</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ww2 ww4 ww2</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             texto  tipo predicted\n",
       "0          ww1 ww3  spam      spam\n",
       "1  ww1 ww2 ww1 ww3  spam      spam\n",
       "2          ww2 ww4   ham       ham\n",
       "3      ww4 ww5 ww2   ham       ham\n",
       "4      ww2 ww4 ww2   ham       ham"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data.csv"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
