

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="es" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="es" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introducción a la clasificación de texto usando Naive Bayes &mdash; documentación de --- Cursos --- - </title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script type="text/javascript" src="../../../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" />
    <link rel="next" title="Filtrado de spam en mensajes de texto (SMS)" href="02-filtrado-de-mensajes-sms.html" />
    <link rel="prev" title="Apriori en Python" href="../apriori/03-apyori.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../../analitica-predictiva/content.html">Sesiones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../analitica-predictiva/course-info.html">Información del curso</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../analitica-predictiva/index.html">Analítica Predictiva</a> &raquo;</li>
        
          <li><a href="../../../analitica-predictiva/content.html">Sesiones</a> &raquo;</li>
        
      <li>Introducción a la clasificación de texto usando Naive Bayes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/notebooks/sklearn/bayes/01-clasificacion-de-texto-usando-bayes.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Introducción-a-la-clasificación-de-texto-usando-Naive-Bayes">
<h1>Introducción a la clasificación de texto usando Naive Bayes<a class="headerlink" href="#Introducción-a-la-clasificación-de-texto-usando-Naive-Bayes" title="Enlazar permanentemente con este título">¶</a></h1>
<ul class="simple">
<li><p><em>60 min</em> | Ultima modificación: Junio 22, 2019</p></li>
</ul>
<p>Los <a class="reference external" href="https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo">clasificadores bayesianos ingenuos</a> son un tipo de clasificador probabilistico en el que se considera que cada característica de una instancia contribuye independientemente de las demás a que un objeto pertenezca a una clase determinada. Mientras que en la inducción de reglas de asociación (algoritmo 1R) solamente se considera una sola característica para determinar a que clase pertence una instancia, en un clasificador
ingenuo se consideran simultáneamente todas las características. En este tutorial se describen los fundamentos matemáticos en que se soporta este tipo de clasificadores y como se aplican a casos reales.</p>
<div class="section" id="Definición-del-problema">
<h2>Definición del problema<a class="headerlink" href="#Definición-del-problema" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En este tutorial se aborda el problema de determinar si un mensaje de texto es válido o spam. Este es un problema típico de minería de texto. Desde el punto de vista del negocio, la recepción de publicidad no deseada y mensajes fraudulentos es un problema que afecta a muchos usuarios; y es por ello, que las compañias prestadoras de servicios desean filtrar este tipo de mensajes con el fin de evitar el consumo de espacio en su infraestructura y la molestia para el usuario.</p>
<p>Se tiene una muestra conformada por los siguientes mensajes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="c1">#  Tipo    Mensaje</span>
<span class="o">---------------------------------------</span>
 <span class="mi">1</span>  <span class="n">spam</span>    <span class="n">w1</span> <span class="n">w3</span>
 <span class="mi">2</span>  <span class="n">spam</span>    <span class="n">w1</span> <span class="n">w2</span> <span class="n">w1</span> <span class="n">w3</span>
 <span class="mi">3</span>  <span class="n">ham</span>     <span class="n">w2</span> <span class="n">w4</span>
 <span class="mi">4</span>  <span class="n">ham</span>     <span class="n">w4</span> <span class="n">w5</span> <span class="n">w2</span>
 <span class="mi">5</span>  <span class="n">ham</span>     <span class="n">w2</span> <span class="n">w4</span> <span class="n">w2</span>
</pre></div>
</div>
<p>El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítimo o spam, a partir del análisis de las palabras que contiente; se supone que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje.</p>
</div>
<div class="section" id="Conceptos-y-Definiciones-Básicas">
<h2>Conceptos y Definiciones Básicas<a class="headerlink" href="#Conceptos-y-Definiciones-Básicas" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Probabilidad">
<h3>Probabilidad<a class="headerlink" href="#Probabilidad" title="Enlazar permanentemente con este título">¶</a></h3>
<p>De los tutoriales anteriores, se sabe que si las variables <span class="math notranslate nohighlight">\(x_i\)</span> representan los eventos posibles, entonces:</p>
<ul class="simple">
<li><p>Todas las probabilidades deben estar entre <span class="math notranslate nohighlight">\(0\)</span> y <span class="math notranslate nohighlight">\(1\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[0 \le \text{Pr}(x_i) \le 1\]</div>
<ul class="simple">
<li><p>Las probabilidades de eventos mutuamente exclusivos (no pueden ocurrir simultáneamente) y colectivamente exhaustivos (cubren todo el universo de casos posibles) deben sumar la unidad:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^n \text{Pr}(x_i) = 1\]</div>
<p>En las siguientes figuras, los eventos F1, F2 y F3, y V1 y V2 están definidos sobre el mismo universo; y son mutuamente exclusivos y colectivamente exhaustivos, tal que se cumplen las dos propiedades anteriores</p>
<p><img alt="assets/eventos-conjuntos-2.jpg" src="../../../_images/eventos-conjuntos-2.jpg" /></p>
<div class="math notranslate nohighlight">
\[\text{Pr}(F1) + \text{Pr}(F2) + \text{Pr}(F3) = 1, \quad \qquad \text{Pr}(V1) + \text{Pr}(V2) = 1\]</div>
</div>
<div class="section" id="Probabilidad-conjunta">
<h3>Probabilidad conjunta<a class="headerlink" href="#Probabilidad-conjunta" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Los eventos considerados ocurren simultáneamente. En la siguiente figura, los eventos F1 y V2 ocurren simultáneamente (área sombreada de la figura), tal que su probabilidad conjunta es:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(F1~\text{and}~V2)\]</div>
<p><img alt="assets/probabilidad-conjunta-3.jpg" src="../../../_images/probabilidad-conjunta-3.jpg" /></p>
</div>
<div class="section" id="Probabilidad-condicional">
<h3>Probabilidad condicional<a class="headerlink" href="#Probabilidad-condicional" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Es la probabilidad de que ocurra un evento sabiendo que el otro ya ocurrio. En la siguiente figura el evento V2 es condicionar a la ocurrencia F1. Noté que en la siguiente figura, el universo no es el rectángulo anterior que cubre todos los eventos, si no el evento F1. De esta forma, la probabilidad condicional es sólo la proporción de V2 que se intercepta con F1, la cual corresponde a la porción sombreada de la figura de abajo. La siguiente expresión matemática permite calcular la probabilidad
condicional en términos de la probabilidad conjunta.</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(V2 \; | \; F1) = \text{Pr}(F1 \; \text{and} \; V2) \; / \; \text{Pr}(F1)\]</div>
<p>En otras palabras,</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \; | \; B) * \text{Pr}(B) = \text{Pr}(A \; \text{and} \; B)\]</div>
<p>para dos eventos A y B.</p>
<p><img alt="assets/probabilidad-condicional.jpg" src="../../../_images/probabilidad-condicional.jpg" /></p>
</div>
<div class="section" id="Independencia">
<h3>Independencia<a class="headerlink" href="#Independencia" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Si los eventos <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span> son independientes, la probabilidad condicional del evento A dado que ocurrio el evento B es igual a la probabilidad del evento A:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \; |  \; B) = \text{Pr}(A)\]</div>
<p>De la definición de probabilidad condicional:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A  \; |  \; B) = \text{Pr}(A) = \frac{\text{Pr}(A\text{ and }B)}{\text{Pr}(B)}\]</div>
<p>Entonces:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A\text{ and } B) \; =  \; \text{Pr}(A) \; * \; \text{Pr}(B)\]</div>
</div>
<div class="section" id="Probabilidad-marginal">
<h3>Probabilidad marginal<a class="headerlink" href="#Probabilidad-marginal" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Sea <span class="math notranslate nohighlight">\(X_1\)</span> con <span class="math notranslate nohighlight">\(i = 1, ... , n\)</span> , un conjunto de eventos mutuamente exclusivos y colectivamente exhaustivos. La probabilidad de un evento <span class="math notranslate nohighlight">\(A\)</span> es:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A) = \sum_{i=1}^n \text{Pr}(A\text{ and }X_i)\]</div>
<p>En la siguiente figura se puede observar que para cualquiera de los tres eventos <span class="math notranslate nohighlight">\(F_j\)</span> (para <span class="math notranslate nohighlight">\(j=1,2,3\)</span>)</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(F_j) = \text{Pr}(F_j\text{ and }V_1) + \text{Pr}(F_j\text{ and }V_2)\]</div>
<p>y que para los dos eventos <span class="math notranslate nohighlight">\(V_i\)</span> (<span class="math notranslate nohighlight">\(i=1,2\)</span>):</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(V_i) = \text{Pr}(V_i\text{ and }F_1) + \text{Pr}(V_i\text{ and }F_2) + \text{Pr}(V_i\text{ and }F_3)\]</div>
<p><img alt="assets/eventos-conjuntos.jpg" src="../../../_images/eventos-conjuntos.jpg" /></p>
</div>
<div class="section" id="Unión-(OR)">
<h3>Unión (OR)<a class="headerlink" href="#Unión-(OR)" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para dos eventos <span class="math notranslate nohighlight">\(A\)</span> y <span class="math notranslate nohighlight">\(B\)</span>:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \text{ or } B) = \text{Pr}(A) + \text{Pr}(B) - \text{Pr}(A\text{ and }B)\]</div>
<p>En la figura de abajo se observa que al unir las regiones de los eventos F1 y V2, las áreas se traslapan y por tanto hay que restar la intersección.</p>
<p><img alt="assets/probabilidad-conjunta.jpg" src="../../../_images/probabilidad-conjunta-3.jpg" /></p>
</div>
<div class="section" id="Complemento-o-negación">
<h3>Complemento o negación<a class="headerlink" href="#Complemento-o-negación" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{not } A) = 1 - \text{Pr}(A)\]</div>
</div>
<div class="section" id="Probabilidad-total">
<h3>Probabilidad total<a class="headerlink" href="#Probabilidad-total" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La probabilidad total indica que la probabilidad de un evento A puede calcularse como la probabilidad de que ocurran los eventos A y B simultáneamente más la probabilidad de que ocurran los evento A y <em>not</em> B (el complemento de B:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A) = \text{Pr}(A\text{ and } B) + \text{Pr}(A\text{ and } \text{not }B)\]</div>
<p>La ecuación anterior puede expresarse en términos de probabilidades condicionales, tal que:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A) = \text{Pr}(A \; | \; B) \; \text{Pr}(B)  \; + \;  \text{Pr}(A \; | \; \text{not }B)\text{ Pr}(\text{not }B)\]</div>
</div>
<div class="section" id="Teorema-de-Bayes">
<h3>Teorema de Bayes<a class="headerlink" href="#Teorema-de-Bayes" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A partir de</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A  \; |  \; B) = \frac{\text{Pr}(A\text{ and }B)}{\text{Pr}(B)},
\quad
\text{Pr}(B  \; |  \; A) = \frac{\text{Pr}(A\text{ and }B)}{\text{Pr}(A)}\]</div>
<p>Se obtiene que:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(A \; | \; B)\text{ Pr}({B}) =  \text{Pr}(B \; | \; A) \; \text{Pr}({A})\]</div>
<p>Despejando <span class="math notranslate nohighlight">\(\text{Pr}(B \; | \; A)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(B \; | \; A) =
    \frac{\text{Pr}(A \; | \; B) \; \text{Pr}(B)}{\text{Pr}(A)} =
    \frac{\text{Pr}(A \; | \; B)~\text{Pr}(B)} {\text{Pr}(A \; | \; B) \; \text{Pr}(B)  \; + \;  \text{Pr}(A \; | \; \text{not }B) \; \text{Pr}(\text{not }B)}\]</div>
<p>En la última ecuación, se aplica el teorema de probabilidad total para el evento A.</p>
<p><strong>Actividad.—</strong> Complete las siguientes tablas de probabilidades:</p>
<p><em>Probabilidades totales</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>          F1    F2    F3  Prob(V)
----------------------------------
    V1   0.10     ?  0.03       ?
    V2      ?  0.26  0.14    0.62
----------------------------------
 Prob(F)    ?     ?     ?
</pre></div>
</div>
<p><em>Probabilidades condicionales</em>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Prob(F|V)                 Prob(V|F)

        F1    F2    F3            F1    F2    F3
----------------------    ----------------------
  V1 10/38     ?     ?      V1     ? 25/51     ?
  V2     ?     ? 14/62      V2     ?     ?     ?
</pre></div>
</div>
<p><strong>Actividad.—</strong> Verifique las dos tablas de probabilidades condicionales calculadas en el ejercicio anterior usando el teorema de Bayes (es decir, calcule <code class="docutils literal notranslate"><span class="pre">Prob(V|F)</span></code> a partir de <code class="docutils literal notranslate"><span class="pre">Prob(F|V)</span></code> y viceversa).</p>
</div>
</div>
<div class="section" id="Aplicación-al-problema-propuesto">
<h2>Aplicación al problema propuesto<a class="headerlink" href="#Aplicación-al-problema-propuesto" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En términos del problema de filtrado de mensajes de texto, V1 se interpreta como «Es spam» y V2 como NOT «Es spam», ya que son eventos mutuamente exclusivos y colectivamente exhaustivos. Si F es la ocurrencia de una determinada palabra en el texto, como por ejemplo «Viagra», entonces F1 sería «Viagra»(«viagra» aparece en el mensaje) y F2 sería NOT «Viagra» («viagra» no aparece en el mensaje).</p>
<p>De acuerdo con el teorema de Bayes:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam} \; | \; \text{viagra}) = \frac{\text{Pr}(\text{viagra} \, | \,
\text{spam})*\text{Pr}(\text{spam})}{\text{Pr}(\text{viagra})}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{spam} \, | \, \text{viagra})\)</span> es la probabilidad posterior.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{viagra} \, | \, \text{spam})\)</span> es la verosimilitud.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{spam})\)</span> es la probabilidad prior, es decir, la probabilidad de que un mensaje sea spam sin conocer el texto que contiene.</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Pr}(\text{viagra})\)</span> es la verosimilitud marginal.</p></li>
</ul>
<p>El cálculo de cada una de las probabilidades se realiza tal como se hizo en el ejercicio anterior.</p>
<p>Para el caso analizado, se tiene una muestra de ejemplos de mensajes que han sido catalogados como spam y válidos (no spam):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="c1">#  Tipo    Mensaje</span>
<span class="o">---------------------------------------</span>
 <span class="mi">1</span>  <span class="n">spam</span>    <span class="n">w1</span> <span class="n">w3</span>
 <span class="mi">2</span>  <span class="n">spam</span>    <span class="n">w1</span> <span class="n">w2</span> <span class="n">w1</span> <span class="n">w3</span>
 <span class="mi">3</span>  <span class="n">ham</span>     <span class="n">w2</span> <span class="n">w4</span>
 <span class="mi">4</span>  <span class="n">ham</span>     <span class="n">w4</span> <span class="n">w5</span> <span class="n">w2</span>
 <span class="mi">5</span>  <span class="n">ham</span>     <span class="n">w2</span> <span class="n">w4</span> <span class="n">w2</span>
</pre></div>
</div>
<p>Para realizar la clasificación se tienen cuatro palabras <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>, <span class="math notranslate nohighlight">\(w_3\)</span>, <span class="math notranslate nohighlight">\(w_4\)</span> y <span class="math notranslate nohighlight">\(w_5\)</span> que pueden estar o no en cada uno de los mensajes de texto. La probabilidad de que la palabra <span class="math notranslate nohighlight">\(w_1\)</span> este en el mensaje se nota como <span class="math notranslate nohighlight">\(\text{Pr}(w_1)\)</span>, y de que no este como <span class="math notranslate nohighlight">\(\text{Pr}(\text{not }w_1)\)</span>.</p>
<p><strong>Actividad.—</strong> Calcule las tablas de probabilidades:</p>
<p><strong>Probabilidad individual</strong> <span class="math notranslate nohighlight">\(\text{Pr}(w_i)\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> Evento          w1    w2    w3    w4    w5
------------------------------------------------
 Ocurre       3/14     ?     ?     ?   1/14
 No ocurre       ?     ?   12/14   ?     ?
</pre></div>
</div>
<p><strong>Probabilidad conjunta</strong> <span class="math notranslate nohighlight">\(\text{Pr}(w_i, \text{Tipo})\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> Tipo     w1    w2    w3    w4    w5  Pr(tipo)
----------------------------------------------
 spam   3/14     ?     ?     ?     ?     6/14
 ham       ?     ?  0/14     ?     ?        ?
</pre></div>
</div>
<p><strong>Probabilidad condicional</strong> <span class="math notranslate nohighlight">\(\text{Pr}(w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
---------------------------------------------
spam    3/6     ?     ?     ?     ?
ham       ?     ?     ?   3/8     ?
</pre></div>
</div>
<p><strong>Probabilidad condicional</strong> <span class="math notranslate nohighlight">\(\text{Pr}(\text{not } w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
---------------------------------------------
spam      ?   5/6     ?     ?     ?
ham       ?     ?     ?     ?   7/8
</pre></div>
</div>
<p>A continuación se usará el teorema de Bayes para determine si el mensaje <span class="math notranslate nohighlight">\(w_1 w_4\)</span> es spam. Ya que este mensaje contiene las palabras <span class="math notranslate nohighlight">\(w_1\)</span> y <span class="math notranslate nohighlight">\(w_4\)</span> y no contiene las palabras <span class="math notranslate nohighlight">\(w_2\)</span>, <span class="math notranslate nohighlight">\(w_3\)</span> y <span class="math notranslate nohighlight">\(w_5\)</span>, la probabilidad de que sea spam es:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p>Por el teorema de Bayes, la ecuación anterior se transforma en:</p>
<div class="math notranslate nohighlight">
\[\frac{\text{Pr}(w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5 |~\text{spam}) * \text{Pr}(\text{spam})}
{\text{Pr}(~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)}\]</div>
<p>Si se tiene en cuenta que la ocurrencia de la palabras <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>, <span class="math notranslate nohighlight">\(w_3\)</span>, <span class="math notranslate nohighlight">\(w_4\)</span> y <span class="math notranslate nohighlight">\(w_5\)</span> son eventos independientes, es decir, que la ocurrencia de una palabra es independiente de la ocurrencia de las otras, entonces, el término <span class="math notranslate nohighlight">\(\text{Pr}(w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4 ~\text{and}~\text{not}~w_5|~\text{spam})\)</span> puede aproximarse como:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(w_1~|~\text{spam})*
\text{Pr}(\text{not}~w_2~|~\text{spam})*
\text{Pr}(\text{not}~w_3|~\text{spam})*
\text{Pr}(w_4~|~\text{spam})*
\text{Pr}(\text{not}~w_5|~\text{spam})\]</div>
<p>Estas cantidades ya fueron computadas en la actividad anterior.</p>
<p><strong>Actividad.—</strong> Calcule la probabilidad de que el mensaje <span class="math notranslate nohighlight">\(w_1 w_4\)</span> sea spam, es decir, calcule la siguiente probabilidad:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p><strong>Actividad.—</strong> Calcule la probabilidad de que el mensaje <span class="math notranslate nohighlight">\(w_1 w_4\)</span> sea ham, es decir, calcule la siguiente probabilidad:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{ham}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p><strong>Actividad.—</strong> Con base en los resultados anteriores, ¿El mensaje es ham o spam?</p>
<p>La ecuación</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(w_1~|~\text{spam})*
\text{Pr}(\text{not}~w_2~|~\text{spam})*
\text{Pr}(\text{not}~w_3|~\text{spam})*
\text{Pr}(w_4~|~\text{spam})*
\text{Pr}(\text{not}~w_5|~\text{spam})\]</div>
<p>es la usada en la implementación computacional del algoritmo Naive Bayes para el cómputo de las probabilidades posteriores. En general, la ecuación anterior se puede escribir como:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(C_L~|~F_1, ...,F_n) = \frac{1}{Z}\text{Pr}(C_L)\prod_{i=1}^n \text{Pr}(F_i~|~C_L)\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F_i\)</span> son las características (las <span class="math notranslate nohighlight">\(x_i\)</span>).</p></li>
<li><p><span class="math notranslate nohighlight">\(1/Z\)</span> es un factor de escala.</p></li>
<li><p><span class="math notranslate nohighlight">\(C_L\)</span> representa el nivel <span class="math notranslate nohighlight">\(L\)</span> de la clase <span class="math notranslate nohighlight">\(C\)</span>.</p></li>
</ul>
<p><strong>Estimador de Laplace</strong></p>
<p>Al construir la tabla de probabilidades de las ocurrencias de las palabras, es posible que una palabra <span class="math notranslate nohighlight">\(w_k\)</span> aparezca únicamente en los mensajes válidos y no aparezca en los mensajes spam. De esta forma si se calcula la probabilidad posterior de un nuevo mensaje que no la contiene, el resultado es cero para spam y uno para válido. Para prevernir esta situación, se hace que el conteo inicial no arranque en cero con el fin de que la probabilidad de ocurrencia sea siempre mayor que cero. Esto
equivale a tener un mensaje para cada clase conformado por todas las palabras posibles.</p>
<p><strong>Actividad.—</strong> Realice nuevamente el ejercicio anterior usando el estimador de Laplace.</p>
<p>Probabilidad individual <span class="math notranslate nohighlight">\(\text{Pr}(w_i)\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                w1    w2    w3    w4    w5
----------------------------------------------
Ocurre        5/24     ?     ?     ?   3/24
No ocurre        ?     ?   20/24   ?     ?
</pre></div>
</div>
<p>Complete la tabla de probabilidad conjunta:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5  Pr(tipo)
----------------------------------------------
spam   4/24     ?     ?     ?     ?    11/24
ham       ?     ?  1/24     ?     ?        ?
</pre></div>
</div>
<p>Complete la tabla de probabilidad condicional <span class="math notranslate nohighlight">\(\text{Pr}(w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
----------------------------------------------
spam   4/11     ?     ?     ?   1/11
ham       ?     ?   1/13     ?    ?
</pre></div>
</div>
<p>Complete la tabla de probabilidad condicional <span class="math notranslate nohighlight">\(\text{Pr}(\text{not } w_i \, | \, \text{Tipo})\)</span>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Tipo     w1    w2    w3    w4    w5
----------------------------------------------
spam      ?  9/11     ?     ?     ?
ham       ?     ?     ?     ?  11/13
</pre></div>
</div>
<p>Calcule la probabilidad de que el mensaje <span class="math notranslate nohighlight">\(w_1w_4\)</span> sea spam:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{spam}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p>R/ 36.56%</p>
<p>Calcule la probabilidad de que el mensaje sea <span class="math notranslate nohighlight">\(w_1w_4\)</span> válido:</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(\text{ham}~|~w_1~\text{and}~\text{not}~w_2~\text{and}~\text{not}~w_3~\text{and}~w_4~\text{and}~\text{not}~w_5)\]</div>
<p>R/ 27.49%</p>
</div>
<div class="section" id="Implementación-de-la-solución-en-Python">
<h2>Implementación de la solución en Python<a class="headerlink" href="#Implementación-de-la-solución-en-Python" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A continuación se presenta la solución usando el lenguaje Python.</p>
<div class="section" id="Preparación">
<h3>Preparación<a class="headerlink" href="#Preparación" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">load_ext</span> rpy2.ipython
</pre></div>
</div>
</div>
</div>
<div class="section" id="Creación-del-archivo">
<h3>Creación del archivo<a class="headerlink" href="#Creación-del-archivo" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> data.csv
<span class="n">texto</span><span class="p">,</span><span class="n">tipo</span>
<span class="n">ww1</span> <span class="n">ww3</span><span class="p">,</span><span class="n">spam</span>
<span class="n">ww1</span> <span class="n">ww2</span> <span class="n">ww1</span> <span class="n">ww3</span><span class="p">,</span><span class="n">spam</span>
<span class="n">ww2</span> <span class="n">ww4</span><span class="p">,</span><span class="n">ham</span>
<span class="n">ww4</span> <span class="n">ww5</span> <span class="n">ww2</span><span class="p">,</span><span class="n">ham</span>
<span class="n">ww2</span> <span class="n">ww4</span> <span class="n">ww2</span><span class="p">,</span><span class="n">ham</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing data.csv
</pre></div></div>
</div>
</div>
<div class="section" id="Lectura-de-datos">
<h3>Lectura de datos<a class="headerlink" href="#Lectura-de-datos" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;data.csv&quot;</span><span class="p">,</span>
    <span class="n">sep</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span>         <span class="c1"># separador de campos</span>
    <span class="n">thousands</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># separador de miles para números</span>
    <span class="n">decimal</span> <span class="o">=</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>     <span class="c1"># separador de los decimales para números</span>

<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texto</th>
      <th>tipo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ww1 ww3</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ww1 ww2 ww1 ww3</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ww2 ww4</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ww4 ww5 ww2</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ww2 ww4 ww2</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se preparan los datos. El conjunto de</span>
<span class="c1">## datos es una lista de strings donde cada</span>
<span class="c1">## string es un mensaje</span>
<span class="c1">##</span>
<span class="n">df</span><span class="o">.</span><span class="n">texto</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0            ww1 ww3
1    ww1 ww2 ww1 ww3
2            ww2 ww4
3        ww4 ww5 ww2
4        ww2 ww4 ww2
Name: texto, dtype: object
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## La clase a la que pertenece cada mensaje</span>
<span class="c1">## también se representa como una lista de strings</span>
<span class="c1">##</span>
<span class="n">df</span><span class="o">.</span><span class="n">tipo</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0    spam
1    spam
2     ham
3     ham
4     ham
Name: tipo, dtype: object
</pre></div></div>
</div>
</div>
<div class="section" id="Transformación">
<h3>Transformación<a class="headerlink" href="#Transformación" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se importa la librería</span>
<span class="c1">##</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1">##</span>
<span class="c1">## La representación DocumentTermMatrix es equivalente</span>
<span class="c1">## a una bag-of-words, en la que cada fila corresponde</span>
<span class="c1">## a un mensaje y cada columna es una palabra.</span>
<span class="c1">##</span>
<span class="c1">## A continuación se crea un transformador</span>
<span class="c1">##</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s1">&#39;content&#39;</span><span class="p">)</span>

<span class="c1">##</span>
<span class="c1">## Se aplica el transformador al texto para convertirlo</span>
<span class="c1">## a una bag-of-words.</span>
<span class="c1">##</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">texto</span><span class="p">)</span>

<span class="c1">##</span>
<span class="c1">## También se transforma la clase a una</span>
<span class="c1">## representación binaria</span>
<span class="c1">##</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">u</span> <span class="o">==</span> <span class="s1">&#39;spam&#39;</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">tipo</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">tipo</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se imprimen los nombres de las columnas</span>
<span class="c1">##</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;ww1&#39;, &#39;ww2&#39;, &#39;ww3&#39;, &#39;ww4&#39;, &#39;ww5&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se imprime la matriz de términos y documentos</span>
<span class="c1">##</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1 0 1 0 0]
 [2 1 1 0 0]
 [0 1 0 1 0]
 [0 1 0 1 1]
 [0 2 0 1 0]]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Ya que interesa es la presencia o no de la palabra</span>
<span class="c1">## y no interesa la cantidad de veces que aparece, entonces</span>
<span class="c1">## se aplica una transformación a la matriz</span>
<span class="c1">##</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">element</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">element</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">()]</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1, 0, 1, 0, 0],
 [1, 1, 1, 0, 0],
 [0, 1, 0, 1, 0],
 [0, 1, 0, 1, 1],
 [0, 1, 0, 1, 0]]
</pre></div></div>
</div>
</div>
<div class="section" id="Especificación-del-modelo">
<h3>Especificación del modelo<a class="headerlink" href="#Especificación-del-modelo" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se importa la libreria</span>
<span class="c1">##</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span>

<span class="c1">##</span>
<span class="c1">## Se crea un clasificador Gaussiano ingenuo</span>
<span class="c1">##</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">BernoulliNB</span><span class="p">(</span>
    <span class="c1">## Laplace parameter</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">binarize</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">fit_prior</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_prior</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Entrenamiento">
<h3>Entrenamiento<a class="headerlink" href="#Entrenamiento" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se entrena el clasificador</span>
<span class="c1">##</span>
<span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)
</pre></div></div>
</div>
</div>
<div class="section" id="Pronóstico">
<h3>Pronóstico<a class="headerlink" href="#Pronóstico" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se pronostica la clasificación de los</span>
<span class="c1">## mensajes para los datos de entrada</span>
<span class="c1">##</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texto</th>
      <th>tipo</th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ww1 ww3</td>
      <td>spam</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ww1 ww2 ww1 ww3</td>
      <td>spam</td>
      <td>spam</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ww2 ww4</td>
      <td>ham</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ww4 ww5 ww2</td>
      <td>ham</td>
      <td>ham</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ww2 ww4 ww2</td>
      <td>ham</td>
      <td>ham</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
</div>
<div class="section" id="Apéndice-----Solución-en-R">
<h2>Apéndice — Solución en R<a class="headerlink" href="#Apéndice-----Solución-en-R" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A continuación se presenta la solución del ejercicio anterior usando el lenguaje R.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-sh notranslate"><div class="highlight"><pre>
<span></span>%%sh
<span class="nv">PACK</span><span class="o">=</span>tm
<span class="k">if</span> /usr/bin/test ! -d /usr/local/lib/R/site-library/<span class="nv">$PACK</span><span class="p">;</span>
<span class="k">then</span>
    sudo Rscript -e <span class="s1">&#39;install.packages(&quot;&#39;</span><span class="nv">$PACK</span><span class="s1">&#39;&quot;)&#39;</span>
<span class="k">fi</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-sh notranslate"><div class="highlight"><pre>
<span></span>%%sh
<span class="nv">PACK</span><span class="o">=</span>e1071
<span class="k">if</span> /usr/bin/test ! -d /usr/local/lib/R/site-library/<span class="nv">$PACK</span><span class="p">;</span>
<span class="k">then</span>
    sudo Rscript -e <span class="s1">&#39;install.packages(&quot;&#39;</span><span class="nv">$PACK</span><span class="s1">&#39;&quot;)&#39;</span>
<span class="k">fi</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## Preparación</span>
<span class="c1">##</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tm</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
R[write to console]: Loading required package: NLP

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span> <span class="o">-</span><span class="n">i</span> <span class="n">df</span>
<span class="c1">##</span>
<span class="c1">## Se crea un corpus que es una colección de documentos.</span>
<span class="c1">##</span>
<span class="n">data_corpus</span> <span class="o">&lt;-</span> <span class="nf">VCorpus</span><span class="p">(</span><span class="nf">VectorSource</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">texto</span><span class="p">))</span>

<span class="c1">##</span>
<span class="c1">## Para ver los documentos del corpus se usa lapply</span>
<span class="c1">##</span>
<span class="nf">lapply</span><span class="p">(</span><span class="n">data_corpus</span><span class="p">,</span> <span class="n">as.character</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
$`1`
[1] &#34;ww1 ww3&#34;

$`2`
[1] &#34;ww1 ww2 ww1 ww3&#34;

$`3`
[1] &#34;ww2 ww4&#34;

$`4`
[1] &#34;ww4 ww5 ww2&#34;

$`5`
[1] &#34;ww2 ww4 ww2&#34;

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## Se puede consultar un mensaje individual</span>
<span class="c1">##</span>
<span class="nf">inspect</span><span class="p">(</span><span class="n">data_corpus[[1]]</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;&lt;PlainTextDocument&gt;&gt;
Metadata:  7
Content:  chars: 7

ww1 ww3
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## Se crea la matriz de términos del documento.</span>
<span class="c1">## Las filas corresponden a los mensajes..</span>
<span class="c1">## Las columnas corresponden a las palabras.</span>
<span class="c1">## El contenido representa la cantidad de veces que</span>
<span class="c1">## aparece una palabra en un documento determinado.</span>
<span class="c1">##</span>
<span class="n">data_dtm</span> <span class="o">&lt;-</span> <span class="nf">DocumentTermMatrix</span><span class="p">(</span><span class="n">data_corpus</span><span class="p">)</span>

<span class="c1">##</span>
<span class="c1">## A continuación se visualiza el contenido de la</span>
<span class="c1">## matriz de términos del documento</span>
<span class="c1">##</span>
<span class="nf">inspect</span><span class="p">(</span><span class="n">data_dtm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;&lt;DocumentTermMatrix (documents: 5, terms: 5)&gt;&gt;
Non-/sparse entries: 12/13
Sparsity           : 52%
Maximal term length: 3
Weighting          : term frequency (tf)
Sample             :
    Terms
Docs ww1 ww2 ww3 ww4 ww5
   1   1   0   1   0   0
   2   2   1   1   0   0
   3   0   1   0   1   0
   4   0   1   0   1   1
   5   0   2   0   1   0
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## La matriz de términos puede convertirse en</span>
<span class="c1">## una matriz de R</span>
<span class="c1">##</span>
<span class="nf">as.matrix</span><span class="p">(</span><span class="n">data_dtm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
    Terms
Docs ww1 ww2 ww3 ww4 ww5
   1   1   0   1   0   0
   2   2   1   1   0   0
   3   0   1   0   1   0
   4   0   1   0   1   1
   5   0   2   0   1   0
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## Se convierte la frecuencia de ocurrencia a &quot;Yes&quot; y &quot;No&quot;</span>
<span class="c1">##</span>
<span class="n">convert_counts</span> <span class="o">&lt;-</span>
<span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">ifelse</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="m">0</span><span class="p">,</span> <span class="s">&quot;Yes&quot;</span><span class="p">,</span> <span class="s">&quot;No&quot;</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">apply</span><span class="p">(</span><span class="n">data_dtm</span><span class="p">,</span> <span class="n">MARGIN</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="n">convert_counts</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
    Terms
Docs ww1   ww2   ww3   ww4   ww5
   1 &#34;Yes&#34; &#34;No&#34;  &#34;Yes&#34; &#34;No&#34;  &#34;No&#34;
   2 &#34;Yes&#34; &#34;Yes&#34; &#34;Yes&#34; &#34;No&#34;  &#34;No&#34;
   3 &#34;No&#34;  &#34;Yes&#34; &#34;No&#34;  &#34;Yes&#34; &#34;No&#34;
   4 &#34;No&#34;  &#34;Yes&#34; &#34;No&#34;  &#34;Yes&#34; &#34;Yes&#34;
   5 &#34;No&#34;  &#34;Yes&#34; &#34;No&#34;  &#34;Yes&#34; &#34;No&#34;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## Construye el clasificador</span>
<span class="c1">##</span>
<span class="n">clf</span> <span class="o">&lt;-</span> <span class="nf">naiveBayes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">df</span><span class="o">$</span><span class="n">tipo</span><span class="p">)</span>

<span class="c1">##</span>
<span class="c1">## Se imprime un resumen de parámetros</span>
<span class="c1">## del clasificador</span>
<span class="c1">##</span>
<span class="n">clf</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = x, y = df$tipo)

A-priori probabilities:
df$tipo
 ham spam
 0.6  0.4

Conditional probabilities:
       ww1
df$tipo No Yes
   ham   1   0
   spam  0   1

       ww2
df$tipo  No Yes
   ham  0.0 1.0
   spam 0.5 0.5

       ww3
df$tipo No Yes
   ham   1   0
   spam  0   1

       ww4
df$tipo No Yes
   ham   0   1
   spam  1   0

       ww5
df$tipo        No       Yes
   ham  0.6666667 0.3333333
   spam 1.0000000 0.0000000

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-r notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="n">R</span>
<span class="c1">##</span>
<span class="c1">## Se pronostica para los datos de prueba.</span>
<span class="c1">##</span>
<span class="nf">predict</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
factor(0)
Levels:
</pre></div></div>
</div>
<hr class="docutils" />
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>rm data.csv
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Juan D. Velasquez

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>