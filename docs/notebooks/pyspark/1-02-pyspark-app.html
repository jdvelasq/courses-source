

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="es" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="es" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Desarrollo de Aplicaciones en PySpark &mdash; documentación de --- Cursos --- - </title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script type="text/javascript" src="../../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="Operaciones sobre RDD (resilient distributed datasets)" href="1-03-operaciones-RDD.html" />
    <link rel="prev" title="WordCount en PySpark" href="1-01-wordcount.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../analitica-de-grandes-datos/content.html">Sesiones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../analitica-de-grandes-datos/grades.html">Laboratorios de Programación</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../analitica-de-grandes-datos/course-info.html">Información del curso</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a> &raquo;</li>
        
          <li><a href="../../analitica-de-grandes-datos/content.html">Sesiones</a> &raquo;</li>
        
      <li>Desarrollo de Aplicaciones en PySpark</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/notebooks/pyspark/1-02-pyspark-app.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Desarrollo-de-Aplicaciones-en-PySpark">
<h1>Desarrollo de Aplicaciones en PySpark<a class="headerlink" href="#Desarrollo-de-Aplicaciones-en-PySpark" title="Enlazar permanentemente con este título">¶</a></h1>
<ul class="simple">
<li><p><em>30 min</em> | Última modificación: Junio 22, 2019</p></li>
</ul>
<p>En este tutorial se describe como implementar y ejecutar una aplicación usando PySpark. Al finalizar este tutorial, el lector estará en capacidad de:</p>
<ul class="simple">
<li><p>Describir el proceso general de desarrollo de una aplicación.</p></li>
<li><p>Gestionar los archivos de entrada y salida de la aplicación.</p></li>
<li><p>Ejecutar la aplicación en Spark.</p></li>
</ul>
<div class="section" id="Descripción-de-la-aplicación">
<h2>Descripción de la aplicación<a class="headerlink" href="#Descripción-de-la-aplicación" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La aplicación desarrollada será el conteo de frecuencia de palabras, desarrollado en el tutorial “WordCount en Spark”.</p>
</div>
<div class="section" id="Preparación-de-los-datos">
<h2>Preparación de los datos<a class="headerlink" href="#Preparación-de-los-datos" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En este proceso, se que los datos originales se encuentran en una carpeta de la máquina local del usuario. Para este ejemplo, se crea el directorio <code class="docutils literal notranslate"><span class="pre">wordcount</span></code>en la carpeta actual y se crean tres archivos dentro de él.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Creación de la carpeta wordcount en la máquina local.</span>
<span class="c1">##</span>
<span class="o">!</span>mkdir -p wordcount/
</pre></div>
</div>
</div>
<p>A continuación se crean los tres archivos de prueba.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> wordcount/text0.txt
<span class="n">Analytics</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">discovery</span><span class="p">,</span> <span class="n">interpretation</span><span class="p">,</span> <span class="ow">and</span> <span class="n">communication</span> <span class="n">of</span> <span class="n">meaningful</span> <span class="n">patterns</span>
<span class="ow">in</span> <span class="n">data</span><span class="o">.</span> <span class="n">Especially</span> <span class="n">valuable</span> <span class="ow">in</span> <span class="n">areas</span> <span class="n">rich</span> <span class="k">with</span> <span class="n">recorded</span> <span class="n">information</span><span class="p">,</span> <span class="n">analytics</span> <span class="n">relies</span>
<span class="n">on</span> <span class="n">the</span> <span class="n">simultaneous</span> <span class="n">application</span> <span class="n">of</span> <span class="n">statistics</span><span class="p">,</span> <span class="n">computer</span> <span class="n">programming</span> <span class="ow">and</span> <span class="n">operations</span> <span class="n">research</span>
<span class="n">to</span> <span class="n">quantify</span> <span class="n">performance</span><span class="o">.</span>

<span class="n">Organizations</span> <span class="n">may</span> <span class="n">apply</span> <span class="n">analytics</span> <span class="n">to</span> <span class="n">business</span> <span class="n">data</span> <span class="n">to</span> <span class="n">describe</span><span class="p">,</span> <span class="n">predict</span><span class="p">,</span> <span class="ow">and</span> <span class="n">improve</span> <span class="n">business</span>
<span class="n">performance</span><span class="o">.</span> <span class="n">Specifically</span><span class="p">,</span> <span class="n">areas</span> <span class="n">within</span> <span class="n">analytics</span> <span class="n">include</span> <span class="n">predictive</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">prescriptive</span>
<span class="n">analytics</span><span class="p">,</span> <span class="n">enterprise</span> <span class="n">decision</span> <span class="n">management</span><span class="p">,</span> <span class="n">descriptive</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">cognitive</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">Big</span>
<span class="n">Data</span> <span class="n">Analytics</span><span class="p">,</span> <span class="n">retail</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">store</span> <span class="n">assortment</span> <span class="ow">and</span> <span class="n">stock</span><span class="o">-</span><span class="n">keeping</span> <span class="n">unit</span> <span class="n">optimization</span><span class="p">,</span>
<span class="n">marketing</span> <span class="n">optimization</span> <span class="ow">and</span> <span class="n">marketing</span> <span class="n">mix</span> <span class="n">modeling</span><span class="p">,</span> <span class="n">web</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">call</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">speech</span>
<span class="n">analytics</span><span class="p">,</span> <span class="n">sales</span> <span class="n">force</span> <span class="n">sizing</span> <span class="ow">and</span> <span class="n">optimization</span><span class="p">,</span> <span class="n">price</span> <span class="ow">and</span> <span class="n">promotion</span> <span class="n">modeling</span><span class="p">,</span> <span class="n">predictive</span>
<span class="n">science</span><span class="p">,</span> <span class="n">credit</span> <span class="n">risk</span> <span class="n">analysis</span><span class="p">,</span> <span class="ow">and</span> <span class="n">fraud</span> <span class="n">analytics</span><span class="o">.</span> <span class="n">Since</span> <span class="n">analytics</span> <span class="n">can</span> <span class="n">require</span> <span class="n">extensive</span>
<span class="n">computation</span> <span class="p">(</span><span class="n">see</span> <span class="n">big</span> <span class="n">data</span><span class="p">),</span> <span class="n">the</span> <span class="n">algorithms</span> <span class="ow">and</span> <span class="n">software</span> <span class="n">used</span> <span class="k">for</span> <span class="n">analytics</span> <span class="n">harness</span> <span class="n">the</span> <span class="n">most</span>
<span class="n">current</span> <span class="n">methods</span> <span class="ow">in</span> <span class="n">computer</span> <span class="n">science</span><span class="p">,</span> <span class="n">statistics</span><span class="p">,</span> <span class="ow">and</span> <span class="n">mathematics</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing wordcount/text0.txt
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> wordcount/text1.txt
<span class="n">The</span> <span class="n">field</span> <span class="n">of</span> <span class="n">data</span> <span class="n">analysis</span><span class="o">.</span> <span class="n">Analytics</span> <span class="n">often</span> <span class="n">involves</span> <span class="n">studying</span> <span class="n">past</span> <span class="n">historical</span> <span class="n">data</span> <span class="n">to</span>
<span class="n">research</span> <span class="n">potential</span> <span class="n">trends</span><span class="p">,</span> <span class="n">to</span> <span class="n">analyze</span> <span class="n">the</span> <span class="n">effects</span> <span class="n">of</span> <span class="n">certain</span> <span class="n">decisions</span> <span class="ow">or</span> <span class="n">events</span><span class="p">,</span> <span class="ow">or</span> <span class="n">to</span>
<span class="n">evaluate</span> <span class="n">the</span> <span class="n">performance</span> <span class="n">of</span> <span class="n">a</span> <span class="n">given</span> <span class="n">tool</span> <span class="ow">or</span> <span class="n">scenario</span><span class="o">.</span> <span class="n">The</span> <span class="n">goal</span> <span class="n">of</span> <span class="n">analytics</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">improve</span>
<span class="n">the</span> <span class="n">business</span> <span class="n">by</span> <span class="n">gaining</span> <span class="n">knowledge</span> <span class="n">which</span> <span class="n">can</span> <span class="n">be</span> <span class="n">used</span> <span class="n">to</span> <span class="n">make</span> <span class="n">improvements</span> <span class="ow">or</span> <span class="n">changes</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing wordcount/text1.txt
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> wordcount/text2.txt
<span class="n">Data</span> <span class="n">analytics</span> <span class="p">(</span><span class="n">DA</span><span class="p">)</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">process</span> <span class="n">of</span> <span class="n">examining</span> <span class="n">data</span> <span class="n">sets</span> <span class="ow">in</span> <span class="n">order</span> <span class="n">to</span> <span class="n">draw</span> <span class="n">conclusions</span>
<span class="n">about</span> <span class="n">the</span> <span class="n">information</span> <span class="n">they</span> <span class="n">contain</span><span class="p">,</span> <span class="n">increasingly</span> <span class="k">with</span> <span class="n">the</span> <span class="n">aid</span> <span class="n">of</span> <span class="n">specialized</span> <span class="n">systems</span>
<span class="ow">and</span> <span class="n">software</span><span class="o">.</span> <span class="n">Data</span> <span class="n">analytics</span> <span class="n">technologies</span> <span class="ow">and</span> <span class="n">techniques</span> <span class="n">are</span> <span class="n">widely</span> <span class="n">used</span> <span class="ow">in</span> <span class="n">commercial</span>
<span class="n">industries</span> <span class="n">to</span> <span class="n">enable</span> <span class="n">organizations</span> <span class="n">to</span> <span class="n">make</span> <span class="n">more</span><span class="o">-</span><span class="n">informed</span> <span class="n">business</span> <span class="n">decisions</span> <span class="ow">and</span> <span class="n">by</span>
<span class="n">scientists</span> <span class="ow">and</span> <span class="n">researchers</span> <span class="n">to</span> <span class="n">verify</span> <span class="ow">or</span> <span class="n">disprove</span> <span class="n">scientific</span> <span class="n">models</span><span class="p">,</span> <span class="n">theories</span> <span class="ow">and</span>
<span class="n">hypotheses</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing wordcount/text2.txt
</pre></div></div>
</div>
</div>
<div class="section" id="Copia-de-los-datos-de-entrada-al-sistema-HDFS">
<h2>Copia de los datos de entrada al sistema HDFS<a class="headerlink" href="#Copia-de-los-datos-de-entrada-al-sistema-HDFS" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En esta aplicación se supone que los datos siempre estarán en la carpeta <code class="docutils literal notranslate"><span class="pre">wordcount</span></code> del directorio actual de trabajo de la máquina local. El primer paso consisten en mover los archivos de la máquina local al sistema HDFS. Por ahora, este paso se hará manualmente. Se define que la aplicación usará siempre la carpeta <code class="docutils literal notranslate"><span class="pre">/tmp/wordcount/</span></code> del sistema HDFS.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Se crea la carpeta /tmp/wc en el sistema HDFS.</span>
<span class="c1">##</span>
<span class="o">!</span>hdfs dfs -mkdir /tmp/wordcount
<span class="o">!</span>hdfs dfs -mkdir /tmp/wordcount/input
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Copia los archvios del directorio local wordcount/</span>
<span class="c1">## al directorio /tmp/wordcount/input en el hdfs</span>
<span class="c1">##</span>
<span class="o">!</span>hdfs dfs -copyFromLocal wordcount/* /tmp/wordcount/input/
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## Verifica que los archivos esten copiados</span>
<span class="c1">## en el hdfs</span>
<span class="c1">##</span>
<span class="o">!</span>hdfs dfs -ls /tmp/wordcount/input
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found 3 items
-rw-r--r--   1 root supergroup       1093 2019-11-15 00:38 /tmp/wordcount/input/text0.txt
-rw-r--r--   1 root supergroup        352 2019-11-15 00:38 /tmp/wordcount/input/text1.txt
-rw-r--r--   1 root supergroup        440 2019-11-15 00:38 /tmp/wordcount/input/text2.txt
</pre></div></div>
</div>
</div>
<div class="section" id="Implementación-del-programa-en-PySpark">
<h2>Implementación del programa en PySpark<a class="headerlink" href="#Implementación-del-programa-en-PySpark" title="Enlazar permanentemente con este título">¶</a></h2>
<p>El archivo <code class="docutils literal notranslate"><span class="pre">wordcount.py</span></code> contiene la implementación de la aplicación. El código es el siguiente:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> wordcount.py

<span class="kn">import</span> <span class="nn">findspark</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkConf</span><span class="p">,</span> <span class="n">SparkContext</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="kn">import</span> <span class="n">add</span>

<span class="n">APP_NAME</span> <span class="o">=</span> <span class="s2">&quot;wordcount-app&quot;</span>

<span class="n">findspark</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">SparkConf</span><span class="p">()</span><span class="o">.</span><span class="n">setAppName</span><span class="p">(</span><span class="n">APP_NAME</span><span class="p">)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span>

<span class="c1">## Lee los archivos de la carpeta de entrada</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;/tmp/wordcount/input/*.txt&quot;</span><span class="p">)</span>

<span class="c1">## Este es el algoritmo para el conteo de frecuencia</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="n">wc</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">wc</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="n">add</span><span class="p">)</span>

<span class="c1">## Escribe los resultados en la carpeta de salida.</span>
<span class="n">counts</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s2">&quot;/tmp/wordcount/output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing wordcount.py
</pre></div></div>
</div>
</div>
<div class="section" id="Ejecución-de-la-aplicación">
<h2>Ejecución de la aplicación<a class="headerlink" href="#Ejecución-de-la-aplicación" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">##</span>
<span class="c1">## La aplicación es ejecutada usando spark-submit,</span>
<span class="c1">## el cual ejecuta el programa wordcount.py en Spark</span>
<span class="c1">##</span>
<span class="o">!</span>spark-submit wordcount.py
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
19/11/15 00:38:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/11/15 00:38:35 INFO spark.SparkContext: Running Spark version 2.4.4
19/11/15 00:38:35 INFO spark.SparkContext: Submitted application: wordcount-app
19/11/15 00:38:35 INFO spark.SecurityManager: Changing view acls to: root
19/11/15 00:38:35 INFO spark.SecurityManager: Changing modify acls to: root
19/11/15 00:38:35 INFO spark.SecurityManager: Changing view acls groups to:
19/11/15 00:38:35 INFO spark.SecurityManager: Changing modify acls groups to:
19/11/15 00:38:35 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/11/15 00:38:36 INFO util.Utils: Successfully started service &#39;sparkDriver&#39; on port 36081.
19/11/15 00:38:36 INFO spark.SparkEnv: Registering MapOutputTracker
19/11/15 00:38:36 INFO spark.SparkEnv: Registering BlockManagerMaster
19/11/15 00:38:36 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/11/15 00:38:36 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/11/15 00:38:36 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-c6bdfffe-3043-4e73-afd2-0144d04eb7b9
19/11/15 00:38:36 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
19/11/15 00:38:36 INFO spark.SparkEnv: Registering OutputCommitCoordinator
19/11/15 00:38:36 INFO util.log: Logging initialized @2561ms
19/11/15 00:38:36 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
19/11/15 00:38:36 INFO server.Server: Started @2629ms
19/11/15 00:38:36 INFO server.AbstractConnector: Started ServerConnector@4d428a45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
19/11/15 00:38:36 INFO util.Utils: Successfully started service &#39;SparkUI&#39; on port 4040.
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69c0257e{/jobs,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27357545{/jobs/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4d06bc8d{/jobs/job,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27542929{/jobs/job/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bc7ffdb{/stages,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@535ddcfa{/stages/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@795ae9f1{/stages/stage,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@566b300d{/stages/stage/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78504e50{/stages/pool,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@bb64ed2{/stages/pool/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4095499{/storage,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@bedf74d{/storage/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71350aae{/storage/rdd,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48cc1a84{/storage/rdd/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6af2298{/environment,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@621cfa9f{/environment/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3ba5ec08{/executors,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1395d9c2{/executors/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6cd192ca{/executors/threadDump,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@699c55cd{/executors/threadDump/json,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7dcd215a{/static,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ce38925{/,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1eef262a{/api,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79b10d70{/jobs/job/kill,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5fc1c880{/stages/stage/kill,null,AVAILABLE,@Spark}
19/11/15 00:38:36 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://1d6429ad4bf0:4040
19/11/15 00:38:36 INFO executor.Executor: Starting executor ID driver on host localhost
19/11/15 00:38:36 INFO util.Utils: Successfully started service &#39;org.apache.spark.network.netty.NettyBlockTransferService&#39; on port 34125.
19/11/15 00:38:36 INFO netty.NettyBlockTransferService: Server created on 1d6429ad4bf0:34125
19/11/15 00:38:36 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/11/15 00:38:36 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 1d6429ad4bf0, 34125, None)
19/11/15 00:38:36 INFO storage.BlockManagerMasterEndpoint: Registering block manager 1d6429ad4bf0:34125 with 366.3 MB RAM, BlockManagerId(driver, 1d6429ad4bf0, 34125, None)
19/11/15 00:38:36 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 1d6429ad4bf0, 34125, None)
19/11/15 00:38:36 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 1d6429ad4bf0, 34125, None)
19/11/15 00:38:36 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70eae4d1{/metrics/json,null,AVAILABLE,@Spark}
19/11/15 00:38:37 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 332.8 KB, free 366.0 MB)
19/11/15 00:38:37 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.1 KB, free 365.9 MB)
19/11/15 00:38:37 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 1d6429ad4bf0:34125 (size: 28.1 KB, free: 366.3 MB)
19/11/15 00:38:37 INFO spark.SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
19/11/15 00:38:37 INFO mapred.FileInputFormat: Total input files to process : 3
19/11/15 00:38:38 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
19/11/15 00:38:38 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:38:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:38:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/15 00:38:38 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Registering RDD 3 (reduceByKey at /datalake/pyspark/wordcount.py:18)
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 4 output partitions
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:78)
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /datalake/pyspark/wordcount.py:18), which has no missing parents
19/11/15 00:38:38 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.8 KB, free 365.9 MB)
19/11/15 00:38:38 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.0 KB, free 365.9 MB)
19/11/15 00:38:38 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 1d6429ad4bf0:34125 (size: 7.0 KB, free: 366.3 MB)
19/11/15 00:38:38 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
19/11/15 00:38:38 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /datalake/pyspark/wordcount.py:18) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/11/15 00:38:38 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
19/11/15 00:38:38 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7898 bytes)
19/11/15 00:38:38 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 7898 bytes)
19/11/15 00:38:38 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, ANY, 7898 bytes)
19/11/15 00:38:38 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, ANY, 7898 bytes)
19/11/15 00:38:38 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
19/11/15 00:38:38 INFO executor.Executor: Running task 1.0 in stage 0.0 (TID 1)
19/11/15 00:38:38 INFO executor.Executor: Running task 2.0 in stage 0.0 (TID 2)
19/11/15 00:38:38 INFO executor.Executor: Running task 3.0 in stage 0.0 (TID 3)
19/11/15 00:38:38 INFO rdd.HadoopRDD: Input split: hdfs://0.0.0.0:9000/tmp/wordcount/input/text0.txt:942+151
19/11/15 00:38:38 INFO rdd.HadoopRDD: Input split: hdfs://0.0.0.0:9000/tmp/wordcount/input/text1.txt:0+352
19/11/15 00:38:38 INFO rdd.HadoopRDD: Input split: hdfs://0.0.0.0:9000/tmp/wordcount/input/text0.txt:0+942
19/11/15 00:38:38 INFO rdd.HadoopRDD: Input split: hdfs://0.0.0.0:9000/tmp/wordcount/input/text2.txt:0+440
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 513, boot = 453, init = 54, finish = 6
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 510, boot = 448, init = 56, finish = 6
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 445, boot = 380, init = 53, finish = 12
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 529, boot = 429, init = 75, finish = 25
19/11/15 00:38:39 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1721 bytes result sent to driver
19/11/15 00:38:39 INFO executor.Executor: Finished task 2.0 in stage 0.0 (TID 2). 1721 bytes result sent to driver
19/11/15 00:38:39 INFO executor.Executor: Finished task 3.0 in stage 0.0 (TID 3). 1721 bytes result sent to driver
19/11/15 00:38:39 INFO executor.Executor: Finished task 1.0 in stage 0.0 (TID 1). 1721 bytes result sent to driver
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1009 ms on localhost (executor driver) (1/4)
19/11/15 00:38:39 INFO python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 36753
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1035 ms on localhost (executor driver) (2/4)
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1018 ms on localhost (executor driver) (3/4)
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1019 ms on localhost (executor driver) (4/4)
19/11/15 00:38:39 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
19/11/15 00:38:39 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (reduceByKey at /datalake/pyspark/wordcount.py:18) finished in 1.144 s
19/11/15 00:38:39 INFO scheduler.DAGScheduler: looking for newly runnable stages
19/11/15 00:38:39 INFO scheduler.DAGScheduler: running: Set()
19/11/15 00:38:39 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
19/11/15 00:38:39 INFO scheduler.DAGScheduler: failed: Set()
19/11/15 00:38:39 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
19/11/15 00:38:39 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 90.1 KB, free 365.8 MB)
19/11/15 00:38:39 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KB, free 365.8 MB)
19/11/15 00:38:39 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 1d6429ad4bf0:34125 (size: 34.2 KB, free: 366.2 MB)
19/11/15 00:38:39 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
19/11/15 00:38:39 INFO scheduler.DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/11/15 00:38:39 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, ANY, 7662 bytes)
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, ANY, 7662 bytes)
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, ANY, 7662 bytes)
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, ANY, 7662 bytes)
19/11/15 00:38:39 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 4)
19/11/15 00:38:39 INFO executor.Executor: Running task 1.0 in stage 1.0 (TID 5)
19/11/15 00:38:39 INFO executor.Executor: Running task 3.0 in stage 1.0 (TID 7)
19/11/15 00:38:39 INFO executor.Executor: Running task 2.0 in stage 1.0 (TID 6)
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 15 ms
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/11/15 00:38:39 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/11/15 00:38:39 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:38:39 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:38:39 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:38:39 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
19/11/15 00:38:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:38:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/15 00:38:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:38:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/15 00:38:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:38:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
19/11/15 00:38:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/15 00:38:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 50, boot = -456, init = 506, finish = 0
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 61, boot = -460, init = 520, finish = 1
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 61, boot = -459, init = 519, finish = 1
19/11/15 00:38:39 INFO python.PythonRunner: Times: total = 61, boot = -442, init = 502, finish = 1
19/11/15 00:38:39 INFO output.FileOutputCommitter: Saved output of task &#39;attempt_20191115003837_0008_m_000000_0&#39; to hdfs://0.0.0.0:9000/tmp/wordcount/output/_temporary/0/task_20191115003837_0008_m_000000
19/11/15 00:38:39 INFO mapred.SparkHadoopMapRedUtil: attempt_20191115003837_0008_m_000000_0: Committed
19/11/15 00:38:39 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 4). 2067 bytes result sent to driver
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 233 ms on localhost (executor driver) (1/4)
19/11/15 00:38:39 INFO output.FileOutputCommitter: Saved output of task &#39;attempt_20191115003837_0008_m_000001_0&#39; to hdfs://0.0.0.0:9000/tmp/wordcount/output/_temporary/0/task_20191115003837_0008_m_000001
19/11/15 00:38:39 INFO mapred.SparkHadoopMapRedUtil: attempt_20191115003837_0008_m_000001_0: Committed
19/11/15 00:38:39 INFO executor.Executor: Finished task 1.0 in stage 1.0 (TID 5). 2024 bytes result sent to driver
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 640 ms on localhost (executor driver) (2/4)
19/11/15 00:38:39 INFO output.FileOutputCommitter: Saved output of task &#39;attempt_20191115003837_0008_m_000003_0&#39; to hdfs://0.0.0.0:9000/tmp/wordcount/output/_temporary/0/task_20191115003837_0008_m_000003
19/11/15 00:38:39 INFO mapred.SparkHadoopMapRedUtil: attempt_20191115003837_0008_m_000003_0: Committed
19/11/15 00:38:39 INFO output.FileOutputCommitter: Saved output of task &#39;attempt_20191115003837_0008_m_000002_0&#39; to hdfs://0.0.0.0:9000/tmp/wordcount/output/_temporary/0/task_20191115003837_0008_m_000002
19/11/15 00:38:39 INFO executor.Executor: Finished task 3.0 in stage 1.0 (TID 7). 2024 bytes result sent to driver
19/11/15 00:38:39 INFO mapred.SparkHadoopMapRedUtil: attempt_20191115003837_0008_m_000002_0: Committed
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 643 ms on localhost (executor driver) (3/4)
19/11/15 00:38:39 INFO executor.Executor: Finished task 2.0 in stage 1.0 (TID 6). 2024 bytes result sent to driver
19/11/15 00:38:39 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 6) in 648 ms on localhost (executor driver) (4/4)
19/11/15 00:38:39 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
19/11/15 00:38:39 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopWriter.scala:78) finished in 0.680 s
19/11/15 00:38:39 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 1.887456 s
19/11/15 00:38:39 INFO io.SparkHadoopWriter: Job job_20191115003837_0008 committed.
]0;IPython: datalake/pyspark19/11/15 00:38:40 INFO spark.SparkContext: Invoking stop() from shutdown hook
19/11/15 00:38:40 INFO server.AbstractConnector: Stopped Spark@4d428a45{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
19/11/15 00:38:40 INFO ui.SparkUI: Stopped Spark web UI at http://1d6429ad4bf0:4040
19/11/15 00:38:40 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/11/15 00:38:40 INFO memory.MemoryStore: MemoryStore cleared
19/11/15 00:38:40 INFO storage.BlockManager: BlockManager stopped
19/11/15 00:38:40 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
19/11/15 00:38:40 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/11/15 00:38:40 INFO spark.SparkContext: Successfully stopped SparkContext
19/11/15 00:38:40 INFO util.ShutdownHookManager: Shutdown hook called
19/11/15 00:38:40 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-218d5c0b-d42c-4e08-8fa7-13c8c6080b80/pyspark-c8cf15a6-d47b-47df-82b1-9188d27b5034
19/11/15 00:38:40 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-218d5c0b-d42c-4e08-8fa7-13c8c6080b80
19/11/15 00:38:40 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-2b66405d-1d0a-468f-8d68-50c98e34d379
</pre></div></div>
</div>
</div>
<div class="section" id="Archivos-de-resultados">
<h2>Archivos de resultados<a class="headerlink" href="#Archivos-de-resultados" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La carpeta <code class="docutils literal notranslate"><span class="pre">/tmp/wordcount/output</span></code> contiene los resultados de la ejecución del programa.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">## Archivos con los resultados. Note que se</span>
<span class="c1">## generan varios archivos de resultados.</span>
<span class="o">!</span>hdfs dfs -ls /tmp/wordcount/output/
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found 5 items
-rw-r--r--   1 root supergroup          0 2019-11-15 00:38 /tmp/wordcount/output/_SUCCESS
-rw-r--r--   1 root supergroup        778 2019-11-15 00:38 /tmp/wordcount/output/part-00000
-rw-r--r--   1 root supergroup        562 2019-11-15 00:38 /tmp/wordcount/output/part-00001
-rw-r--r--   1 root supergroup        510 2019-11-15 00:38 /tmp/wordcount/output/part-00002
-rw-r--r--   1 root supergroup        594 2019-11-15 00:38 /tmp/wordcount/output/part-00003
</pre></div></div>
</div>
<p>El archivo <code class="docutils literal notranslate"><span class="pre">output/_SUCCESS</span></code> es un archivo vacio que indica que el programa fue ejecutado correctamente.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>hdfs dfs -cat /tmp/wordcount/output/part-00000 <span class="p">|</span> head
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;interpretation,&#39;, 1)
(&#39;of&#39;, 8)
(&#39;in&#39;, 5)
(&#39;data.&#39;, 1)
(&#39;Especially&#39;, 1)
(&#39;analytics&#39;, 8)
(&#39;simultaneous&#39;, 1)
(&#39;operations&#39;, 1)
(&#39;research&#39;, 2)
(&#39;quantify&#39;, 1)
</pre></div></div>
</div>
</div>
<div class="section" id="Archivo-de-comandos-del-sistema-operativo">
<h2>Archivo de comandos del sistema operativo<a class="headerlink" href="#Archivo-de-comandos-del-sistema-operativo" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Finalmente, se crea un script que copie los archivos y ejecute la aplicación.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>%%writefile wordcountapp
#! /bin/bash

## borra la carpeta input si existe
!hdfs dfs -rm -r -f /tmp/wordcount/input

## crea la carpeta
!hdfs dfs -mkdir /tmp/wordcount/input

## copia los archivos de entrada de la
## maquina local al sistema hdfs
!hdfs dfs -copyFromLocal wordcount/* /tmp/wordcount/input/

## ejecuta la aplicación de spark
spark-submit wordcount.py
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing wordcountapp
</pre></div></div>
</div>
<p>Esta aplicación sería ejecutada en Terminal con el siguiente comando:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ bash wordcountapp
</pre></div>
</div>
<hr class="docutils" />
<p><strong>Limpieza de las carpetas de trabajo</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>rm wordcountapp
<span class="o">!</span>rm -rf wordcount
<span class="o">!</span>hdfs dfs -rm -r -f /tmp/wordcount/
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Deleted /tmp/wordcount
</pre></div></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Juan D. Velasquez

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>