

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="es" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="es" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>WordCount en Apache Pig en modo standalone &mdash; documentación de --- Cursos --- - </title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script type="text/javascript" src="../../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="Conteo de palabras en Apache Hive" href="../hive/1-01-conteo-de-palabras-en-hive.html" />
    <link rel="prev" title="Funciones de Usuario (udfs)" href="2-06-udfs.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../analitica-de-grandes-datos/content.html">Sesiones</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../analitica-de-grandes-datos/grades.html">Laboratorios de Programación</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../analitica-de-grandes-datos/course-info.html">Información del curso</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica-financiera/index.html">Analítica Financiera</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ciencia-de-los-datos/index.html">Ciencia de los Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../redes-neuronales-con-tensorflow/index.html">Redes Neuronales Artificiales</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../analitica-de-grandes-datos/index.html">Analítica de grandes datos</a> &raquo;</li>
        
          <li><a href="../../analitica-de-grandes-datos/content.html">Sesiones</a> &raquo;</li>
        
      <li>WordCount en Apache Pig en modo standalone</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/notebooks/pig/2-07-standalone.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="WordCount-en-Apache-Pig-en-modo-standalone">
<h1>WordCount en Apache Pig en modo standalone<a class="headerlink" href="#WordCount-en-Apache-Pig-en-modo-standalone" title="Enlazar permanentemente con este título">¶</a></h1>
<ul class="simple">
<li><p>30 min | Última modificación: Noviembre 15, 2019</p></li>
</ul>
<div class="section" id="Definición-del-problema">
<h2>Definición del problema<a class="headerlink" href="#Definición-del-problema" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Se desea contar la frecuencia de ocurrencia de palabras en un conjunto de documentos usando Apache Pig.</p>
</div>
<div class="section" id="Solución">
<h2>Solución<a class="headerlink" href="#Solución" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="section" id="Preparación">
<h3>Preparación<a class="headerlink" href="#Preparación" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="section" id="Inicio-de-la-máquina-virtual">
<h4>Inicio de la máquina virtual<a class="headerlink" href="#Inicio-de-la-máquina-virtual" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Si usa linux o macOS puede pasar directamente al siguiente paso. Inicie la VM con:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>vagrant up
</pre></div>
</div>
<p>y luego vaya a la carpeta de trabajo:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">vagrant</span>
</pre></div>
</div>
</div>
<div class="section" id="Ejecución-del-contendor-de-Docker">
<h4>Ejecución del contendor de Docker<a class="headerlink" href="#Ejecución-del-contendor-de-Docker" title="Enlazar permanentemente con este título">¶</a></h4>
<p>Si va a iniciar el contendor de Hadoop en la carpeta compartida con su máquina local use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">--</span><span class="n">rm</span> <span class="o">-</span><span class="n">it</span> <span class="o">-</span><span class="n">v</span> <span class="s2">&quot;$PWD&quot;</span><span class="p">:</span><span class="o">/</span><span class="n">datalake</span>  <span class="o">--</span><span class="n">name</span> <span class="n">pig</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8888</span><span class="p">:</span><span class="mi">8888</span> <span class="n">jdvelasq</span><span class="o">/</span><span class="n">pig</span><span class="p">:</span><span class="mf">0.17</span><span class="o">.</span><span class="mi">0</span><span class="o">-</span><span class="n">standalone</span>
</pre></div>
</div>
<p>Si desea iniciar la sesión en el <code class="docutils literal notranslate"><span class="pre">datalake</span></code> use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">--</span><span class="n">rm</span> <span class="o">-</span><span class="n">it</span> <span class="o">-</span><span class="n">v</span> <span class="n">datalake</span><span class="p">:</span><span class="o">/</span><span class="n">datalake</span> <span class="o">--</span><span class="n">name</span> <span class="n">pig</span>  <span class="o">-</span><span class="n">p</span> <span class="mi">8888</span><span class="p">:</span><span class="mi">8888</span> <span class="n">jdvelasq</span><span class="o">/</span><span class="n">pig</span><span class="p">:</span><span class="mf">0.17</span><span class="o">.</span><span class="mi">0</span><span class="o">-</span><span class="n">standalone</span>
</pre></div>
</div>
<p>Si un contenedor ya se está ejecutando puede abrir un nuevo terminal con:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="n">pig</span> <span class="n">bash</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Archivos-de-prueba">
<h3>Archivos de prueba<a class="headerlink" href="#Archivos-de-prueba" title="Enlazar permanentemente con este título">¶</a></h3>
<p>A continuación se generarán tres archivos de prueba para probar el sistema. Puede usar directamente comandos del sistema operativo en el Terminal y el editor de texto <code class="docutils literal notranslate"><span class="pre">pico</span></code> para crear los archivos.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">## Se crea el directorio de entrada</span>
<span class="o">!</span>rm -rf input tmp
<span class="o">!</span>mkdir input
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> input/text0.txt
<span class="n">Analytics</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">discovery</span><span class="p">,</span> <span class="n">interpretation</span><span class="p">,</span> <span class="ow">and</span> <span class="n">communication</span> <span class="n">of</span> <span class="n">meaningful</span> <span class="n">patterns</span>
<span class="ow">in</span> <span class="n">data</span><span class="o">.</span> <span class="n">Especially</span> <span class="n">valuable</span> <span class="ow">in</span> <span class="n">areas</span> <span class="n">rich</span> <span class="k">with</span> <span class="n">recorded</span> <span class="n">information</span><span class="p">,</span> <span class="n">analytics</span> <span class="n">relies</span>
<span class="n">on</span> <span class="n">the</span> <span class="n">simultaneous</span> <span class="n">application</span> <span class="n">of</span> <span class="n">statistics</span><span class="p">,</span> <span class="n">computer</span> <span class="n">programming</span> <span class="ow">and</span> <span class="n">operations</span> <span class="n">research</span>
<span class="n">to</span> <span class="n">quantify</span> <span class="n">performance</span><span class="o">.</span>

<span class="n">Organizations</span> <span class="n">may</span> <span class="n">apply</span> <span class="n">analytics</span> <span class="n">to</span> <span class="n">business</span> <span class="n">data</span> <span class="n">to</span> <span class="n">describe</span><span class="p">,</span> <span class="n">predict</span><span class="p">,</span> <span class="ow">and</span> <span class="n">improve</span> <span class="n">business</span>
<span class="n">performance</span><span class="o">.</span> <span class="n">Specifically</span><span class="p">,</span> <span class="n">areas</span> <span class="n">within</span> <span class="n">analytics</span> <span class="n">include</span> <span class="n">predictive</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">prescriptive</span>
<span class="n">analytics</span><span class="p">,</span> <span class="n">enterprise</span> <span class="n">decision</span> <span class="n">management</span><span class="p">,</span> <span class="n">descriptive</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">cognitive</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">Big</span>
<span class="n">Data</span> <span class="n">Analytics</span><span class="p">,</span> <span class="n">retail</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">store</span> <span class="n">assortment</span> <span class="ow">and</span> <span class="n">stock</span><span class="o">-</span><span class="n">keeping</span> <span class="n">unit</span> <span class="n">optimization</span><span class="p">,</span>
<span class="n">marketing</span> <span class="n">optimization</span> <span class="ow">and</span> <span class="n">marketing</span> <span class="n">mix</span> <span class="n">modeling</span><span class="p">,</span> <span class="n">web</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">call</span> <span class="n">analytics</span><span class="p">,</span> <span class="n">speech</span>
<span class="n">analytics</span><span class="p">,</span> <span class="n">sales</span> <span class="n">force</span> <span class="n">sizing</span> <span class="ow">and</span> <span class="n">optimization</span><span class="p">,</span> <span class="n">price</span> <span class="ow">and</span> <span class="n">promotion</span> <span class="n">modeling</span><span class="p">,</span> <span class="n">predictive</span>
<span class="n">science</span><span class="p">,</span> <span class="n">credit</span> <span class="n">risk</span> <span class="n">analysis</span><span class="p">,</span> <span class="ow">and</span> <span class="n">fraud</span> <span class="n">analytics</span><span class="o">.</span> <span class="n">Since</span> <span class="n">analytics</span> <span class="n">can</span> <span class="n">require</span> <span class="n">extensive</span>
<span class="n">computation</span> <span class="p">(</span><span class="n">see</span> <span class="n">big</span> <span class="n">data</span><span class="p">),</span> <span class="n">the</span> <span class="n">algorithms</span> <span class="ow">and</span> <span class="n">software</span> <span class="n">used</span> <span class="k">for</span> <span class="n">analytics</span> <span class="n">harness</span> <span class="n">the</span> <span class="n">most</span>
<span class="n">current</span> <span class="n">methods</span> <span class="ow">in</span> <span class="n">computer</span> <span class="n">science</span><span class="p">,</span> <span class="n">statistics</span><span class="p">,</span> <span class="ow">and</span> <span class="n">mathematics</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing input/text0.txt
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> input/text1.txt
<span class="n">The</span> <span class="n">field</span> <span class="n">of</span> <span class="n">data</span> <span class="n">analysis</span><span class="o">.</span> <span class="n">Analytics</span> <span class="n">often</span> <span class="n">involves</span> <span class="n">studying</span> <span class="n">past</span> <span class="n">historical</span> <span class="n">data</span> <span class="n">to</span>
<span class="n">research</span> <span class="n">potential</span> <span class="n">trends</span><span class="p">,</span> <span class="n">to</span> <span class="n">analyze</span> <span class="n">the</span> <span class="n">effects</span> <span class="n">of</span> <span class="n">certain</span> <span class="n">decisions</span> <span class="ow">or</span> <span class="n">events</span><span class="p">,</span> <span class="ow">or</span> <span class="n">to</span>
<span class="n">evaluate</span> <span class="n">the</span> <span class="n">performance</span> <span class="n">of</span> <span class="n">a</span> <span class="n">given</span> <span class="n">tool</span> <span class="ow">or</span> <span class="n">scenario</span><span class="o">.</span> <span class="n">The</span> <span class="n">goal</span> <span class="n">of</span> <span class="n">analytics</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">improve</span>
<span class="n">the</span> <span class="n">business</span> <span class="n">by</span> <span class="n">gaining</span> <span class="n">knowledge</span> <span class="n">which</span> <span class="n">can</span> <span class="n">be</span> <span class="n">used</span> <span class="n">to</span> <span class="n">make</span> <span class="n">improvements</span> <span class="ow">or</span> <span class="n">changes</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing input/text1.txt
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> input/text2.txt
<span class="n">Data</span> <span class="n">analytics</span> <span class="p">(</span><span class="n">DA</span><span class="p">)</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">process</span> <span class="n">of</span> <span class="n">examining</span> <span class="n">data</span> <span class="n">sets</span> <span class="ow">in</span> <span class="n">order</span> <span class="n">to</span> <span class="n">draw</span> <span class="n">conclusions</span>
<span class="n">about</span> <span class="n">the</span> <span class="n">information</span> <span class="n">they</span> <span class="n">contain</span><span class="p">,</span> <span class="n">increasingly</span> <span class="k">with</span> <span class="n">the</span> <span class="n">aid</span> <span class="n">of</span> <span class="n">specialized</span> <span class="n">systems</span>
<span class="ow">and</span> <span class="n">software</span><span class="o">.</span> <span class="n">Data</span> <span class="n">analytics</span> <span class="n">technologies</span> <span class="ow">and</span> <span class="n">techniques</span> <span class="n">are</span> <span class="n">widely</span> <span class="n">used</span> <span class="ow">in</span> <span class="n">commercial</span>
<span class="n">industries</span> <span class="n">to</span> <span class="n">enable</span> <span class="n">organizations</span> <span class="n">to</span> <span class="n">make</span> <span class="n">more</span><span class="o">-</span><span class="n">informed</span> <span class="n">business</span> <span class="n">decisions</span> <span class="ow">and</span> <span class="n">by</span>
<span class="n">scientists</span> <span class="ow">and</span> <span class="n">researchers</span> <span class="n">to</span> <span class="n">verify</span> <span class="ow">or</span> <span class="n">disprove</span> <span class="n">scientific</span> <span class="n">models</span><span class="p">,</span> <span class="n">theories</span> <span class="ow">and</span>
<span class="n">hypotheses</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Writing input/text2.txt
</pre></div></div>
</div>
</div>
<div class="section" id="Código-en-Apache-Pig">
<h3>Código en Apache Pig<a class="headerlink" href="#Código-en-Apache-Pig" title="Enlazar permanentemente con este título">¶</a></h3>
<p><strong>Nota.</strong> Se usan los dos guiones <code class="docutils literal notranslate"><span class="pre">--</span></code> para comentario de una línea y <code class="docutils literal notranslate"><span class="pre">/*</span></code> … <code class="docutils literal notranslate"><span class="pre">*/</span></code> para comentarios de varias líneas.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%writefile</span> script.pig

<span class="o">--</span> <span class="n">crea</span> <span class="n">la</span> <span class="n">carpeta</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">el</span> <span class="n">HDFS</span>
<span class="n">fs</span> <span class="o">-</span><span class="n">mkdir</span> <span class="n">tmp</span>
<span class="n">fs</span> <span class="o">-</span><span class="n">mkdir</span> <span class="n">tmp</span><span class="o">/</span><span class="nb">input</span>

<span class="o">--</span> <span class="n">copia</span> <span class="n">los</span> <span class="n">archivos</span> <span class="k">del</span> <span class="n">sistema</span> <span class="n">local</span> <span class="n">al</span> <span class="n">HDFS</span>
<span class="n">fs</span> <span class="o">-</span><span class="n">put</span> <span class="nb">input</span><span class="o">/</span> <span class="n">tmp</span><span class="o">/</span>

<span class="o">--</span> <span class="n">carga</span> <span class="n">de</span> <span class="n">datos</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">LOAD</span> <span class="s1">&#39;tmp/input/text*.txt&#39;</span> <span class="n">AS</span> <span class="p">(</span><span class="n">line</span><span class="p">:</span><span class="n">CHARARRAY</span><span class="p">);</span>

<span class="o">--</span> <span class="n">genera</span> <span class="n">una</span> <span class="n">tabla</span> <span class="n">llamada</span> <span class="n">words</span> <span class="n">con</span> <span class="n">una</span> <span class="n">palabra</span> <span class="n">por</span> <span class="n">registro</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">FOREACH</span> <span class="n">lines</span> <span class="n">GENERATE</span> <span class="n">FLATTEN</span><span class="p">(</span><span class="n">TOKENIZE</span><span class="p">(</span><span class="n">line</span><span class="p">))</span> <span class="n">AS</span> <span class="n">word</span><span class="p">;</span>

<span class="o">--</span> <span class="n">agrupa</span> <span class="n">los</span> <span class="n">registros</span> <span class="n">que</span> <span class="n">tienen</span> <span class="n">la</span> <span class="n">misma</span> <span class="n">palabra</span>
<span class="n">grouped</span> <span class="o">=</span> <span class="n">GROUP</span> <span class="n">words</span> <span class="n">BY</span> <span class="n">word</span><span class="p">;</span>

<span class="o">--</span> <span class="n">genera</span> <span class="n">una</span> <span class="n">variable</span> <span class="n">que</span> <span class="n">cuenta</span> <span class="n">las</span> <span class="n">ocurrencias</span> <span class="n">por</span> <span class="n">cada</span> <span class="n">grupo</span>
<span class="n">wordcount</span> <span class="o">=</span> <span class="n">FOREACH</span> <span class="n">grouped</span> <span class="n">GENERATE</span> <span class="n">group</span><span class="p">,</span> <span class="n">COUNT</span><span class="p">(</span><span class="n">words</span><span class="p">);</span>

<span class="o">--</span> <span class="n">selecciona</span> <span class="n">las</span> <span class="n">primeras</span> <span class="mi">15</span> <span class="n">palabras</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">LIMIT</span> <span class="n">wordcount</span> <span class="mi">15</span><span class="p">;</span>

<span class="o">--</span> <span class="n">escribe</span> <span class="n">el</span> <span class="n">archivo</span> <span class="n">de</span> <span class="n">salida</span>
<span class="n">STORE</span> <span class="n">s</span> <span class="n">INTO</span> <span class="s1">&#39;tmp/output&#39;</span><span class="p">;</span>

<span class="o">--</span> <span class="n">copia</span> <span class="n">los</span> <span class="n">archivos</span> <span class="k">del</span> <span class="n">HDFS</span> <span class="n">al</span> <span class="n">sistema</span> <span class="n">local</span> <span class="p">(</span><span class="n">genera</span> <span class="n">la</span> <span class="n">carpeta</span> <span class="n">output</span> <span class="n">en</span> <span class="n">el</span> <span class="n">directorio</span> <span class="n">actual</span><span class="p">)</span>
<span class="n">fs</span> <span class="o">-</span><span class="n">get</span> <span class="n">tmp</span><span class="o">/</span><span class="n">output</span><span class="o">/</span> <span class="o">.</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Overwriting script.pig
</pre></div></div>
</div>
</div>
<div class="section" id="Ejecución-del-script-en-modo-standalone">
<h3>Ejecución del script en modo standalone<a class="headerlink" href="#Ejecución-del-script-en-modo-standalone" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pig -execute <span class="s1">&#39;run script.pig&#39;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2019-11-15 02:31:43,492 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-11-15 02:31:44,405 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator
2019-11-15 02:31:44,678 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
2019-11-15 02:31:44,679 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
2019-11-15 02:31:44,701 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
2019-11-15 02:31:44,704 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
2019-11-15 02:31:44,736 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
2019-11-15 02:31:44,743 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication
2019-11-15 02:31:44,851 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address
2019-11-15 02:31:44,861 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:44,872 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2019-11-15 02:31:44,924 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2019-11-15 02:31:45,026 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 3
2019-11-15 02:31:45,057 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
2019-11-15 02:31:45,138 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1059171614_0001
2019-11-15 02:31:45,342 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785105218/pig-0.17.0-core-h2.jar &lt;- /datalake/pig/pig-0.17.0-core-h2.jar
2019-11-15 02:31:45,352 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp-681383038/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1573785105218/pig-0.17.0-core-h2.jar
2019-11-15 02:31:45,366 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785105219/automaton-1.11-8.jar &lt;- /datalake/pig/automaton-1.11-8.jar
2019-11-15 02:31:45,369 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp1410257452/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1573785105219/automaton-1.11-8.jar
2019-11-15 02:31:45,369 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785105220/antlr-runtime-3.4.jar &lt;- /datalake/pig/antlr-runtime-3.4.jar
2019-11-15 02:31:45,372 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp208607162/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1573785105220/antlr-runtime-3.4.jar
2019-11-15 02:31:45,372 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785105221/joda-time-2.9.3.jar &lt;- /datalake/pig/joda-time-2.9.3.jar
2019-11-15 02:31:45,375 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp-1341981989/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1573785105221/joda-time-2.9.3.jar
2019-11-15 02:31:45,443 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785105218/pig-0.17.0-core-h2.jar
2019-11-15 02:31:45,444 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785105219/automaton-1.11-8.jar
2019-11-15 02:31:45,444 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785105220/antlr-runtime-3.4.jar
2019-11-15 02:31:45,444 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785105221/joda-time-2.9.3.jar
2019-11-15 02:31:45,448 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2019-11-15 02:31:45,450 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2019-11-15 02:31:45,487 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
2019-11-15 02:31:45,487 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
2019-11-15 02:31:45,490 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:45,490 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:45,491 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2019-11-15 02:31:45,547 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2019-11-15 02:31:45,547 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1059171614_0001_m_000000_0
2019-11-15 02:31:45,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:45,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:45,603 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2019-11-15 02:31:45,608 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :3
Total Length = 1885
Input split[0]:
   Length = 1093
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit
   Locations:

-----------------------
Input split[1]:
   Length = 440
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit
   Locations:

-----------------------
Input split[2]:
   Length = 352
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit
   Locations:

-----------------------

2019-11-15 02:31:45,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2019-11-15 02:31:45,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2019-11-15 02:31:45,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2019-11-15 02:31:45,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2019-11-15 02:31:45,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2019-11-15 02:31:45,678 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-11-15 02:31:45,802 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner -
2019-11-15 02:31:45,802 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output
2019-11-15 02:31:45,802 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output
2019-11-15 02:31:45,802 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 3602; bufvoid = 104857600
2019-11-15 02:31:45,802 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213388(104853552); length = 1009/6553600
2019-11-15 02:31:45,858 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0
2019-11-15 02:31:45,872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1059171614_0001_m_000000_0 is done. And is in the process of committing
2019-11-15 02:31:45,900 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map
2019-11-15 02:31:45,900 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task &#39;attempt_local1059171614_0001_m_000000_0&#39; done.
2019-11-15 02:31:45,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1059171614_0001_m_000000_0: Counters: 18
        File System Counters
                FILE: Number of bytes read=5805191
                FILE: Number of bytes written=12096229
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=24
                Map output records=253
                Map output bytes=3602
                Map output materialized bytes=2687
                Input split bytes=483
                Combine input records=253
                Combine output records=155
                Spilled Records=155
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=400556032
        File Input Format Counters
                Bytes Read=0
2019-11-15 02:31:45,904 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1059171614_0001_m_000000_0
2019-11-15 02:31:45,904 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2019-11-15 02:31:45,908 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2019-11-15 02:31:45,908 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1059171614_0001_r_000000_0
2019-11-15 02:31:45,930 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:45,930 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:45,946 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2019-11-15 02:31:45,949 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@34b2efd6
2019-11-15 02:31:45,962 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2019-11-15 02:31:45,964 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1059171614_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2019-11-15 02:31:45,998 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1059171614_0001_m_000000_0 decomp: 2683 len: 2687 to MEMORY
2019-11-15 02:31:46,005 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2683 bytes from map-output for attempt_local1059171614_0001_m_000000_0
2019-11-15 02:31:46,007 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -&gt; map-output of size: 2683, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;2683
2019-11-15 02:31:46,008 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2019-11-15 02:31:46,009 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
2019-11-15 02:31:46,009 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2019-11-15 02:31:46,014 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2019-11-15 02:31:46,014 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2677 bytes
2019-11-15 02:31:46,018 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2683 bytes to disk to satisfy reduce memory limit
2019-11-15 02:31:46,019 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2687 bytes from disk
2019-11-15 02:31:46,020 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2019-11-15 02:31:46,020 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2019-11-15 02:31:46,021 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2677 bytes
2019-11-15 02:31:46,022 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
2019-11-15 02:31:46,025 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:46,026 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:46,027 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2019-11-15 02:31:46,038 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1059171614_0001_r_000000_0 is done. And is in the process of committing
2019-11-15 02:31:46,041 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
2019-11-15 02:31:46,041 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1059171614_0001_r_000000_0 is allowed to commit now
2019-11-15 02:31:46,044 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task &#39;attempt_local1059171614_0001_r_000000_0&#39; to file:/tmp/temp-1327976925/tmp-382248047/_temporary/0/task_local1059171614_0001_r_000000
2019-11-15 02:31:46,045 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce &gt; reduce
2019-11-15 02:31:46,045 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task &#39;attempt_local1059171614_0001_r_000000_0&#39; done.
2019-11-15 02:31:46,046 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1059171614_0001_r_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=5810597
                FILE: Number of bytes written=12099135
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=155
                Reduce shuffle bytes=2687
                Reduce input records=155
                Reduce output records=15
                Spilled Records=155
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=12
                Total committed heap usage (bytes)=400556032
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=0
2019-11-15 02:31:46,046 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1059171614_0001_r_000000_0
2019-11-15 02:31:46,047 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2019-11-15 02:31:50,467 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:50,479 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:50,479 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2019-11-15 02:31:50,481 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:50,548 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:50,553 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2019-11-15 02:31:50,632 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2019-11-15 02:31:50,634 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
2019-11-15 02:31:50,648 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1598448235_0002
2019-11-15 02:31:50,800 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785110672/pig-0.17.0-core-h2.jar &lt;- /datalake/pig/pig-0.17.0-core-h2.jar
2019-11-15 02:31:50,803 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp197641247/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1573785110672/pig-0.17.0-core-h2.jar
2019-11-15 02:31:50,803 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785110673/automaton-1.11-8.jar &lt;- /datalake/pig/automaton-1.11-8.jar
2019-11-15 02:31:50,807 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp-1024201414/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1573785110673/automaton-1.11-8.jar
2019-11-15 02:31:50,807 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785110674/antlr-runtime-3.4.jar &lt;- /datalake/pig/antlr-runtime-3.4.jar
2019-11-15 02:31:50,810 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp1175028320/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1573785110674/antlr-runtime-3.4.jar
2019-11-15 02:31:50,811 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1573785110675/joda-time-2.9.3.jar &lt;- /datalake/pig/joda-time-2.9.3.jar
2019-11-15 02:31:50,814 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1327976925/tmp663184705/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1573785110675/joda-time-2.9.3.jar
2019-11-15 02:31:50,859 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785110672/pig-0.17.0-core-h2.jar
2019-11-15 02:31:50,859 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785110673/automaton-1.11-8.jar
2019-11-15 02:31:50,859 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785110674/antlr-runtime-3.4.jar
2019-11-15 02:31:50,859 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1573785110675/joda-time-2.9.3.jar
2019-11-15 02:31:50,860 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2019-11-15 02:31:50,861 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2019-11-15 02:31:50,871 [Thread-54] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator
2019-11-15 02:31:50,872 [Thread-54] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
2019-11-15 02:31:50,872 [Thread-54] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent
2019-11-15 02:31:50,873 [Thread-54] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:50,873 [Thread-54] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:50,873 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter
2019-11-15 02:31:50,882 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2019-11-15 02:31:50,882 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1598448235_0002_m_000000_0
2019-11-15 02:31:50,893 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:50,893 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:50,893 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2019-11-15 02:31:50,896 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1
Total Length = 207
Input split[0]:
   Length = 207
   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit
   Locations:

-----------------------

2019-11-15 02:31:50,951 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2019-11-15 02:31:50,951 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2019-11-15 02:31:50,951 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2019-11-15 02:31:50,951 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2019-11-15 02:31:50,952 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2019-11-15 02:31:50,953 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2019-11-15 02:31:50,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner -
2019-11-15 02:31:50,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output
2019-11-15 02:31:50,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output
2019-11-15 02:31:50,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 237; bufvoid = 104857600
2019-11-15 02:31:50,959 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2019-11-15 02:31:50,961 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0
2019-11-15 02:31:50,962 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1598448235_0002_m_000000_0 is done. And is in the process of committing
2019-11-15 02:31:50,965 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map
2019-11-15 02:31:50,965 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task &#39;attempt_local1598448235_0002_m_000000_0&#39; done.
2019-11-15 02:31:50,965 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1598448235_0002_m_000000_0: Counters: 17
        File System Counters
                FILE: Number of bytes read=11612080
                FILE: Number of bytes written=24179434
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Map input records=15
                Map output records=15
                Map output bytes=237
                Map output materialized bytes=273
                Input split bytes=379
                Combine input records=0
                Spilled Records=15
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=505937920
        File Input Format Counters
                Bytes Read=0
2019-11-15 02:31:50,966 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1598448235_0002_m_000000_0
2019-11-15 02:31:50,966 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2019-11-15 02:31:50,967 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2019-11-15 02:31:50,967 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1598448235_0002_r_000000_0
2019-11-15 02:31:50,979 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:50,979 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:50,981 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]
2019-11-15 02:31:50,981 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@bb946c0
2019-11-15 02:31:50,982 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2019-11-15 02:31:50,983 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1598448235_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2019-11-15 02:31:50,987 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1598448235_0002_m_000000_0 decomp: 269 len: 273 to MEMORY
2019-11-15 02:31:50,988 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 269 bytes from map-output for attempt_local1598448235_0002_m_000000_0
2019-11-15 02:31:50,988 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -&gt; map-output of size: 269, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;269
2019-11-15 02:31:50,990 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2019-11-15 02:31:50,991 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
2019-11-15 02:31:50,991 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2019-11-15 02:31:50,992 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2019-11-15 02:31:50,992 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 256 bytes
2019-11-15 02:31:50,994 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 269 bytes to disk to satisfy reduce memory limit
2019-11-15 02:31:50,994 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 273 bytes from disk
2019-11-15 02:31:50,994 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2019-11-15 02:31:50,994 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2019-11-15 02:31:50,995 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 256 bytes
2019-11-15 02:31:50,995 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
2019-11-15 02:31:51,009 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2019-11-15 02:31:51,009 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-11-15 02:31:51,037 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1598448235_0002_r_000000_0 is done. And is in the process of committing
2019-11-15 02:31:51,044 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
2019-11-15 02:31:51,044 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1598448235_0002_r_000000_0 is allowed to commit now
2019-11-15 02:31:51,051 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task &#39;attempt_local1598448235_0002_r_000000_0&#39; to file:/datalake/pig/tmp/output/_temporary/0/task_local1598448235_0002_r_000000
2019-11-15 02:31:51,052 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce &gt; reduce
2019-11-15 02:31:51,052 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task &#39;attempt_local1598448235_0002_r_000000_0&#39; done.
2019-11-15 02:31:51,053 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1598448235_0002_r_000000_0: Counters: 24
        File System Counters
                FILE: Number of bytes read=11612658
                FILE: Number of bytes written=24179800
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
        Map-Reduce Framework
                Combine input records=0
                Combine output records=0
                Reduce input groups=15
                Reduce shuffle bytes=273
                Reduce input records=15
                Reduce output records=15
                Spilled Records=15
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=0
                Total committed heap usage (bytes)=505937920
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Output Format Counters
                Bytes Written=0
2019-11-15 02:31:51,053 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1598448235_0002_r_000000_0
2019-11-15 02:31:51,053 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2019-11-15 02:31:56,065 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,066 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,067 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,080 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,081 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,082 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,090 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,091 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2019-11-15 02:31:56,092 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
</pre></div></div>
</div>
</div>
<div class="section" id="Visualización-de-los-resultados-en-el-HDFS">
<h3>Visualización de los resultados en el HDFS<a class="headerlink" href="#Visualización-de-los-resultados-en-el-HDFS" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>hadoop fs -ls tmp/output/*
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-rw-r--r--   1 root root          0 2019-11-15 02:31 tmp/output/_SUCCESS
-rw-r--r--   1 root root         81 2019-11-15 02:31 tmp/output/part-r-00000
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>hadoop fs -cat tmp/output/part-r-00000
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
a       1
DA      1
be      1
by      2
in      5
is      3
of      8
on      1
or      5
to      12
Big     1
The     2
aid     1
and     15
are     1
</pre></div></div>
</div>
</div>
<div class="section" id="Limpieza-del-HDFS-y-de-la-máquina-local">
<h3>Limpieza del HDFS y de la máquina local<a class="headerlink" href="#Limpieza-del-HDFS-y-de-la-máquina-local" title="Enlazar permanentemente con este título">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>rm -rf input tmp output
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Juan D. Velasquez

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>