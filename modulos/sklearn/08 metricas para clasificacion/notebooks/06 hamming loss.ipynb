{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d925946-2f45-46ff-b19d-37bc2cc4b9e2",
   "metadata": {},
   "source": [
    "Hamming loss\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbfdfad-fef1-4c11-b602-3cba339701d2",
   "metadata": {},
   "source": [
    "* Esta función computa el promedio de la función de pérdida de Hamming o distancia de Hamming entre dos conjuntos de muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a277324-dd30-47dc-b8b1-54ef25357287",
   "metadata": {},
   "source": [
    "* La distancia de Hamming entre dos strings de igual longitud es el número de posiciones en que los símbolos son diferentes. Tambien se define como la cantidad mínima de sustituciones requeridas para transformar un string en otro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a14a668-6a1e-4b96-b272-a807229d257a",
   "metadata": {},
   "source": [
    "* La función de pérdida se define como:\n",
    "$$\n",
    "L_\\text{Hamming}(y, \\hat{y}) = \n",
    "\\frac{1}{n_\\text{samples} \\times n_\\text{labels}}\n",
    "\\sum_{i=0}^{n_\\text{samples} - 1}\n",
    "\\sum_{j=0}^{n_\\text{labels} - 1}\n",
    "1(\\hat{y}_{i,j} \\ne y_{i,j})\n",
    "$$\n",
    "donde:\n",
    "\n",
    "    * $\\hat{y}_{i,j}$ es el valor pronosticado para la $j$-ésima etiqueta de la muestra $i$. \n",
    "    \n",
    "    * $y_{i,j}$ es el valor verdadero.\n",
    "     \n",
    "    * $n_\\text{samples}$ es el número de muestras.\n",
    "     \n",
    "    * $n_\\text{labels}$ es el número de etiquetas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c75cc-fb5d-4a70-bdec-78cab3e042ab",
   "metadata": {},
   "source": [
    "* La ecuación anterior no puede ser usada para clasificación con múltiples clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a131365-23ee-4b2a-878f-aab8c97bcfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "y_pred = [1, 2, 3, 4]\n",
    "y_true = [2, 2, 3, 4]\n",
    "\n",
    "hamming_loss(\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Ground truth (correct) labels.\n",
    "    y_true=y_true,\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Predicted labels, as returned by a classifier.\n",
    "    y_pred=y_pred,\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Sample weights.\n",
    "    sample_weight=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83145a97-48d2-4143-a5b5-a859055f2a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#\n",
    "# y_true:\n",
    "#   [[0, 1],\n",
    "#    [1, 1]]\n",
    "#\n",
    "# y_pred:\n",
    "#   [[0, 0],\n",
    "#    [0, 0]]\n",
    "#\n",
    "\n",
    "hamming_loss(\n",
    "    y_true=np.array([[0, 1], [1, 1]]),\n",
    "    y_pred=np.zeros((2, 2)),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
