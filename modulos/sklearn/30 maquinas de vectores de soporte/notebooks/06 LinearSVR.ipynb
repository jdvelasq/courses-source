{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c322504-53b2-45e9-842e-699096309919",
   "metadata": {},
   "source": [
    "LinearSVR\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30b87f-c884-48a1-aeb4-fded94a74382",
   "metadata": {},
   "source": [
    "* Corresponde al modelo SVR con kernel lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243bb4ec-8a1e-4257-9341-e02d94f1a6d7",
   "metadata": {},
   "source": [
    "* Se obtiene al reformular el problema primal como:\n",
    "\n",
    "$$\n",
    "\\min_{w,b} \\frac{1}{2} w^T w + C \\sum_{i=1}^n \\max \\left(0, |y_i - (w^T \\phi(x_i)+ b)| - \\epsilon\\right) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0054e456-e586-4742-85dc-ed0ad9c7d3f1",
   "metadata": {},
   "source": [
    "* Se usa la función de error $\\epsilon$-insensitiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5a095b-61b6-4207-9af1-6a5feda0ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_features=4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ea96c7-f446-4293-9a63-33aae992c411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -30.55095759,   -0.6458061 ,  -77.1914936 ,  -13.38403813,\n",
       "         18.1801038 ,  -30.12151035,   34.56371925,  -80.16935785,\n",
       "        -32.35589234,   59.78179542,  -83.44132152,   67.77309488,\n",
       "        -49.92473794,  -23.93571221, -111.84789107,  -44.08465841,\n",
       "        -87.14806055, -110.71870437,    8.49643527,   -4.97835778,\n",
       "         20.81752614,   84.59286846,   98.07396361,   73.15235246,\n",
       "        -72.53155235,  -25.12048214,  200.41121381,  -54.24288837,\n",
       "         28.41800609,   50.19661321,   81.68962756,   -7.23505086,\n",
       "         -3.45935488,   82.877153  ,  -99.49055193,   55.22880025,\n",
       "         -3.93677763,   89.27545316, -137.64285998, -208.68974901,\n",
       "         67.07670989,  -19.83287988,   69.73081865,   62.0966189 ,\n",
       "        -80.72307316,  -30.95893732,   88.55105755, -157.64785808,\n",
       "        -43.94367411,   63.09924443,  -90.03014181,   39.28808415,\n",
       "         98.56851178,  211.98062677, -104.96636582,  -51.02058039,\n",
       "         37.40133741,  -49.11142001,  -53.38541583,   45.44301341,\n",
       "         17.39746762,   73.58381415,  202.61309322,   23.56670239,\n",
       "         62.43038472,   60.6262052 , -163.86100282,   50.31192299,\n",
       "         65.12008149,  -34.33836754,   84.53070356,  -24.53157987,\n",
       "       -179.18454211,  -19.65462806,  -43.23869415,  109.58684464,\n",
       "        -52.97892474,  -13.88767123,  -59.76937543,  -69.6739172 ,\n",
       "        -21.91120677,  -10.48687369,  -65.8454146 ,  -68.89790057,\n",
       "        -36.88303111,  -14.07884056,   13.08608705,   88.63078331,\n",
       "       -143.8483861 ,   98.86990346,  -82.89696107,   69.32654946,\n",
       "       -101.68547961,  -27.56443293,  153.73557004, -178.86173772,\n",
       "        -15.68495868,  -13.87536386,   30.9876405 ,  -82.98927737])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "linearSVR = LinearSVR(\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Epsilon parameter in the epsilon-insensitive loss function. Note that the\n",
    "    # value of this parameter depends on the scale of the target variable y. If\n",
    "    # unsure, set epsilon=0.\n",
    "    epsilon=0.0,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Tolerance for stopping criterion.\n",
    "    tol=1e-3,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Regularization parameter. The strength of the regularization is inversely\n",
    "    # proportional to C. Must be strictly positive.\n",
    "    # penalty.\n",
    "    C=1,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Specifies the loss function. The epsilon-insensitive loss (standard SVR) \n",
    "    # is the L1 loss, while the squared epsilon-insensitive loss \n",
    "    # (‘squared_epsilon_insensitive’) is the L2 loss.\n",
    "    loss='epsilon_insensitive',\n",
    "    # --------------------------------------------------------------------------\n",
    "    # hether to calculate the intercept for this model. If set to false, no\n",
    "    # intercept will be used in calculations\n",
    "    fit_intercept=True,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # When self.fit_intercept is True, instance vector x becomes\n",
    "    # [x, self.intercept_scaling], i.e. a “synthetic” feature with constant\n",
    "    # value equals to intercept_scaling is appended to the instance vector. The\n",
    "    # intercept becomes intercept_scaling * synthetic feature weight Note! the\n",
    "    # synthetic feature weight is subject to l1/l2 regularization as all other\n",
    "    # features. To lessen the effect of regularization on synthetic feature\n",
    "    # weight (and therefore on the intercept) intercept_scaling has to be\n",
    "    # increased.\n",
    "    intercept_scaling=1.0,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Select the algorithm to either solve the dual or primal optimization \n",
    "    # problem. Prefer dual=False when n_samples > n_features.\n",
    "    dual=True,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Controls the pseudo random number generation for shuffling the data. Pass\n",
    "    # an int for reproducible output across multiple function calls\n",
    "    random_state=None,\n",
    "    # --------------------------------------------------------------------------\n",
    "    # The maximum number of iterations to be run.\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "linearSVR.fit(X, y)\n",
    "linearSVR.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66468fc6-03a8-4d8a-9dd8-f92f091621f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989207322892478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVR.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c17aa1d-2131-421b-acb9-d1d7b2a47d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.31719289, 26.73950553, 42.36522226, 60.46032178])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVR.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660dffd8-c667-48d1-8102-59be9a417478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.45333764])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVR.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
