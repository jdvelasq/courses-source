{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f47fe60-47b6-498f-92f9-45c75619ced1",
   "metadata": {},
   "source": [
    "Definición\n",
    "===\n",
    "\n",
    "* Ultima modificación: 2023-03-11 | [YouTube](https://www.youtube.com/watch?v=2485ZJz5NZg&list=PLEFpZ3YehTnDwjNNX3D7jjBsVKshZH4Kb&index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86133ec0-1eb3-498f-80a6-e101d543502e",
   "metadata": {},
   "source": [
    "* Es un metodo de aprendizaje supervisado no paramétrico usado para clasificación y regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28b95d-d1f5-4aec-aeff-b7d8e38d26db",
   "metadata": {},
   "source": [
    "* El modelo aprende reglas de decisión simples que pueden ser inferidas de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91656d72-c511-46ef-a251-b96d38c33dbf",
   "metadata": {},
   "source": [
    "* Scikit-learn implementa el algoritmo CART."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eddf70-7a3a-4d93-8fd7-bc351c495094",
   "metadata": {},
   "source": [
    "* Su estructura puede interpretarse como un árbol de decisiones, el cual parte del dominio de las variables independienes en regiones. Para decidir que región asignar a un nuevo punto ($x_1$, $x_2$) simplemente se recorre el árbol de decisión usando los valores $x_1$ y $x_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4b2fe-0306-42a8-be09-4cf1312cf167",
   "metadata": {},
   "source": [
    "![assets/tree.jpg](assets/tree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dcabc6-6d1e-454e-a3d7-f3a0085add1c",
   "metadata": {},
   "source": [
    "* El árbol de la derecha puede interpretarse como un conjunto de reglas if anidadas:\n",
    "\n",
    "      if x2 > C then \n",
    "         class = azul\n",
    "      else\n",
    "         if x1 < A then\n",
    "             class = verde\n",
    "         else\n",
    "             if x2 < B then \n",
    "                 class = rojo\n",
    "             else\n",
    "                 class = amarillo\n",
    "             end if\n",
    "         end if\n",
    "      end if\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a1660-d84b-4e6f-9308-cc65492131b8",
   "metadata": {},
   "source": [
    "* Sus ventajas son las siguientes:\n",
    "\n",
    "    * Es fácil de entender e interpretar, y puede ser visualizado.\n",
    "    \n",
    "    * Requere poca preparación de la data. No requiere normalización ni creación de variables dummy.\n",
    "    \n",
    "    * Es computacionalmente eficiente en pronóstico.\n",
    "    \n",
    "    * Se considera un modelo de caja blanca, es decir, es facil explicar un resultado entregado por el modelo.\n",
    "    \n",
    "    * Es posible validar el modelo usando técnicas estadísticas.\n",
    "    \n",
    "    * Tiene un buen comportamiento aunque se violen los supuestos de los datos que fueron usados para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89c0e7-1e7f-4d18-8516-2a25f50924ae",
   "metadata": {},
   "source": [
    "* Su desventajas son las siguientes:\n",
    "\n",
    "    * Pueden presentar sobreajuste.\n",
    "    \n",
    "    * Pueden ser inestables, es decir, pequeñas variaciones en los datos pueden producir árboles completamente diferentes.\n",
    "    \n",
    "    * La predicción es brusca y discontinua, similar a los modelos lineales por tramos.\n",
    "    \n",
    "    * No son buenos modelos para extrapolar.\n",
    "    \n",
    "    * La obtención de un árbol de decisión óptimo es tipo NP-completo, por lo que se usan algoritmos heurísticos.\n",
    "    \n",
    "    * Existen conceptos que un árbol no puede expresar fáciltmente como los problemas XOR, paridad o multiplexers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de39ff-1ab0-43d9-b861-8c25dc4e48a6",
   "metadata": {},
   "source": [
    "* Para su uso práctico se deben tener en cuenta los siguientes puntos:\n",
    "\n",
    "    * Los árboles decisión tienden a sobreajustar datasets con un número grande de características. \n",
    "    \n",
    "    * Se recomienda utilizar técnicas de reducción de la dimensinalidad (PCA, ICA, selección de características) antes de entrenar el árbol.\n",
    "    \n",
    "    * Se debe analizar la estructura del árbol de decisión y visualizarla.\n",
    "    \n",
    "    * Se debe controlar la profundidad del árbol para prevenir sobreajuste.\n",
    "    \n",
    "    * Se debe controlar el número mínimo de patrones asociados a un nodo.\n",
    "    \n",
    "    * En clasificación el dataset debería ser balanceado para evitar que el árbol se sesge hacia la clase más frecuente.\n",
    "    \n",
    "    * En lo posible se deben usar pesos para los patrones o ejemplos, con el fin de facilitar la optimización del árbol."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
