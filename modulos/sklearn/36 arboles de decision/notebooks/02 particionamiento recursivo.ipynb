{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23fdf9c0-f7a9-43d6-9b60-4ca3eb9426c0",
   "metadata": {},
   "source": [
    "Algoritmo general de particionamiento recursivo\n",
    "===\n",
    "\n",
    "* Ultima modificación: 2023-03-11 | [YouTube](https://www.youtube.com/watch?v=2485ZJz5NZg&list=PLEFpZ3YehTnDwjNNX3D7jjBsVKshZH4Kb&index=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa9eac-8ab7-45a9-a92a-4a83d1959022",
   "metadata": {},
   "source": [
    "* Considere el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa7156-5be8-4c5f-920e-551702b0d366",
   "metadata": {},
   "source": [
    "![assets/tree-exercise.jpg](assets/tree-exercise.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe7eec-a68a-4714-9f82-5ab4733024d1",
   "metadata": {},
   "source": [
    "* Este puede ser representado como una tabla de datos:\n",
    "\n",
    "        x1  x2  clase\n",
    "       --------------- \n",
    "         1   1   rojo\n",
    "         1   2   rojo\n",
    "         1   3   rojo\n",
    "         1   4   rojo\n",
    "         2   1   rojo\n",
    "         2   2   azul\n",
    "         2   3   azul\n",
    "         2   4   rojo\n",
    "         3   1   gris\n",
    "         3   2   azul\n",
    "         3   3   azul\n",
    "         3   4   rojo\n",
    "         4   1   gris\n",
    "         4   2   gris\n",
    "         4   3   gris\n",
    "         4   4   azul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc300d77-2fbb-4fcd-a9a0-147a80d0ad3e",
   "metadata": {},
   "source": [
    "* En el ejemplo, se tienen únicamente dos atributos $x_1$ y $x_2$, y un total de $N$ ejemplos para construir el árbol. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b45bd-4dc5-477c-9854-65256826bd4e",
   "metadata": {},
   "source": [
    "* Para construir la primera instancia, se construyen todos los árboles posibles de profunidad 1 (un nodo). El primer árbol se construye usando como frontera de decisión el primer valor de $x_1$ en la muestra del ejemplo (véase la figura de abajo); el segundo árbol se construye con el segundo valor, y así sucesivamente. Una vez se recorren todos los valores de $x_1$, se recorren todos los valores de $x_2$ y así sucesivamente hasta agotar todas las variables explicativas (atributos).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff1528-884f-4230-b7e3-8eeef2ac78f0",
   "metadata": {},
   "source": [
    "![assets/C50-rule1.jpg](assets/C50-rule1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef5c6f-97ac-4174-9d7d-dbafb684ca11",
   "metadata": {},
   "source": [
    "* La mejor partición se escoje como aquella que clasifica el mayor número de ejemplos correctamente (o una métrica equivente) y se obtiene un primer árbol. Esto equivale a encontra la mejor partición de todo el espacio de características en dos regiones que clasifiquen de mejor forma los ejemplos usandos para el entrenamiento del modelo (véase la parte derecha de la figura anterior). En la figura anterior, se supone que la mejor clasificación se obtiene usando como punto de corte el dato `x1[4]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4af1d-cf8a-4602-8974-e8c203ed47a7",
   "metadata": {},
   "source": [
    "* El algoritmo continua obteniendo una tercera región y para ello se debe decidir cuál de las dos regiones existentes se parte y en que orientación va dicho corte. El algoritmo prueba nuevamente cada punto del conjunto de datos como punto de corte de la siguiente manera: se hace `x1[1]` el nuevo punto de corte; si `x1[1]` está a la izquierda de `x1[4]`, se esta partiendo dicha región y por lo tanto se agrega esta nueva partición en la parte correspondiente de la regla (primera partición de la figura de abajo). Se hace `x1[2]` el nuevo punto de corte; si se asume que `x1[2]` esta a la derecha de `x1[4]` entonces se agrega a la parte `else` del modelo óptimo; se procede así sucesivamente hasta hasta obtener todos los modelos posibles con dos cortes. Asumiendo que el mejor corte se obtiene para `x2[6]`, el árbol queda como se presenta en el conjunto de reglas de la parte derecha de la siguiente figura.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8b146-8ebf-4ce5-8030-12b68bee5b14",
   "metadata": {},
   "source": [
    "![assets/C50-rule2.jpg](assets/C50-rule2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e152e4-8ade-4ac5-a989-a603fb5e5d62",
   "metadata": {},
   "source": [
    "* El proceso continua agregando un tercer corte, luego un cuarto y así sucesivamente. De ahí que el proceso se conozca como particionamiento recursivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29abda33-a1a0-45f4-b888-f44fa30c8e1f",
   "metadata": {},
   "source": [
    "* Nótese que el proceso puede realizarse hasta que se asigne una región única a cada uno de los datos, lo que resulta erróneo ya que el modelo simplemente memoriza la información usada para el entrenamiento (explique que es esto!). El proceso de crecimiento del árbol de decisión puede deternerse asignando un máximo a la profundidad del árbol (early stoping) o limitando la cantidad mínima de puntos que puede contener una región (pre-pruning)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
