{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Deprecated) WordCount en PySpark (modo standalone)\n",
    "===\n",
    "\n",
    "* *30 min* | Última modificacion: Noviembre 16, 2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contenedor en Docker\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usando la máquina local:\n",
    "\n",
    "```\n",
    "docker run --rm -it -v \"$PWD\":/datalake  --name pyspark -p 8888:8888 jdvelasq/pyspark:2.4.4-standalone\n",
    "```\n",
    "\n",
    "\n",
    "* Usando un volumen de docker:\n",
    "\n",
    "```\n",
    "docker run --rm -it -v datalake:/datalake --name pyspark  -p 8888:8888 jdvelasq/pyspark:2.4.4-standalone\n",
    "```\n",
    "\n",
    "\n",
    "* Acceso a un contenedor corriendo:\n",
    "\n",
    "```\n",
    "docker exec -it pyspark bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición del problema\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Se crea el directorio wordcount en la carpeta actual de trabajo\n",
    "# y se escriben tres archivos en ella.\n",
    "#\n",
    "!mkdir -p wordcount/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text0.txt\n",
    "Analytics is the discovery, interpretation, and communication of meaningful patterns \n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies \n",
    "on the simultaneous application of statistics, computer programming and operations research \n",
    "to quantify performance.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business \n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive \n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big \n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization, \n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech \n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive \n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive \n",
    "computation (see big data), the algorithms and software used for analytics harness the most \n",
    "current methods in computer science, statistics, and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to \n",
    "research potential trends, to analyze the effects of certain decisions or events, or to \n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve \n",
    "the business by gaining knowledge which can be used to make improvements or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions \n",
    "about the information they contain, increasingly with the aid of specialized systems \n",
    "and software. Data analytics technologies and techniques are widely used in commercial \n",
    "industries to enable organizations to make more-informed business decisions and by \n",
    "scientists and researchers to verify or disprove scientific models, theories and \n",
    "hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solución\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:27 /tmp/hsperfdata_root\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se usan un directorio temporal en el HDFS. La siguiente\n",
    "# instrucción muestra el contenido del dicho directorio\n",
    "#\n",
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Crea la carpeta wordcount en el hdfs\n",
    "#\n",
    "!hdfs dfs -mkdir /tmp/wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:28 /tmp/hsperfdata_root\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:28 /tmp/wordcount\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Verifica la creación de la carpeta\n",
    "#\n",
    "!hdfs dfs -ls /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Copia los archvios del directorio local wordcount/\n",
    "# al directorio /tmp/wordcount/ en el hdfs\n",
    "#\n",
    "!hdfs dfs -copyFromLocal wordcount/*  /tmp/wordcount/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root root       1093 2019-11-16 11:28 /tmp/wordcount/text0.txt\n",
      "-rw-r--r--   1 root root        352 2019-11-16 11:28 /tmp/wordcount/text1.txt\n",
      "-rw-r--r--   1 root root        440 2019-11-16 11:28 /tmp/wordcount/text2.txt\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Verifica que los archivos esten copiados\n",
    "# en el hdfs\n",
    "#\n",
    "!hdfs dfs -ls /tmp/wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación en PySpark\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación en PySpark es la siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# findspark: Permite usar PySpark como una libreria de Python\n",
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "#\n",
    "# Importa las librerias requeridas para conectar\n",
    "# a Python con PySpark\n",
    "#\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#\n",
    "# operador de agregación (MapReduce)\n",
    "#\n",
    "from operator import add\n",
    "\n",
    "#\n",
    "# Nombre de la aplicación en el cluster\n",
    "#\n",
    "APP_NAME = \"My Spark Application\"\n",
    "\n",
    "#\n",
    "# Configure Spark\n",
    "#\n",
    "conf = SparkConf().setAppName(APP_NAME) \n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analytics is the discovery, interpretation, and communication of meaningful patterns ',\n",
       " 'in data. Especially valuable in areas rich with recorded information, analytics relies ',\n",
       " 'on the simultaneous application of statistics, computer programming and operations research ',\n",
       " 'to quantify performance.',\n",
       " '',\n",
       " 'Organizations may apply analytics to business data to describe, predict, and improve business ',\n",
       " 'performance. Specifically, areas within analytics include predictive analytics, prescriptive ',\n",
       " 'analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big ',\n",
       " 'Data Analytics, retail analytics, store assortment and stock-keeping unit optimization, ',\n",
       " 'marketing optimization and marketing mix modeling, web analytics, call analytics, speech ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Lee los archivos del hdfs y los carga\n",
    "# a la variable text\n",
    "#\n",
    "text = sc.textFile(\"/tmp/wordcount/*.txt\")\n",
    "\n",
    "# Se imprimen las primeras 10 líneas\n",
    "text.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analytics',\n",
       " 'is',\n",
       " 'the',\n",
       " 'discovery,',\n",
       " 'interpretation,',\n",
       " 'and',\n",
       " 'communication',\n",
       " 'of',\n",
       " 'meaningful',\n",
       " 'patterns']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# separa por palabras (split)\n",
    "# con una palabra por registro\n",
    "#\n",
    "words = text.flatMap(lambda x: x.split())\n",
    "\n",
    "# Se imprimen las primeras 10 palabras\n",
    "words.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Analytics', 1),\n",
       " ('is', 1),\n",
       " ('the', 1),\n",
       " ('discovery,', 1),\n",
       " ('interpretation,', 1),\n",
       " ('and', 1),\n",
       " ('communication', 1),\n",
       " ('of', 1),\n",
       " ('meaningful', 1),\n",
       " ('patterns', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Genera las parejas <clave, valor> representandolas\n",
    "# com la tupla (word, 1)\n",
    "#\n",
    "wc = words.map(lambda x: (x,1))\n",
    "wc.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('interpretation,', 1),\n",
       " ('of', 8),\n",
       " ('in', 5),\n",
       " ('data.', 1),\n",
       " ('Especially', 1),\n",
       " ('analytics', 8),\n",
       " ('simultaneous', 1),\n",
       " ('operations', 1),\n",
       " ('research', 2),\n",
       " ('quantify', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Suma los valores para la misma clave.\n",
    "# Spark internamente ordena por claves\n",
    "#\n",
    "counts = wc.reduceByKey(add)\n",
    "counts.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Escribe los resultados al directorio `/tmp/output`\n",
    "#\n",
    "counts.saveAsTextFile(\"/tmp/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo de resultados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:29 /tmp/blockmgr-dc0a35be-c1e7-4952-88ad-e823aebb8ef3\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:29 /tmp/hsperfdata_root\n",
      "-rw-r--r--   1 root root      59545 2019-11-16 11:28 /tmp/liblz4-java2548858282861632294.so\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:29 /tmp/output\n",
      "drwx------   - root root       4096 2019-11-16 11:28 /tmp/spark-5bea8c51-1e31-400b-a7a9-57118c19e7cb\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:28 /tmp/spark-d68ac211-749a-41c9-b07f-69ccfbde47ef\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:28 /tmp/wordcount\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "-rw-r--r--   1 root root          0 2019-11-16 11:29 /tmp/output/_SUCCESS\n",
      "-rw-r--r--   1 root root        778 2019-11-16 11:29 /tmp/output/part-00000\n",
      "-rw-r--r--   1 root root        562 2019-11-16 11:29 /tmp/output/part-00001\n",
      "-rw-r--r--   1 root root        510 2019-11-16 11:29 /tmp/output/part-00002\n",
      "-rw-r--r--   1 root root        594 2019-11-16 11:29 /tmp/output/part-00003\n"
     ]
    }
   ],
   "source": [
    "# Archivos con los resultados. Note que se \n",
    "# generan varios archivos de resultados.\n",
    "!hdfs dfs -ls /tmp/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo `/tmp/output/_SUCCESS` es un archivo vacio que indica que el programa fue ejecutado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('interpretation,', 1)\n",
      "('of', 8)\n",
      "('in', 5)\n",
      "('data.', 1)\n",
      "('Especially', 1)\n",
      "('analytics', 8)\n",
      "('simultaneous', 1)\n",
      "('operations', 1)\n",
      "('research', 2)\n",
      "('quantify', 1)\n",
      "('Organizations', 1)\n",
      "('may', 1)\n",
      "('business', 4)\n",
      "('predict,', 1)\n",
      "('include', 1)\n",
      "('decision', 1)\n",
      "('descriptive', 1)\n",
      "('store', 1)\n",
      "('optimization,', 2)\n",
      "('modeling,', 2)\n",
      "('speech', 1)\n",
      "('promotion', 1)\n",
      "('risk', 1)\n",
      "('fraud', 1)\n",
      "('Since', 1)\n",
      "('algorithms', 1)\n",
      "('used', 3)\n",
      "('harness', 1)\n",
      "('current', 1)\n",
      "('field', 1)\n",
      "('involves', 1)\n",
      "('studying', 1)\n",
      "('potential', 1)\n",
      "('trends,', 1)\n",
      "('performance', 1)\n",
      "('goal', 1)\n",
      "('changes.', 1)\n",
      "('process', 1)\n",
      "('draw', 1)\n",
      "('specialized', 1)\n",
      "('systems', 1)\n",
      "('software.', 1)\n",
      "('techniques', 1)\n",
      "('are', 1)\n",
      "('commercial', 1)\n",
      "('organizations', 1)\n",
      "('disprove', 1)\n",
      "('scientific', 1)\n",
      "('hypotheses.', 1)\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /tmp/output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movimiento de los archivos de resultados a la máquina local\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea la carpeta local para poder mover los archivos\n",
    "!mkdir -p output\n",
    "!hdfs dfs -copyToLocal /tmp/output/* output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root   0 Nov 16 11:29 output/_SUCCESS\n",
      "-rw-r--r-- 1 root root 778 Nov 16 11:29 output/part-00000\n",
      "-rw-r--r-- 1 root root 562 Nov 16 11:29 output/part-00001\n",
      "-rw-r--r-- 1 root root 510 Nov 16 11:29 output/part-00002\n",
      "-rw-r--r-- 1 root root 594 Nov 16 11:29 output/part-00003\n"
     ]
    }
   ],
   "source": [
    "!ls -l output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de las carpetas de trabajo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/wordcount\n",
      "Deleted /tmp/output\n"
     ]
    }
   ],
   "source": [
    "!rm -rf wordcount\n",
    "!rm -rf output\n",
    "!hdfs dfs -rm -r -f /tmp/wordcount/\n",
    "!hdfs dfs -rm -r -f /tmp/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:29 /tmp/blockmgr-dc0a35be-c1e7-4952-88ad-e823aebb8ef3\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:30 /tmp/hsperfdata_root\n",
      "-rw-r--r--   1 root root      59545 2019-11-16 11:28 /tmp/liblz4-java2548858282861632294.so\n",
      "drwx------   - root root       4096 2019-11-16 11:28 /tmp/spark-5bea8c51-1e31-400b-a7a9-57118c19e7cb\n",
      "drwxr-xr-x   - root root       4096 2019-11-16 11:28 /tmp/spark-d68ac211-749a-41c9-b07f-69ccfbde47ef\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
