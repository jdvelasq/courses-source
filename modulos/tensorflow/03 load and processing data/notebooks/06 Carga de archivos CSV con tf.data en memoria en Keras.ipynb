{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968f3aa4-e951-4c7d-8fd2-671dd1d9a747",
   "metadata": {
    "tags": []
   },
   "source": [
    "Carga de archivos CSV con tf.data en memoria --- 12:17 min\n",
    "===\n",
    "\n",
    "* Última modificación: Marzo 6, 2022 | [YouTube]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774b0ef-23a1-4f55-80ae-93e1a83d1990",
   "metadata": {
    "tags": []
   },
   "source": [
    "Importación de librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997b0503-2252-493c-ab55-10d98b18f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b16c4-9493-4136-8c1b-cf09189e89f6",
   "metadata": {},
   "source": [
    "Carga y preparación de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a994e9-6731-45c7-84d5-ad0c5ddd996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop(\"survived\")\n",
    "\n",
    "titanic_features_dict = {\n",
    "    name: np.array(value) for name, value in titanic_features.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52576a-fe7b-4c9b-8c19-18a31a733a2c",
   "metadata": {},
   "source": [
    "Iteración usando un slice manual\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b0dcac-b50e-431d-b7f8-80210c27a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def slices(features):\n",
    "    #\n",
    "    # count(start=0, step=1)  genera una secuencia de valores igualmente espaciados.\n",
    "    # Note que no se almacena la cantidad de items de features.\n",
    "    #\n",
    "    for i in itertools.count():\n",
    "        example = {name: values[i] for name, values in features.items()}\n",
    "        yield example\n",
    "\n",
    "\n",
    "for example in slices(titanic_features_dict):\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bcf618-65af-49b9-ace8-61aad349f06f",
   "metadata": {},
   "source": [
    "Iteración usando from_tensor_slices\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94884326-fdc7-4e73-a67d-dcc3a6fe6382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# from_tensor_slices permite iterar sobre los patrones del dataset\n",
    "#\n",
    "features_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    titanic_features_dict,\n",
    ")\n",
    "\n",
    "for example in features_ds:\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cb15e1-5d3c-4606-81b2-bc429f2eb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Creación del dataset\n",
    "#\n",
    "titanic_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        titanic_features_dict,\n",
    "        titanic_labels,\n",
    "    )\n",
    ")\n",
    "\n",
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels))\n",
    "titanic_batches = titanic_batches.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82937f-6de5-45bc-8c9a-eb07b33da6e9",
   "metadata": {},
   "source": [
    "Preprocesamiento de los datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4df751-73da-4754-99b4-d70042eb4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inputs(titanic_features):\n",
    "    inputs = {}\n",
    "    for name, column in titanic_features.items():\n",
    "        dtype = column.dtype\n",
    "        if dtype == object:\n",
    "            dtype = tf.string\n",
    "        else:\n",
    "            dtype = tf.float32\n",
    "        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def preprocess_numeric_inputs(inputs):\n",
    "    numeric_inputs = {\n",
    "        name: input for name, input in inputs.items() if input.dtype == tf.float32\n",
    "    }\n",
    "    x = tf.keras.layers.Concatenate()(list(numeric_inputs.values()))\n",
    "    norm = tf.keras.layers.Normalization()\n",
    "    norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "    return [norm(x)]\n",
    "\n",
    "\n",
    "def preprocess_categoric_inputs(inputs):\n",
    "    categoric_inputs = []\n",
    "    for name, input in inputs.items():\n",
    "        if input.dtype == tf.float32:\n",
    "            continue\n",
    "        lookup = tf.keras.layers.StringLookup(\n",
    "            vocabulary=np.unique(\n",
    "                titanic_features[name],\n",
    "            )\n",
    "        )\n",
    "        one_hot = tf.keras.layers.CategoryEncoding(\n",
    "            num_tokens=lookup.vocabulary_size(),\n",
    "            output_mode=\"multi_hot\",\n",
    "        )\n",
    "        x = lookup(input)\n",
    "        x = one_hot(x)\n",
    "        categoric_inputs.append(x)\n",
    "    return categoric_inputs\n",
    "\n",
    "\n",
    "inputs = make_inputs(titanic_features)\n",
    "numeric_inputs = preprocess_numeric_inputs(inputs)\n",
    "categoric_inputs = preprocess_categoric_inputs(inputs)\n",
    "\n",
    "preprocessed_inputs = numeric_inputs + categoric_inputs\n",
    "concatenate_layer = tf.keras.layers.Concatenate()\n",
    "preprocessed_inputs = concatenate_layer(preprocessed_inputs)\n",
    "\n",
    "preprocessing_head = tf.keras.Model(inputs, preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d9126e-e323-4066-bd78-7c86f7698a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 0.6468\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5375\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4908\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4650\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4467\n"
     ]
    }
   ],
   "source": [
    "def make_titanic_model(preprocessing_head, inputs):\n",
    "\n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    \n",
    "    body = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(64),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ],\n",
    "    )    \n",
    "    result = body(preprocessed_inputs)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs,\n",
    "        result,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "titanic_model = make_titanic_model(\n",
    "    preprocessing_head,\n",
    "    inputs,\n",
    ")\n",
    "\n",
    "history = titanic_model.fit(titanic_batches, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
