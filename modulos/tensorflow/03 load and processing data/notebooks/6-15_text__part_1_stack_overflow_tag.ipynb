{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9d2ff2-a13e-4b77-805a-a2107981c9bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Predicción de la etiqueta de una pregunta en Stack Overflow--- 0:00 min\n",
    "===\n",
    "\n",
    "* Última modificación: Marzo 1, 2022 | YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac19a2-f366-486e-8432-a66188898b5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Importación de librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45c494e-1929-41d9-abb9-14853b83f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c529078-6b2b-41f6-9882-d7f1f708d9a5",
   "metadata": {},
   "source": [
    "Definición del problema\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5680fc-5caa-4e53-9cd8-5bb00d2a9343",
   "metadata": {},
   "source": [
    "En la base de datos usada, cada pregunta es etiquetada con una de las siguientes etiquetas: Python, CSharp, JavaScript, o Java. El problema consiste en pronosticar la etiqueta dada la pregunta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f86e49-8f45-47a0-a352-cc225e9b8df7",
   "metadata": {},
   "source": [
    "Descarga de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db998abf-9a5d-4981-867a-a32b7f60d658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/stackoverflow/stack_overflow_16k.tar.gz'),\n",
       " PosixPath('/tmp/stackoverflow/train'),\n",
       " PosixPath('/tmp/stackoverflow/README.md'),\n",
       " PosixPath('/tmp/stackoverflow/test')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "data_url = \"https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\"\n",
    "\n",
    "dataset_dir = tf.keras.utils.get_file(\n",
    "    origin=data_url,\n",
    "    untar=True,\n",
    "    cache_dir=\"stack_overflow\",\n",
    "    cache_subdir=\"/tmp/stackoverflow\",\n",
    ")\n",
    "\n",
    "dataset_dir = pathlib.Path(dataset_dir).parent\n",
    "\n",
    "list(dataset_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcfcb05-b540-40bb-a7eb-4aede7545f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/stackoverflow/train/java'),\n",
       " PosixPath('/tmp/stackoverflow/train/javascript'),\n",
       " PosixPath('/tmp/stackoverflow/train/csharp'),\n",
       " PosixPath('/tmp/stackoverflow/train/python')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = dataset_dir / \"train\"\n",
    "list(train_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427c618f-5bb1-4082-84bd-9ecab9009012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why does this blank program print true x=true.def stupid():.    x=false.stupid().print x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ejemplo de un mensaje\n",
    "#\n",
    "sample_file = train_dir / \"python/1755.txt\"\n",
    "\n",
    "with open(sample_file) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1861a-49e3-43fc-b7e8-eff0183ff2b2",
   "metadata": {},
   "source": [
    "Estructura del directorio de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9b9ce-6efb-465f-9a05-287cc8bfdf24",
   "metadata": {},
   "source": [
    "```\n",
    "train/\n",
    "...csharp/ \n",
    "......1.txt\n",
    "......2.txt\n",
    "...java/\n",
    "......1.txt\n",
    "......2.txt\n",
    "...javascript/\n",
    "......1.txt\n",
    "......2.txt\n",
    "...python/\n",
    "......1.txt\n",
    "......2.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196043fd-f485-4246-891e-de5bc6dbf011",
   "metadata": {},
   "source": [
    "Parámetros generales para la carga de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ee9387-3b0a-4927-8cba-1824f9ae2b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parámetros generales para la carga de datos\n",
    "#\n",
    "params = {\n",
    "    \"directory\": train_dir,\n",
    "    \"batch_size\": 32,\n",
    "    \"seed\": 12345,\n",
    "    \"validation_split\": 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee0c29-ebbb-4f1f-bf2c-8445c52aee04",
   "metadata": {
    "tags": []
   },
   "source": [
    "Carga del conjunto de entrenamiento\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a863ff6f-e444-4a90-8da8-951b9be3776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Carga del conjunto de entrenamiento\n",
    "#\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    **params,\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562499d-6ed2-45b3-8322-c849a0172a29",
   "metadata": {},
   "source": [
    "Mensajes de ejemplo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56ea335-ef65-4b56-8e2b-1d27a228ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  b'\"stopping rotating images when popup dialog box is active i am using blank functions to rotate images in an orbital manner. i also have created a popup dialog box as well. what i am trying to do is have it so that when the dialog box is active, the images stop even if i were to mouseout from the image. ..here is my blank functions i have made:..var popupstatus = 0;.var timer = null;.var m = {.z   : 100,.xm  : 0,.xmm : .25,.ymm : 0,.ym  : 0,.mx  : 0,.nx  : 0,.ny  : 0,.nw  : 0,.nh  : 0,.xr  : 0,.ni  : 0,.scr : 0,.img : 0,...run : function () {.    m.xm += (m.xmm - m.xm) * .1;.    if (m.ym &lt; m.nw * .15) m.ym++;.    m.xr += m.xm;.    for (var i = 0; i &lt; m.ni; i++){.        var a = (i * 360 / m.ni) + m.xr;.        var x = math.cos(a * (math.pi / 180));.        var y = math.sin(a * (math.pi / 180));.        var a = m.img[i];.        a.style.width  = \\'\\'.concat(math.round(math.abs(y * m.ym) + y * m.z), \\'px\\');.        a.style.left   = \\'\\'.concat(math.round((m.nw * .5) + x * ((m.nw * .5) - (m.nw * .05)) - ((math.abs(y * m.ym) + y * m.z) * .5)), \\'px\\');.        a.style.height = \\'\\'.concat(math.round(m.ym + y * m.z), \\'px\\');.        a.style.top    = \\'\\'.concat(math.round((m.nh * .5) - (m.ym * .5) - x * (m.z * .5) - (m.ymm * y)), \\'px\\');.        a.style.zindex = 600 + math.round(y);.        m.setopacity(a, (y * 50) + 100);.    }.    timer = settimeout(m.run, 30);.},..resize : function () {.    m.nx  = m.scr.offsetleft;.    m.ny  = m.scr.offsettop;.    m.nw  = m.scr.offsetwidth;.    m.nh  = m.scr.offsetheight;.},..mousemove : function (e) {.    if (window.event) e = window.event;.    m.xmm = (m.nx + (m.nw * .5) - (e.x || e.clientx)) / (m.nw * .25);.    m.ymm = (m.ny + (m.nh * .5) - (e.y || e.clienty)) / (m.nh * .005);.},..setopacity : function (obj, a) {.    if (a &lt; 0) a = 0; else if (a &gt; 100) a = 100;.    if (obj.filters) obj.filters.alpha.opacity = a;.    else obj.style.opacity = a / 100;.},..init : function () {.    m.scr = document.getelementbyid(\"\"screen\"\");.    m.img = m.scr.getelementsbytagname(\"\"img\"\");.    m.ni  = m.img.length;.    window.onresize = m.resize;..    m.resize();.    m.ym = m.z;.    m.run();.}...}.function stop(){.cleartimeout(timer);.}...onload = function() {.m.init();.}......function loadpopup(){.//loads popup only if it is disabled.if(popupstatus==0){.    $(\"\"#backgroundpopup\"\").css({.        \"\"opacity\"\": \"\"0.7\"\".    });.    $(\"\"#backgroundpopup\"\").fadein(\"\"slow\"\");.    $(\"\"#popupcontact\"\").fadein(\"\"slow\"\");.    popupstatus = 1;.}.();.}...function disablepopup(){.//disables popup only if it is enabled.if(popupstatus==1){.    $(\"\"#backgroundpopup\"\").fadeout(\"\"slow\"\");.    $(\"\"#popupcontact\"\").fadeout(\"\"slow\"\");.    popupstatus = 0;.}.}..//centering popup.function pospopup(){.//request data for centering.var windowwidth = document.documentelement.clientwidth;.var windowheight = document.documentelement.clientheight;.var popupheight = $(\"\"#popupcontact\"\").height();.var popupwidth = $(\"\"#popupcontact\"\").width();.//centering.$(\"\"#popupcontact\"\").css({.    \"\"position\"\": \"\"absolute\"\",.    \"\"top\"\": windowheight/2-popupheight/350,.    \"\"left\"\": windowwidth/2-popupwidth/8.});.//only need force for ie6..$(\"\"#backgroundpopup\"\").css({.    \"\"height\"\": windowheight.});..}...//controlling events in jquery.$(document).ready(function(){..//loading popup.//click the button event!.$(\"\"#button\"\").click(function(){.    //centering with css.    pospopup();.    //load popup.    loadpopup();.    stop();..});.});\"\\n'\n",
      "Label: 2\n",
      "\n",
      "Question:  b'\"using buffered reader does not give runtime error but using scanner gives on online judge? i was doing this question. i submitted the following code that uses a scanner to read input...import blank.io.*;.import blank.math.*;.import blank.util.*;.import blank.lang.*;..class main{ ..public static void main(string[] args)throws blank.lang.exception{.    scanner cin = new scanner(system.in);.    treemap&lt;string, integer&gt; map = new treemap&lt;string, integer&gt;();.    int trees = 0;.    while(true){.        string tree = cin.nextline();.        if(tree==null){.            break;.        }.        trees++;.        if(map.containskey(tree)){.            map.put(tree, map.get(tree)+1);.        }else{.            map.put(tree, 1);.        }.    }.    for(string key : map.keyset()){..    }..    iterator&lt;string&gt; itr = map.keyset().iterator();.    while(itr.hasnext()){.        string tree = itr.next();.        system.out.print(tree + \"\" \"\" );.        double percent = (double)map.get(tree)/trees*100;.        system.out.format(\"\"%.4fn\"\", percent);.    }..}.}...but i get a runtime error. but when i submit the same code but this time i use a buffered reader, then my answer gets accepted. is this a problem with the judge or am i missing some feature of blank\\'s input output routines. ..should i use a buffered reader or a scanner to read data more robustly?..import blank.io.*;.import blank.math.*;.import blank.util.*;.import blank.lang.*;..class main{ ..public static void main(string[] args)throws blank.lang.exception{.    bufferedreader br = new bufferedreader(new inputstreamreader(system.in));.    treemap&lt;string, integer&gt; map = new treemap&lt;string, integer&gt;();.    int trees = 0;.    while(true){.        string tree = br.readline();.        if(tree==null){.            break;.        }.        trees++;.        if(map.containskey(tree)){.            map.put(tree, map.get(tree)+1);.        }else{.            map.put(tree, 1);.        }.    }.    for(string key : map.keyset()){..    }..    iterator&lt;string&gt; itr = map.keyset().iterator();.    while(itr.hasnext()){.        string tree = itr.next();.        system.out.print(tree + \"\" \"\" );.        double percent = (double)map.get(tree)/trees*100;.        system.out.format(\"\"%.4fn\"\", percent);.    }..}.}\"\\n'\n",
      "Label: 1\n",
      "\n",
      "Question:  b'call function from the same function how can i call a function from the same function in angularjs?..example:..function one(){..           function two(){.            //now i have to call function one().           }.}\\n'\n",
      "Label: 2\n",
      "\n",
      "Question:  b'what is meaning of expression while(n&3)==0 and n>>=2 i find confused with these expression while(n&amp;3)==0 and n&gt;&gt;=2 . i am not sure when this condition is executed while((n&amp;3)==0) and what happens n&gt;&gt;=2..public int numsquares(int n) {.    while ((n &amp; 3) == 0) //n % 4 == 0  .        n &gt;&gt;= 2;  .    if ((n &amp; 7) == 7) return 4; //n% 8 == 7  ..    if(is_square(n)) return 1;  .    int sqrt_n = (int) math.sqrt(n);  .    for (int i = 1; i&lt;= sqrt_n; i++){  .        if (is_square(n-i*i)) return 2;  .    }  .    return 3;             .}..public boolean is_square(int n){  .    int temp = (int) math.sqrt(n);  .    return temp * temp == n;  .}\\n'\n",
      "Label: 1\n",
      "\n",
      "Question:  b'\"dynamic iframe content - how to get the access to that iframe? i\\'m loading a content dynamically to the &lt;iframe&gt;..&lt;iframe style=\\'border:none;\\' id=\\'abc\\' src=\"\"http://localhost:39217/home/getcontent/some_dynamic_code\"\"&gt;&lt;/iframe&gt;...after a success response, in that iframe is that content..&lt;html&gt;.   &lt;head&gt;.      &lt;script type=\"\"text/blank\"\"&gt;.          function onpageload() {.              if (document.readystate === \"\"complete\"\") {.                  var cont = document.getelementbyid(\"\"abc\"\");.                  alert(cont);    .              }.          }.      &lt;/script&gt;.   &lt;/head&gt;..   &lt;body onload=\\'onpageload()\\'&gt;.      &lt;a target=\"\"_blank\"\" href=\\'http://lorem\\'&gt;.        &lt;img class=\\'abc\\' style=\\'max-width:300px; max-height: 38px;\\' alt=\\'\\' src=\\'/images/image.png\\' /&gt;.      &lt;/a&gt;.   &lt;/body&gt;.&lt;/html&gt;...that iframe will be using outside my site (by users), but i want to have the ability to change the &lt;img&gt; src. but, i need also to change the width/height of the iframeafter i change the image. so, how can i get the access to that iframe using js ? that code above alerts me null\"\\n'\n",
      "Label: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(\"Question: \", text_batch.numpy()[i])\n",
    "        print(\"Label:\", label_batch.numpy()[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd97800-fe2b-46ba-a247-cd2b56883305",
   "metadata": {},
   "source": [
    "Etiquetas en el conjunto de entrenamiento\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be705fc-a9fa-4401-90f7-1fd1fd51d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to csharp\n",
      "Label 1 corresponds to java\n",
      "Label 2 corresponds to javascript\n",
      "Label 3 corresponds to python\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(raw_train_ds.class_names):\n",
    "    print(\"Label\", i, \"corresponds to\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a763ec7-5264-4339-883e-81af8e4e069a",
   "metadata": {},
   "source": [
    "Conjunto de validación\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c34662-36c5-4753-82f6-0310da324331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Create a validation set.\n",
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    **params,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc81c8-ab60-4fdd-abf5-1836a705a79f",
   "metadata": {},
   "source": [
    "Conjunto de prueba\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2095d0-4a92-4df1-9412-983ea366ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = dataset_dir / \"test\"\n",
    "\n",
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    test_dir, batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a95441-9fd5-4e03-ab7a-b0326e552789",
   "metadata": {},
   "source": [
    "Preparación del texto\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5693e63-a6fb-4cab-998c-e3d6d9ba7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Elimina la etiqueta asignada a cada mensaje\n",
    "#\n",
    "train_text = raw_train_ds.map(lambda text, labels: text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c947503-0e4f-4761-baa0-071cf1101baf",
   "metadata": {},
   "source": [
    "Modelo con el texto binarizado (existe o no exite la palabra en el texto)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c0af8c2-a2ca-40c4-a39b-896b2f679f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "\n",
    "binary_vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"binary\",\n",
    ")\n",
    "\n",
    "binary_vectorize_layer.adapt(train_text)\n",
    "\n",
    "def binary_vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return binary_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984457f5-4cfe-4ca0-97ca-be82c80e3d5a",
   "metadata": {},
   "source": [
    "**Ejemplo de texto binarizado**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc1ff01-cff1-4a00-ac65-6802d1bacb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question tf.Tensor(b\"are there constants for the request types in blank i am using the blank.net.httpurlconnection object to set the request method. i am about to construct an enum to handle the possible values but it seems silly this isn't already done. am i missing something? is there an enum somewhere with all of these values?..update..the content type can be handled with a jax-rs class see this.\\n\", shape=(), dtype=string)\n",
      "Label tf.Tensor(1, shape=(), dtype=int32)\n",
      "'binary' vectorized question: tf.Tensor([[1. 1. 1. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Carga el primer batch de 32 elementos\n",
    "#\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "\n",
    "#\n",
    "# Extrae la primera pregunta y su etiqueta\n",
    "#\n",
    "first_question, first_label = text_batch[0], label_batch[0]\n",
    "\n",
    "#\n",
    "# Ejemplo\n",
    "#\n",
    "print(\"Question\", first_question)\n",
    "print(\"Label\", first_label)\n",
    "print(\n",
    "    \"'binary' vectorized question:\",\n",
    "    binary_vectorize_text(first_question, first_label)[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459342bf-c713-49f7-8377-781915b47304",
   "metadata": {},
   "source": [
    "**Preparación de los conjuntos de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e2758d-cbdc-439d-9a33-e86ac25697d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_ds = raw_train_ds.map(binary_vectorize_text)\n",
    "binary_val_ds = raw_val_ds.map(binary_vectorize_text)\n",
    "binary_test_ds = raw_test_ds.map(binary_vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc017f-ece9-49bf-8e0c-06a1b20d0e58",
   "metadata": {},
   "source": [
    "**Configuración para el desempeño**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f5e0ba-768b-429d-ae70-9abb19bf776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def configure_dataset(dataset):\n",
    "    return dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f77238c-52e4-4460-bc06-2269f36b7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_ds = configure_dataset(binary_train_ds)\n",
    "binary_val_ds = configure_dataset(binary_val_ds)\n",
    "binary_test_ds = configure_dataset(binary_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4decf-fd25-4733-8685-b780d1576392",
   "metadata": {},
   "source": [
    "**Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a54b795e-9831-465e-85bd-71732890bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 2s 7ms/step - loss: 1.1167 - accuracy: 0.6602 - val_loss: 0.9206 - val_accuracy: 0.7550\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7763 - accuracy: 0.8163 - val_loss: 0.7596 - val_accuracy: 0.7788\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6257 - accuracy: 0.8580 - val_loss: 0.6754 - val_accuracy: 0.7981\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5327 - accuracy: 0.8825 - val_loss: 0.6228 - val_accuracy: 0.8081\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4669 - accuracy: 0.9034 - val_loss: 0.5868 - val_accuracy: 0.8156\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4168 - accuracy: 0.9164 - val_loss: 0.5607 - val_accuracy: 0.8150\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3767 - accuracy: 0.9273 - val_loss: 0.5413 - val_accuracy: 0.8138\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3434 - accuracy: 0.9364 - val_loss: 0.5263 - val_accuracy: 0.8181\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3153 - accuracy: 0.9434 - val_loss: 0.5148 - val_accuracy: 0.8181\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.9500 - val_loss: 0.5057 - val_accuracy: 0.8156\n"
     ]
    }
   ],
   "source": [
    "binary_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(4),\n",
    "    ]\n",
    ")\n",
    "\n",
    "binary_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = binary_model.fit(binary_train_ds, validation_data=binary_val_ds, epochs=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb762984-dfbf-4a10-a86a-1a1c44ad31a4",
   "metadata": {},
   "source": [
    "Modelo con texto como secuencia de enteros\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "654d648e-9990-410b-b9ff-cd30329344f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "int_vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE, output_mode=\"int\", output_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    ")\n",
    "\n",
    "int_vectorize_layer.adapt(train_text)\n",
    "\n",
    "def int_vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return int_vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b735-f9a3-44f3-8a40-bdb92abe5cba",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6f00717-da80-4959-bec5-2e7e334652ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'int' vectorized question: tf.Tensor(\n",
      "[[  61   68 3725   12    2  555  545    7   16    3   36   47    2    1\n",
      "    57    4   99    2  555   64    3   36  199    4 2630   31  916    4\n",
      "   740    2  204  131   26   11  310 2468   13  547  346  402   36    3\n",
      "   439  147    6   68   31  916 2152   23   73    9  227    1  425  116\n",
      "    34   33 3438   23    5    1   28  189   13    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]], shape=(1, 250), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"'int' vectorized question:\", int_vectorize_text(first_question, first_label)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c9c962-faaf-4bde-83c8-da36eddb7147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1289 --->  documentation\n",
      "313 --->  go\n",
      "Vocabulary size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"1289 ---> \", int_vectorize_layer.get_vocabulary()[1289])\n",
    "print(\"313 ---> \", int_vectorize_layer.get_vocabulary()[313])\n",
    "print(\"Vocabulary size: {}\".format(len(int_vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7aafd7-f008-419b-91f7-f3c761d78e48",
   "metadata": {},
   "source": [
    "**Configuración para el desempeño**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4309679-938f-44fe-8793-75a0da5c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_train_ds = raw_train_ds.map(int_vectorize_text)\n",
    "int_val_ds = raw_val_ds.map(int_vectorize_text)\n",
    "int_test_ds = raw_test_ds.map(int_vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92266420-4025-4f9b-bb0d-ffc49718f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_train_ds = configure_dataset(int_train_ds)\n",
    "int_val_ds = configure_dataset(int_val_ds)\n",
    "int_test_ds = configure_dataset(int_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36247541-95ef-42b9-a0d3-38cdb191dad9",
   "metadata": {},
   "source": [
    "**Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65f0c61-2359-4080-8468-47fdda8b9ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_labels):\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Embedding(vocab_size, 64, mask_zero=True,),\n",
    "            tf.keras.layers.Conv1D(\n",
    "                64, 5, padding=\"valid\", activation=\"relu\", strides=2,\n",
    "            ),\n",
    "            tf.keras.layers.GlobalMaxPooling1D(),\n",
    "            tf.keras.layers.Dense(num_labels),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919b4f78-97eb-4ccc-8c27-c394a2c2bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 13ms/step - loss: 1.1369 - accuracy: 0.5044 - val_loss: 0.7528 - val_accuracy: 0.6869\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.6181 - accuracy: 0.7661 - val_loss: 0.5513 - val_accuracy: 0.7725\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.3770 - accuracy: 0.8822 - val_loss: 0.4762 - val_accuracy: 0.8169\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.2086 - accuracy: 0.9492 - val_loss: 0.4668 - val_accuracy: 0.8188\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 2s 12ms/step - loss: 0.1029 - accuracy: 0.9822 - val_loss: 0.4895 - val_accuracy: 0.8138\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# `vocab_size` es `VOCAB_SIZE + 1` ya que `0` es usado para el padding.\n",
    "#\n",
    "int_model = create_model(vocab_size=VOCAB_SIZE + 1, num_labels=4,)\n",
    "\n",
    "int_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = int_model.fit(\n",
    "    int_train_ds,\n",
    "    validation_data=int_val_ds,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457db78d-f990-4778-aae4-5938aac2c95f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Comparación de los modelos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16411075-50a9-4293-849b-888906a6c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4)                 40004     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,004\n",
      "Trainable params: 40,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3126f49f-60fe-41ed-a7d4-a6f0e0538e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          640064    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 64)          20544     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660,868\n",
      "Trainable params: 660,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac6fadfb-6aa5-41b2-92cc-b6ba4661201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.8170\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.8054\n",
      "Binary model accuracy: 81.70%\n",
      "Int model accuracy: 80.54%\n"
     ]
    }
   ],
   "source": [
    "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_ds)\n",
    "int_loss, int_accuracy = int_model.evaluate(int_test_ds)\n",
    "\n",
    "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))\n",
    "print(\"Int model accuracy: {:2.2%}\".format(int_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7076bc8-cd20-4992-9b74-5556158c74f3",
   "metadata": {},
   "source": [
    "Exportación del modelo\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9b1bdde-fc32-4aea-9905-411a8177778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5205 - accuracy: 0.8170\n",
      "Accuracy: 81.70%\n"
     ]
    }
   ],
   "source": [
    "export_model = tf.keras.Sequential(\n",
    "    [binary_vectorize_layer, binary_model, tf.keras.layers.Activation(\"sigmoid\"),]\n",
    ")\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "#\n",
    "# test\n",
    "#\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(\"Accuracy: {:2.2%}\".format(binary_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf27b4-0613-462a-bd05-b90d2cf57d41",
   "metadata": {},
   "source": [
    "Ejecución sobre nuevos datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d8ef429-c886-4727-a934-73cc3df0dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_labels(predicted_scores_batch):\n",
    "    predicted_int_labels = tf.argmax(predicted_scores_batch, axis=1)\n",
    "    predicted_labels = tf.gather(raw_train_ds.class_names, predicted_int_labels)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1639fcc-8ed8-4b2e-8503-8efb94b29452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  how do I extract keys from a dict into a list?\n",
      "Predicted label:  b'python'\n",
      "\n",
      "Question:  debug public static void main(string[] args) {...}\n",
      "Predicted label:  b'java'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"how do I extract keys from a dict into a list?\",  # 'python'\n",
    "    \"debug public static void main(string[] args) {...}\",  # 'java'\n",
    "]\n",
    "predicted_scores = export_model.predict(inputs)\n",
    "predicted_labels = get_string_labels(predicted_scores)\n",
    "for input, label in zip(inputs, predicted_labels):\n",
    "    print(\"Question: \", input)\n",
    "    print(\"Predicted label: \", label.numpy())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
