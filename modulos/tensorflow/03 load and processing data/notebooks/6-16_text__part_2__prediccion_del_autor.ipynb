{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c3522b-6f5b-4455-98e6-0bb7815b6ef3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Predicción del autor de una traducción --- 0:00 min\n",
    "===\n",
    "\n",
    "* Última modificación: Marzo 1, 2022 | YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e055ffa-859a-458e-94cb-4b5b3f9fe749",
   "metadata": {
    "tags": []
   },
   "source": [
    "Importación de librerías\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab62e7be-a10b-474a-9762-c016033a9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be2650-1784-4b6f-a406-dc59209a7813",
   "metadata": {},
   "source": [
    "Descarga de datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2869e677-1eaa-4cca-a27c-ec10daf71bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tmp/authors/derby.txt'),\n",
       " PosixPath('/tmp/authors/butler.txt'),\n",
       " PosixPath('/tmp/authors/cowper.txt')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "DIRECTORY_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/illiad/\"\n",
    "\n",
    "FILE_NAMES = [\n",
    "    \"cowper.txt\",\n",
    "    \"derby.txt\",\n",
    "    \"butler.txt\",\n",
    "]\n",
    "\n",
    "for name in FILE_NAMES:\n",
    "    text_dir = tf.keras.utils.get_file(\n",
    "        name, origin=DIRECTORY_URL + name, cache_subdir=\"/tmp/authors\"\n",
    "    )\n",
    "\n",
    "parent_dir = pathlib.Path(text_dir).parent\n",
    "list(parent_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede74da8-8947-4bc8-bec0-bd023a6a9922",
   "metadata": {},
   "source": [
    "Carga de los datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74885bc-ab72-4239-88e5-55e946f81f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(example, index):\n",
    "    #\n",
    "    # Convierte el indice a un int64\n",
    "    #\n",
    "    return example, tf.cast(index, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f2040a-25f7-44e0-9b83-8d96a3369a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# En esa lista se agregan todos los archivos\n",
    "#\n",
    "labeled_data_sets = []\n",
    "\n",
    "for i, file_name in enumerate(FILE_NAMES):\n",
    "    #\n",
    "    # Cada línea de texto es un registro en el dataset (no el archivo como se\n",
    "    # hizo antes)\n",
    "    #\n",
    "    lines_dataset = tf.data.TextLineDataset(str(parent_dir / file_name))\n",
    "\n",
    "    #\n",
    "    # Agrega la etiquea a cada línea de texto\n",
    "    #\n",
    "    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n",
    "\n",
    "    #\n",
    "    # Adiciona las líneas etiquetadas\n",
    "    #\n",
    "    labeled_data_sets.append(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52099972-1ae1-4623-81da-9e04bed57b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df7a4f0-ba58-483b-864d-1ad663ea20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Crea un único dataset\n",
    "#\n",
    "all_labeled_data = labeled_data_sets[0]\n",
    "\n",
    "for labeled_dataset in labeled_data_sets[1:]:\n",
    "    all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n",
    "\n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "    BUFFER_SIZE,\n",
    "    reshuffle_each_iteration=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3566dc64-4c80-4f07-b0e9-78e850b396d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  b\"servant that was the city's herald with him. Then she saw him that was\"\n",
      "Label: 2\n",
      "Sentence:  b'To soothe the awful Goddess? Tell me true.'\n",
      "Label: 0\n",
      "Sentence:  b\"And from his father's vineyard captive borne:\"\n",
      "Label: 1\n",
      "Sentence:  b'come out of the fight. Agamemnon, king of men, sacrificed a fat'\n",
      "Label: 2\n",
      "Sentence:  b'The onset of AEneas, swift in fight,'\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "for text, label in all_labeled_data.take(5):\n",
    "    print(\"Sentence: \", text.numpy())\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75a436-ab88-4762-9d1a-f5f24f49a02e",
   "metadata": {},
   "source": [
    "Prepración del dataset para entrenamiento\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7838afc5-c8b0-4c10-ad75-b7a3df38afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf_text.UnicodeScriptTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4f4c14-f2ad-4ea8-8203-d7d7003282f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, unused_label):\n",
    "    lower_case = tf_text.case_fold_utf8(text)\n",
    "    return tokenizer.tokenize(lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64fe2747-e494-491b-86aa-6bdbdf79dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ds = all_labeled_data.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5c15e6-9010-4213-ad2a-865270bedbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  [b'servant' b'that' b'was' b'the' b'city' b\"'\" b's' b'herald' b'with'\n",
      " b'him' b'.' b'then' b'she' b'saw' b'him' b'that' b'was']\n",
      "Tokens:  [b'to' b'soothe' b'the' b'awful' b'goddess' b'?' b'tell' b'me' b'true'\n",
      " b'.']\n",
      "Tokens:  [b'and' b'from' b'his' b'father' b\"'\" b's' b'vineyard' b'captive' b'borne'\n",
      " b':']\n",
      "Tokens:  [b'come' b'out' b'of' b'the' b'fight' b'.' b'agamemnon' b',' b'king' b'of'\n",
      " b'men' b',' b'sacrificed' b'a' b'fat']\n",
      "Tokens:  [b'the' b'onset' b'of' b'aeneas' b',' b'swift' b'in' b'fight' b',']\n"
     ]
    }
   ],
   "source": [
    "for text_batch in tokenized_ds.take(5):\n",
    "    print(\"Tokens: \", text_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ab4794-5a8a-4bed-a88e-c0a0022ed83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def configure_dataset(dataset):\n",
    "    return dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "tokenized_ds = configure_dataset(tokenized_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b767a38-92d1-4caf-bc66-0be623265e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  10000\n",
      "First five vocab entries: [b',', b'the', b'and', b\"'\", b'of']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "vocab_dict = defaultdict(lambda: 0)\n",
    "\n",
    "for toks in tokenized_ds.as_numpy_iterator():\n",
    "    for tok in toks:\n",
    "        vocab_dict[tok] += 1\n",
    "\n",
    "vocab = sorted(\n",
    "    vocab_dict.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True,\n",
    ")\n",
    "\n",
    "vocab = [token for token, count in vocab]\n",
    "vocab = vocab[:VOCAB_SIZE]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "print(\"First five vocab entries:\", vocab[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a8ac046-1289-45c0-b4ef-2613afae5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = vocab\n",
    "values = range(2, len(vocab) + 2)  # Reserve `0` for padding, `1` for OOV tokens.\n",
    "\n",
    "init = tf.lookup.KeyValueTensorInitializer(\n",
    "    keys, values, key_dtype=tf.string, value_dtype=tf.int64\n",
    ")\n",
    "\n",
    "num_oov_buckets = 1\n",
    "vocab_table = tf.lookup.StaticVocabularyTable(init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977b4439-b1ef-40a6-aed1-fffd11bfd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, label):\n",
    "    standardized = tf_text.case_fold_utf8(text)\n",
    "    tokenized = tokenizer.tokenize(standardized)\n",
    "    vectorized = vocab_table.lookup(tokenized)\n",
    "    return vectorized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1cc2e1-6952-4d40-a5f7-d1a6f4b3319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encoded_data = all_labeled_data.map(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65e25f-cd27-4528-9128-42ff191e398c",
   "metadata": {},
   "source": [
    "Conjuntos de entrenamiento y prueba\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b780e5-d5e9-4b3a-88c7-9b9504f1f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_encoded_data.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE)\n",
    "validation_data = all_encoded_data.take(VALIDATION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99738a1d-1c67-4676-997a-d1964066739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.padded_batch(BATCH_SIZE)\n",
    "validation_data = validation_data.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b76b5fc-7407-4473-9afe-6cc19be77c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text batch shape:  (64, 18)\n",
      "Label batch shape:  (64,)\n",
      "First text example:  tf.Tensor(\n",
      "[2263   23   36    3  149    5   29 1007   14   16    7   33   69  200\n",
      "   16   23   36    0], shape=(18,), dtype=int64)\n",
      "First label example:  tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Ejemplo\n",
    "#\n",
    "sample_text, sample_labels = next(iter(validation_data))\n",
    "print(\"Text batch shape: \", sample_text.shape)\n",
    "print(\"Label batch shape: \", sample_labels.shape)\n",
    "print(\"First text example: \", sample_text[0])\n",
    "print(\"First label example: \", sample_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45069ae0-0a65-4c39-84fc-c8b09dce9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e816f0e-41bb-42d9-bd44-5a6f2f8656b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = configure_dataset(train_data)\n",
    "validation_data = configure_dataset(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa8662-65cc-43b8-ac33-fecf59f84b30",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e667e21-7af4-4847-95b7-088e3e44e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_labels):\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Embedding(\n",
    "                vocab_size,\n",
    "                64,\n",
    "                mask_zero=True,\n",
    "            ),\n",
    "            tf.keras.layers.Conv1D(\n",
    "                64,\n",
    "                5,\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "                strides=2,\n",
    "            ),\n",
    "            tf.keras.layers.GlobalMaxPooling1D(),\n",
    "            tf.keras.layers.Dense(num_labels),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa72f8dc-0e14-4c99-959b-b9d82b270f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "697/697 [==============================] - 245s 44ms/step - loss: 0.5144 - accuracy: 0.7720 - val_loss: 0.3656 - val_accuracy: 0.8406\n",
      "Epoch 2/3\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.2819 - accuracy: 0.8861 - val_loss: 0.3578 - val_accuracy: 0.8462\n",
      "Epoch 3/3\n",
      "697/697 [==============================] - 6s 9ms/step - loss: 0.1921 - accuracy: 0.9277 - val_loss: 0.3920 - val_accuracy: 0.8450\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size=vocab_size, num_labels=3)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(train_data, validation_data=validation_data, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d526c7-13e9-4dae-90a6-35b4a68c01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8450\n",
      "Loss:  0.39201173186302185\n",
      "Accuracy: 84.50%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_data)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: {:2.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c625c-c882-4f93-a8a2-17ed2d902941",
   "metadata": {},
   "source": [
    "Exportación del modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8006e37-44d6-4513-ad46-56d4a6527190",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "preprocess_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    standardize=tf_text.case_fold_utf8,\n",
    "    split=tokenizer.tokenize,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    ")\n",
    "\n",
    "preprocess_layer.set_vocabulary(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f29b24-2b9b-4ccc-9b6c-42c322e81488",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential(\n",
    "    [\n",
    "        preprocess_layer,\n",
    "        model,\n",
    "        tf.keras.layers.Activation(\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e955ab2-d0c3-4be2-b0f6-0a9063d53e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 7s 4ms/step - loss: 0.5805 - accuracy: 0.7776\n",
      "Loss:  0.5805197358131409\n",
      "Accuracy: 77.76%\n"
     ]
    }
   ],
   "source": [
    "# Create a test dataset of raw strings.\n",
    "test_ds = all_labeled_data.take(VALIDATION_SIZE).batch(BATCH_SIZE)\n",
    "test_ds = configure_dataset(test_ds)\n",
    "\n",
    "loss, accuracy = export_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: {:2.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47cb674-6885-4d65-b2eb-6846658c75c4",
   "metadata": {},
   "source": [
    "Ejecución sobre nuevos datos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62f07d19-e77e-43cf-aa7e-8f6cda187dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Join'd to th' Ionians with their flowing robes,\n",
      "Predicted label:  1\n",
      "Question:  the allies, and his armour flashed about him so that he seemed to all\n",
      "Predicted label:  2\n",
      "Question:  And with loud clangor of his arms he fell.\n",
      "Predicted label:  0\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"Join'd to th' Ionians with their flowing robes,\",  # Label: 1\n",
    "    \"the allies, and his armour flashed about him so that he seemed to all\",  # Label: 2\n",
    "    \"And with loud clangor of his arms he fell.\",  # Label: 0\n",
    "]\n",
    "\n",
    "predicted_scores = export_model.predict(inputs)\n",
    "predicted_labels = tf.argmax(predicted_scores, axis=1)\n",
    "\n",
    "for input, label in zip(inputs, predicted_labels):\n",
    "    print(\"Question: \", input)\n",
    "    print(\"Predicted label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9bd2c-e89c-4568-a117-d36545f691ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
